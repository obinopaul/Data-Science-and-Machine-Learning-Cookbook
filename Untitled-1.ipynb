{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.datasets import load_iris, load_digits, load_breast_cancer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the breast cancer dataset\n",
    "X, y  = load_breast_cancer(return_X_y=True,as_frame=True)\n",
    "\n",
    "numerical_feature = [feature for feature in X.columns if X[feature].dtypes != 'O']\n",
    "discrete_feature=[feature for feature in numerical_feature if len(X[feature].unique())<25]\n",
    "continuous_feature = [feature for feature in numerical_feature if feature not in discrete_feature]\n",
    "categorical_feature = [feature for feature in X.columns if feature not in numerical_feature]\n",
    "print(\"Numerical Features Count {}\".format(len(numerical_feature)))\n",
    "print(\"Discrete feature Count {}\".format(len(discrete_feature)))\n",
    "print(\"Continuous feature Count {}\".format(len(continuous_feature)))\n",
    "print(\"Categorical feature Count {}\".format(len(categorical_feature)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "X, y = load_breast_cancer(return_X_y=True, as_frame=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, label = fetch_openml(name = 'blood-transfusion-service-center', as_frame=True, return_X_y=True)# data_id=1464)\n",
    "X, y = fetch_openml(data_id=1597)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X x "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Cornel\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n",
      "c:\\Users\\Cornel\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1382: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster_0</th>\n",
       "      <th>cluster_1</th>\n",
       "      <th>cluster_2</th>\n",
       "      <th>age</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>70000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>45000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>90000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>25000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>35000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>60000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>70</td>\n",
       "      <td>120000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>55000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>40000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cluster_0  cluster_1  cluster_2  age  income\n",
       "0          1          0          0   22   50000\n",
       "1          1          0          0   45   70000\n",
       "2          0          0          1   30   45000\n",
       "3          0          1          0   60   90000\n",
       "4          0          0          1   18   25000\n",
       "5          0          0          1   25   35000\n",
       "6          1          0          0   40   60000\n",
       "7          0          1          0   70  120000\n",
       "8          1          0          0   35   55000\n",
       "9          0          0          1   28   40000"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Create a sample dataset\n",
    "data = {'age': [22, 45, 30, 60, 18, 25, 40, 70, 35, 28],\n",
    "        'income': [50000, 70000, 45000, 90000, 25000, 35000, 60000, 120000, 55000, 40000],\n",
    "        'label': [0, 1, 0, 1, 0, 0, 1, 1, 0, 0]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Perform K-Means clustering for discretization\n",
    "kmeans = KMeans(n_clusters=3)\n",
    "df['cluster'] = kmeans.fit_predict(df[['age', 'income']])\n",
    "# df\n",
    "# Build a model on the discretized dataset\n",
    "X = pd.get_dummies(df['cluster'], prefix='cluster')\n",
    "\n",
    "X['age'] = df['age']\n",
    "X['income'] = df['income']\n",
    "# y = df['label']\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OpenML Classification Task\n",
       "==========================\n",
       "Task Type Description: https://www.openml.org/tt/TaskType.SUPERVISED_CLASSIFICATION\n",
       "Task ID..............: 3954\n",
       "Task URL.............: https://www.openml.org/t/3954\n",
       "Estimation Procedure.: crossvalidation\n",
       "Target Feature.......: class:\n",
       "# of Classes.........: 2\n",
       "Cost Matrix..........: Available"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Cornel\\anaconda3\\lib\\site-packages\\openml\\extensions\\sklearn\\extension.py\", line 1696, in _run_model_on_fold\n",
      "    # for measuring runtime. Only available since Python 3.3\n",
      "  File \"c:\\Users\\Cornel\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 401, in fit\n",
      "    Xt = self._fit(X, y, **fit_params_steps)\n",
      "  File \"c:\\Users\\Cornel\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 359, in _fit\n",
      "    X, fitted_transformer = fit_transform_one_cached(\n",
      "  File \"c:\\Users\\Cornel\\anaconda3\\lib\\site-packages\\joblib\\memory.py\", line 349, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"c:\\Users\\Cornel\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 893, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"c:\\Users\\Cornel\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_set_output.py\", line 140, in wrapped\n",
      "    data_to_wrap = f(self, X, *args, **kwargs)\n",
      "  File \"c:\\Users\\Cornel\\anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 724, in fit_transform\n",
      "    self._validate_column_callables(X)\n",
      "  File \"c:\\Users\\Cornel\\anaconda3\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py\", line 424, in _validate_column_callables\n",
      "    columns = columns(X)\n",
      "  File \"c:\\Users\\Cornel\\anaconda3\\lib\\site-packages\\openml\\extensions\\sklearn\\__init__.py\", line 36, in cat\n",
      "    raise AttributeError(\"Not a Pandas DataFrame with 'dtypes' as attribute!\")\n",
      "AttributeError: Not a Pandas DataFrame with 'dtypes' as attribute!\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Cornel\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 3460, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Cornel\\AppData\\Local\\Temp\\ipykernel_33732\\1557646214.py\", line 32, in <module>\n",
      "    run = openml.runs.run_model_on_task(\n",
      "  File \"c:\\Users\\Cornel\\anaconda3\\lib\\site-packages\\openml\\runs\\functions.py\", line 131, in run_model_on_task\n",
      "    run = run_flow_on_task(\n",
      "  File \"c:\\Users\\Cornel\\anaconda3\\lib\\site-packages\\openml\\runs\\functions.py\", line 273, in run_flow_on_task\n",
      "    model=flow.model,\n",
      "  File \"c:\\Users\\Cornel\\anaconda3\\lib\\site-packages\\openml\\runs\\functions.py\", line 474, in _run_task_get_arffcontent\n",
      "  File \"c:\\Users\\Cornel\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 1048, in __call__\n",
      "    if self.dispatch_one_batch(iterator):\n",
      "  File \"c:\\Users\\Cornel\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 864, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"c:\\Users\\Cornel\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 782, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"c:\\Users\\Cornel\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"c:\\Users\\Cornel\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"c:\\Users\\Cornel\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 263, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\Cornel\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\", line 263, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"c:\\Users\\Cornel\\anaconda3\\lib\\site-packages\\openml\\runs\\functions.py\", line 668, in _run_task_get_arffcontent_parallel_helper\n",
      "    config.logger.info(\n",
      "  File \"c:\\Users\\Cornel\\anaconda3\\lib\\site-packages\\openml\\extensions\\sklearn\\extension.py\", line 1709, in _run_model_on_fold\n",
      "    refit_time = model_copy.refit_time_ * 1000 if hasattr(model_copy, \"refit_time_\") else 0\n",
      "openml.exceptions.PyOpenMLError: Not a Pandas DataFrame with 'dtypes' as attribute!\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Cornel\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\interactiveshell.py\", line 2057, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "  File \"C:\\Users\\Cornel\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\ultratb.py\", line 1118, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "  File \"C:\\Users\\Cornel\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\ultratb.py\", line 1012, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "  File \"C:\\Users\\Cornel\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\ultratb.py\", line 865, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "  File \"C:\\Users\\Cornel\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\ultratb.py\", line 818, in format_exception_as_a_whole\n",
      "    frames.append(self.format_record(r))\n",
      "  File \"C:\\Users\\Cornel\\AppData\\Roaming\\Python\\Python310\\site-packages\\IPython\\core\\ultratb.py\", line 736, in format_record\n",
      "    result += ''.join(_format_traceback_lines(frame_info.lines, Colors, self.has_colors, lvals))\n",
      "  File \"C:\\Users\\Cornel\\AppData\\Roaming\\Python\\Python310\\site-packages\\stack_data\\utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"C:\\Users\\Cornel\\AppData\\Roaming\\Python\\Python310\\site-packages\\stack_data\\core.py\", line 734, in lines\n",
      "    pieces = self.included_pieces\n",
      "  File \"C:\\Users\\Cornel\\AppData\\Roaming\\Python\\Python310\\site-packages\\stack_data\\utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"C:\\Users\\Cornel\\AppData\\Roaming\\Python\\Python310\\site-packages\\stack_data\\core.py\", line 681, in included_pieces\n",
      "    pos = scope_pieces.index(self.executing_piece)\n",
      "  File \"C:\\Users\\Cornel\\AppData\\Roaming\\Python\\Python310\\site-packages\\stack_data\\utils.py\", line 144, in cached_property_wrapper\n",
      "    value = obj.__dict__[self.func.__name__] = self.func(obj)\n",
      "  File \"C:\\Users\\Cornel\\AppData\\Roaming\\Python\\Python310\\site-packages\\stack_data\\core.py\", line 660, in executing_piece\n",
      "    return only(\n",
      "  File \"C:\\Users\\Cornel\\AppData\\Roaming\\Python\\Python310\\site-packages\\executing\\executing.py\", line 190, in only\n",
      "    raise NotOneValueFound('Expected one value, found 0')\n",
      "executing.executing.NotOneValueFound: Expected one value, found 0\n"
     ]
    }
   ],
   "source": [
    "# To perform the following line offline, it is required to have been called before\n",
    "# such that the task is cached on the local openml cache directory:\n",
    "from sklearn.pipeline import Pipeline\n",
    "from openml.extensions.sklearn import cat, cont\n",
    "import openml\n",
    "from sklearn import compose, ensemble, impute, neighbors, preprocessing, pipeline, tree\n",
    "# task = openml.tasks.get_task(6)\n",
    "\n",
    "pipe = Pipeline(\n",
    "    steps=[\n",
    "        (\n",
    "            \"Preprocessing\",\n",
    "            compose.ColumnTransformer(\n",
    "                [\n",
    "                    (\n",
    "                        \"categorical\",\n",
    "                        preprocessing.OneHotEncoder(sparse=False, handle_unknown=\"ignore\"),\n",
    "                        cat,  # returns the categorical feature indices\n",
    "                    ),\n",
    "                    (\n",
    "                        \"continuous\",\n",
    "                        impute.SimpleImputer(strategy=\"median\"),\n",
    "                        cont,\n",
    "                    ),  # returns the numeric feature indices\n",
    "                ]\n",
    "            ),\n",
    "        ),\n",
    "        (\"Classifier\", ensemble.RandomForestClassifier(n_estimators=10)),\n",
    "    ]\n",
    ")\n",
    "# The following lines can then be executed offline:\n",
    "run = openml.runs.run_model_on_task(\n",
    "    pipe,\n",
    "    task,\n",
    "    avoid_duplicate_runs=False,\n",
    "    upload_flow=False,\n",
    "    dataset_format=\"array\",\n",
    ")\n",
    "\n",
    "# The run may be stored offline, and the flow will be stored along with it:\n",
    "run.to_filesystem(directory=\"myrun\")\n",
    "\n",
    "# They may be loaded and uploaded at a later time\n",
    "run = openml.runs.OpenMLRun.from_filesystem(directory=\"myrun\")\n",
    "run.publish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.cluster import DBSCAN\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Load the breast cancer dataset\n",
    "data = load_breast_cancer()\n",
    "X, y = data.data, data.target\n",
    "\n",
    "# Preprocess the data (e.g., remove missing values, scale the data)\n",
    "\n",
    "# Density-based anomaly detection using LOF\n",
    "k = 10\n",
    "lof = LocalOutlierFactor(n_neighbors=k)\n",
    "scores = lof.fit_predict(X)\n",
    "\n",
    "# Identify the anomalies\n",
    "anomalies = X[scores == -1]\n",
    "\n",
    "# Visualize the anomalies using scatter plots\n",
    "fig, ax = plt.subplots(figsize=(10, 7))\n",
    "ax.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.Set1, edgecolor='k')\n",
    "ax.scatter(anomalies[:, 0], anomalies[:, 1], c='red', marker='x', s=100, linewidth=2)\n",
    "ax.set_xlabel('Feature 0')\n",
    "ax.set_ylabel('Feature 1')\n",
    "ax.set_title('Breast Cancer Dataset (LOF Anomalies in Red)')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Generate a random dataset for demonstration purposes\n",
    "X, y = make_classification(n_samples=1000, n_features=10, n_classes=2, random_state=42)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Preprocess the data (e.g., remove missing values, scale the data)\n",
    "\n",
    "# Density-based anomaly detection using LOF\n",
    "k = 10\n",
    "lof = LocalOutlierFactor(n_neighbors=k,  novelty=True)\n",
    "lof.fit(X_train)\n",
    "\n",
    "# Predict the anomalies on the test set\n",
    "lof_scores = lof.negative_outlier_factor_\n",
    "lof_pred = lof.predict(X_test)\n",
    "lof_anomalies = X_test[lof_pred == -1]\n",
    "\n",
    "# Evaluate the performance of LOF on the test set\n",
    "lof_cm = confusion_matrix(y_test, np.where(lof_pred == -1, 1, 0))\n",
    "lof_cr = classification_report(y_test, np.where(lof_pred == -1, 1, 0))\n",
    "\n",
    "lof_cm, lof_cr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Clustering-based anomaly detection using DBSCAN\n",
    "eps = 1.0\n",
    "min_samples = 10\n",
    "dbscan = DBSCAN(eps=eps, min_samples=min_samples)\n",
    "dbscan.fit(X)\n",
    "\n",
    "# Identify the anomalies\n",
    "anomalies = X[dbscan.labels_ == -1]\n",
    "\n",
    "# Visualize the anomalies using scatter plots\n",
    "fig, ax = plt.subplots(figsize=(10, 7))\n",
    "ax.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.Set1, edgecolor='k')\n",
    "ax.scatter(anomalies[:, 0], anomalies[:, 1], c='red', marker='x', s=100, linewidth=2)\n",
    "ax.set_xlabel('Feature 0')\n",
    "ax.set_ylabel('Feature 1')\n",
    "ax.set_title('Breast Cancer Dataset (DBSCAN Anomalies in Red)')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clustering-based anomaly detection using DBSCAN\n",
    "eps = 1.0\n",
    "min_samples = 10\n",
    "dbscan = DBSCAN(eps=eps, min_samples=min_samples)\n",
    "dbscan.fit(X_train)\n",
    "\n",
    "# Get the labels of the training data\n",
    "dbscan_labels = dbscan.labels_\n",
    "\n",
    "# Get the indices of the normal and anomalous samples\n",
    "normal_idx = np.where(dbscan_labels != -1)[0]\n",
    "anomalous_idx = np.where(dbscan_labels == -1)[0]\n",
    "\n",
    "# Get the normal and anomalous samples\n",
    "normal_samples = X[normal_idx]\n",
    "anomalous_samples = X[anomalous_idx]\n",
    "\n",
    "# Evaluate the performance of DBSCAN\n",
    "dbscan_cm = confusion_matrix(y, np.where(dbscan_labels == -1, 1, 0))\n",
    "dbscan_cr = classification_report(y, np.where(dbscan_labels == -1, 1, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OR\n",
    "from sklearn.model_selection import train_test_split\n",
    "from yellowbrick.target import ClassBalance \n",
    "# Instantiate the visualizer\n",
    "X, y = load_iris(return_X_y=True, as_frame=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=45)\n",
    "\n",
    "visualizer = ClassBalance(labels=['setosa', 'versicolor', 'virginica'])\n",
    "visualizer.fit(y_train, y_test)        # Fit the data to the visualizer (you can also use visualizer.fit(y))\n",
    "# visualizer.fit(y) \n",
    "visualizer.show()                       # Finalize and render the figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "X, y = load_iris(return_X_y=True, as_frame=True)\n",
    "X['target'] = y \n",
    "target_name = df.target_names\n",
    "\n",
    "def check_imbalance(dataset, columns=None, threshold=10):\n",
    "    \"\"\"\n",
    "    This function takes a dataset and one or more columns as input and returns True if any of the specified columns\n",
    "    are imbalanced, False otherwise. A column is considered imbalanced if the percentage of the minority class is less\n",
    "    than the specified threshold.\n",
    "    \"\"\"\n",
    "    # If no columns are specified, use all columns except for the last one as the features\n",
    "    if columns is None:\n",
    "        features = dataset.iloc[:, :-1]\n",
    "        columns = features.columns\n",
    "    \n",
    "    # Check the imbalance of each specified column\n",
    "    for col in columns:\n",
    "        # Get the counts of each class in the column\n",
    "        class_counts = dataset[col].value_counts()\n",
    "\n",
    "        # Calculate the percentage of each class in the column\n",
    "        class_percentages = class_counts / len(dataset) * 100\n",
    "\n",
    "        # Plot the class percentages\n",
    "        plt.bar(class_counts.index, class_percentages)\n",
    "        plt.xlabel(col)\n",
    "        plt.ylabel('Percentage')\n",
    "        plt.title(f'{col} Distribution')\n",
    "        plt.show()\n",
    "\n",
    "        # Check if the column is imbalanced\n",
    "        minority_class = class_counts.index[-1]\n",
    "        minority_class_percentage = class_percentages.iloc[-1]\n",
    "        if minority_class_percentage < threshold:\n",
    "            print(f'{col} is imbalanced. Minority class: {minority_class}, Percentage: {minority_class_percentage:.2f}%')\n",
    "            return True\n",
    "\n",
    "    # If none of the specified columns are imbalanced, return False\n",
    "    print('No imbalance found.')\n",
    "    return False\n",
    "\n",
    "check_imbalance(X, columns=['target'], threshold=10) \n",
    "\n",
    "\n",
    "\n",
    "#OR\n",
    "\n",
    "# from yellowbrick.target import ClassBalance \n",
    "# # Instantiate the visualizer\n",
    "# visualizer = ClassBalance(labels=[\"draw\", \"loss\", \"win\"])\n",
    "# visualizer.fit(y_train, y_test)        # Fit the data to the visualizer (you can also use visualizer.fit(y))\n",
    "# visualizer.show()                       # Finalize and render the figure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../requirements.txt', 'r') as file:\n",
    "  loss=[] \n",
    "  for line in file:\n",
    "    if line.startswith('jupyter'):\n",
    "        loss.append(line.split('@')[0].strip())\n",
    "    #   loss.append(line.split('@ ')[1].strip())\n",
    "\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost\n",
    "import shap\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# train an XGBoost model\n",
    "X, y = load_iris(return_X_y=True, as_frame=True)\n",
    "model = xgboost.XGBRegressor().fit(X, y)\n",
    "\n",
    "# explain the model's predictions using SHAP\n",
    "# (same syntax works for LightGBM, CatBoost, scikit-learn, transformers, Spark, etc.)\n",
    "explainer = shap.Explainer(model)\n",
    "shap_values = explainer(X)\n",
    "\n",
    "# visualize the first prediction's explanation\n",
    "shap.plots.waterfall(shap_values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X, y = load_breast_cancer(return_X_y=True, as_frame=True)\n",
    "X, y = load_digits(return_X_y=True, as_frame=True)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state= 42)\n",
    "\n",
    "# Initialize KFold with 5 folds\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "\n",
    "def split_data(X, y, test_size=0.1, val_size=0.1):\n",
    "    \"\"\"\n",
    "    Split a dataset into training, validation, and test sets.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataset : array-like of shape (n_samples, n_features)\n",
    "        The input dataset.\n",
    "    test_size : float, optional\n",
    "        The proportion of the dataset to include in the test set.\n",
    "    val_size : float, optional\n",
    "        The proportion of the dataset to include in the validation set.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    X_train : array-like of shape (n_train_samples, n_features)\n",
    "        The training input samples.\n",
    "    X_val : array-like of shape (n_val_samples, n_features)\n",
    "        The validation input samples.\n",
    "    X_test : array-like of shape (n_test_samples, n_features)\n",
    "        The test input samples.\n",
    "    y_train : array-like of shape (n_train_samples,)\n",
    "        The target values (class labels) for the training input samples.\n",
    "    y_val : array-like of shape (n_val_samples,)\n",
    "        The target values (class labels) for the validation input samples.\n",
    "    y_test : array-like of shape (n_test_samples,)\n",
    "        The target values (class labels) for the test input samples.\n",
    "    \"\"\"\n",
    "    # Split the dataset into train and test sets\n",
    "    X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=test_size, random_state=42)\n",
    "\n",
    "    # Split the train set into train and validation sets\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=val_size/(1-test_size), random_state=42)\n",
    "\n",
    "    #show the shapes\n",
    "    print(X_train.shape, X_val.shape, X_test.shape, y_train.shape, y_val.shape, y_test.shape)\n",
    "    \n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test\n",
    "\n",
    "\n",
    "# Split the dataset into training, validation, and test sets\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = split_data(X, y) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#develop the model\n",
    "\n",
    "# Initialize Random Forest Classifier with 100 trees\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_val)\n",
    "y_pred_proba = clf.predict_proba(X_val)\n",
    "\n",
    "y_pred.shape, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the shape and values of the predicted class probabilities\n",
    "print(\"Shape of y_pred_proba:\", y_pred_proba.shape)\n",
    "print(\"Predicted class probabilities:\", y_pred_proba[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking for bias and variance \n",
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "\n",
    "def cv_bias_variance(model, X, y, cv):\n",
    "    scores = cross_val_score(model, X, y, cv=cv, n_jobs=-1, scoring='accuracy')   \n",
    "    train_error =  - scores.mean()\n",
    "    val_error = - scores.std()\n",
    "    return train_error, val_error, scores\n",
    "\n",
    "train_error, val_error, scores = cv_bias_variance(clf, X_train, y_train, cv)\n",
    "\n",
    "print(\"Mean training error:\", train_error)\n",
    "print(\"Mean validation error:\", val_error)\n",
    "\n",
    "\n",
    "train_sizes = np.linspace(0.1, 1, 10) \n",
    "def cv_learning_curve(model, X, y, cv, train_sizes):\n",
    "    train_sizes, train_scores, test_scores = learning_curve(model, X, y, cv=cv, n_jobs=-1, train_sizes=train_sizes, scoring='neg_mean_squared_error')\n",
    "    train_mean = np.mean(-train_scores, axis=1)\n",
    "    train_std = np.std(-train_scores, axis=1)\n",
    "    test_mean = np.mean(-test_scores, axis=1)\n",
    "    test_std = np.std(-test_scores, axis=1)\n",
    "    \n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.plot(train_sizes, train_mean, 'o-', color='blue', label='Training Error')\n",
    "    plt.plot(train_sizes, test_mean, 'o-', color='green', label='Validation Error')\n",
    "    plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, alpha=0.1, color='blue')\n",
    "    plt.fill_between(train_sizes, test_mean - test_std, test_mean + test_std, alpha=0.1, color='green')\n",
    "    plt.xlabel('Number of Training Examples')\n",
    "    plt.ylabel('Mean Squared Error')\n",
    "    plt.title('Learning Curve')\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()\n",
    "    \n",
    "    return train_sizes, train_mean, train_std, test_mean, test_std\n",
    "\n",
    "\n",
    "# Generate learning curve plot\n",
    "train_sizes, train_mean, train_std, test_mean, test_std = cv_learning_curve(clf, X_train, y_train, cv, train_sizes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_breast_cancer().target_names "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function plots a confusion matrix.\n",
    "    \"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    \n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    \n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    \n",
    "    for i, j in np.ndindex(cm.shape):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    \n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "\n",
    "plot_confusion_matrix(y_val, y_pred, classes=load_breast_cancer().target_names,\n",
    "                      title='Confusion matrix, Accuracy = {:.2f}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "def plot_roc(y_actual, y_pred):\n",
    "    \"\"\"\n",
    "    Function to plot AUC-ROC curve\n",
    "    \"\"\"\n",
    "    fpr, tpr, thresholds = roc_curve(y_actual, y_pred)\n",
    "    plt.plot(\n",
    "        fpr,\n",
    "        tpr,\n",
    "        color=\"b\",\n",
    "        label=r\"Model (AUC = %0.2f)\" % (roc_auc_score(y_actual, y_pred)),\n",
    "        lw=2,\n",
    "        alpha=0.8,\n",
    "    )\n",
    "    plt.plot(\n",
    "        [0, 1],\n",
    "        [0, 1],\n",
    "        linestyle=\"--\",\n",
    "        lw=2,\n",
    "        color=\"r\",\n",
    "        label=\"Luck (AUC = 0.5)\",\n",
    "        alpha=0.8,\n",
    "    )\n",
    "    plt.xlim([-0.05, 1.05])\n",
    "    plt.ylim([-0.05, 1.05])\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(\"Receiver operating characteristic example\")\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "    #To choose the threshold value that maximizes the Youden's J statistic\n",
    "    # calculate Youden's J statistic for each threshold value\n",
    "    J = tpr - fpr\n",
    "    best_threshold = thresholds[np.argmax(J)]\n",
    "    print('Best threshold:', best_threshold)\n",
    "plot_roc(y_val, y_pred) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_imbalance(dataset, columns=None, threshold=10):\n",
    "    \"\"\"\n",
    "    This function takes a dataset and one or more columns as input and returns True if any of the specified columns\n",
    "    are imbalanced, False otherwise. A column is considered imbalanced if the percentage of the minority class is less\n",
    "    than the specified threshold.\n",
    "    \"\"\"\n",
    "    # If no columns are specified, use all columns except for the last one as the features\n",
    "    if columns is None:\n",
    "        features = dataset.iloc[:, :-1]\n",
    "        columns = features.columns\n",
    "    \n",
    "    # Check the imbalance of each specified column\n",
    "    for col in columns:\n",
    "        # Get the counts of each class in the column\n",
    "        class_counts = dataset[col].value_counts()\n",
    "\n",
    "        # Calculate the percentage of each class in the column\n",
    "        class_percentages = class_counts / len(dataset) * 100\n",
    "\n",
    "        # Plot the class percentages\n",
    "        plt.bar(class_counts.index, class_percentages)\n",
    "        plt.xlabel(col)\n",
    "        plt.ylabel('Percentage')\n",
    "        plt.title(f'{col} Distribution')\n",
    "        plt.show()\n",
    "\n",
    "        # Check if the column is imbalanced\n",
    "        minority_class = class_counts.index[-1]\n",
    "        minority_class_percentage = class_percentages.iloc[-1]\n",
    "        if minority_class_percentage < threshold:\n",
    "            print(f'{col} is imbalanced. Minority class: {minority_class}, Percentage: {minority_class_percentage:.2f}%')\n",
    "            return True\n",
    "\n",
    "    # If none of the specified columns are imbalanced, return False\n",
    "    print('No imbalance found.')\n",
    "    return False\n",
    "\n",
    "check_imbalance(df, columns=['target'], threshold=10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "X,y = make_classification(n_samples=5000, n_features=20, n_classes=2, weights=[1,1], shuffle=True, random_state=1)\n",
    "\n",
    "feature_names = ['Feature_{}'.format(i) for i in range(X.shape[1])] # Create feature names\n",
    "\n",
    "X_train = pd.DataFrame(X, columns=feature_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = BaggingClassifier(RandomForestClassifier(), n_estimators=15, verbose=2, max_samples=1000, max_features=1)\n",
    "# clf = BaggingClassifier(DecisionTreeClassifier(), n_estimators=15, verbose=2, max_samples=1000, max_features=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf.fit(X_train, y)\n",
    "clf.fit(X, y)\n",
    "y_pred = clf.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier, StackingClassifier  \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Generate synthetic data\n",
    "X, y = make_classification(n_samples=1000, n_features=10, random_state=42)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a base classifier\n",
    "base_classifier_1 = RandomForestClassifier()\n",
    "base_classifier_2 = DecisionTreeClassifier()\n",
    "base_classifier_3 = LogisticRegression()\n",
    "\n",
    "# Create a BaggingClassifier with 15 base classifiers\n",
    "stacking_classifier = StackingClassifier(estimators=[('random forest', base_classifier_1), \n",
    "                                                     ('decision trees', base_classifier_2),\n",
    "                                                     ('logistic regression', base_classifier_3)], stack_method='predict', final_estimator=RandomForestClassifier())\n",
    "\n",
    "\n",
    "# Fit the BaggingClassifier to training data\n",
    "stacking_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Get predicted probabilities for training data\n",
    "y_pred_proba = stacking_classifier.predict(X_train)\n",
    "\n",
    "# Get predicted probabilities for testing data\n",
    "y_pred_proba_test = stacking_classifier.predict_proba(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.datasets import load_digits\n",
    "# X, y = load_digits(return_X_y=True, as_frame=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "X, y = load_breast_cancer(return_X_y=True, as_frame=True)\n",
    "\n",
    "print(X.shape)\n",
    "X.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of PCA with the desired number of components\n",
    "n_components = 20  # specify the number of components you want to retain\n",
    "pca = PCA(n_components=n_components)\n",
    "\n",
    "# Fit and transform the data to the reduced-dimensional space\n",
    "X_pca = pca.fit_transform(X)\n",
    "\n",
    "# X is your input data, a numpy array or a pandas DataFrame\n",
    "# X_pca contains the reduced-dimensional representation of the data after applying PCA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# sys.path(\"C://Program Files/\")\n",
    "\n",
    "import kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openml import datasets\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
