{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> Industries to focus on in Computer Vision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Healthcare & Medicine\n",
    "# Manufacturing\n",
    "# Aerospace & Defense\n",
    "# Automotive\n",
    "# Banking & Finance\n",
    "# Transportation\n",
    "# Oil & Gas\n",
    "# Retail & Ecommmerce\n",
    "# Safety & Security\n",
    "# Telecommunications\n",
    "# Utilities"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> Computer Vision Areas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use this link for code and video tutorials for all the models: https://roboflow.com/models/object-detection\n",
    "https://universe.roboflow.com/\t#roboflow pretrained models, computer vision projects and datasets\n",
    "\n",
    "#Images\n",
    "# 1. Image Classification (YOLOv(*), Vision Transformer, OpenAI CLip, MobileNet, EfficientNet ,ResNet, Inception, and VGGNet):\n",
    "    # Image classification involves assigning a label or category to an input image. \n",
    "    # The goal is to train a model that can accurately classify images into predefined classes\n",
    "\n",
    "# 2. Object Detection and Localization (YOLOv(*), YOLO-NAS, GroundingDINO, Detectron2, DETR, SSD, EfficientDet and Faster R-CNN):\n",
    "    # Object detection involves locating and classifying multiple objects within an image or video.\n",
    "    # The aim is to identify and draw bounding boxes around objects of interest in an image.\n",
    "\n",
    "# 3. Semantic Segmentation (SegFormer, U-Net, DeepLab, FCN):\n",
    "    # Semantic segmentation involves pixel-level classification, where each pixel in an image is assigned a class label.\n",
    "    # The objective is to partition an image into meaningful regions and assign a label to each pixel to understand the \n",
    "    #     scene's semantic meaning\n",
    "\n",
    "# 4. Instance Segmentation (DETIC, Segment ANything Model, Yolov(*), OneFormer,  ,Mask R-CNN, PointRend):\n",
    "    # Instance segmentation extends semantic segmentation by differentiating between individual instances of objects.\n",
    "    # It aims to detect and segment each instance separately, providing precise boundaries for each object within an image.\n",
    "\n",
    "# 5. Generative Adversarial Networks (GANs) (StyleGAN, CycleGAN, BigGAN, DCGAN, WGAN, BicycleGAN):\n",
    "    # StyleGAN: GAN architecture for high-quality image synthesis and control over the generated images' attributes.\n",
    "    # CycleGAN: Unpaired image-to-image translation model that learns mappings between different domains.\n",
    "    # BigGAN: Large-scale GAN architecture capable of generating high-resolution and diverse images.\n",
    "\n",
    "# Video Understanding:\n",
    "    # I3D (Inflated 3D ConvNet): 3D convolutional networks pre-trained on large video datasets for video classification and \n",
    "        # action recognition.\n",
    "    # SlowFast: A two-stream architecture with both slow and fast pathways to capture both temporal and spatial information \n",
    "        # in videos.\n",
    "    # C3D: 3D convolutional network designed for video analysis tasks like action recognition.\n",
    "\n",
    "\n",
    "#Videos\n",
    "# Video classification: Categorizing videos into different classes or categories based on their content or actions depicted.\n",
    "    # Models: Convolutional Neural Networks (CNNs), Recurrent Neural Networks (RNNs), \n",
    "        # 3D Convolutional Neural Networks (3D CNNs), I3D (Inflated 3D) Networks, C3D (Convolutional 3D) Networks\n",
    "    \n",
    "# Video object tracking: Tracking the movement of specific objects or regions of interest within a video sequence.\n",
    "    # Models: Single Object Tracking (SOT) models such as correlation filters (e.g., MOSSE, KCF), Siamese networks\n",
    "        # (e.g., SiamFC, SiamRPN), DeepSORT (Deep Learning based Single Object Tracking), \n",
    "        # ECO (Ensemble of Convolutional Networks), GOTURN (Generic Object Tracking using Regression Networks)\n",
    "    \n",
    "# Video summarization: Creating concise representations or summaries of long videos by selecting key frames or \n",
    "    # extracting important segments.\n",
    "    # Models: Keyframe extraction algorithms (e.g., Temporal Average, Sum-Product Networks), \n",
    "        # Video summarization using deep learning (e.g., SeqGAN, LSTM-based models), Shot boundary detection algorithms \n",
    "        # (e.g., Thresholding, Histogram-based approaches)\n",
    "    \n",
    "# Action recognition: Identifying and classifying human actions or activities performed in videos.\n",
    "    # Models: Two-stream Convolutional Networks, 3D Convolutional Neural Networks (3D CNNs), Temporal Convolutional Networks \n",
    "    # (TCNs), Recurrent Neural Networks (RNNs), Long Short-Term Memory (LSTM) networks, \n",
    "    # Convolutional LSTM (ConvLSTM) networks, I3D (Inflated 3D) Networks\n",
    "    \n",
    "# Video generation: Generating new videos or modifying existing ones using techniques like video interpolation or \n",
    "    # video synthesis.\n",
    "    # Models: Generative Adversarial Networks (GANs) (e.g., DCGAN, CycleGAN), Variational Autoencoders (VAEs), \n",
    "    # Recurrent Neural Networks (RNNs), Conditional GANs, Video prediction models (e.g., PredRNN, ConvLSTM), \n",
    "    # Video synthesis models (e.g., Vid2Vid, MoCoGAN)\n",
    "    \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> Pretrained Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch domain libraries\tor (https://pytorch.org/hub/)\n",
    "    torchvision.models, torchtext.models, torchaudio.models, torchrec.models\n",
    "# HuggingFace Hub\t\n",
    "    https://huggingface.co/models, https://huggingface.co/datasets\n",
    "# timm (PyTorch Image Models) \n",
    "    https://github.com/rwightman/pytorch-image-models\n",
    "# Paperswithcode\t\n",
    "    https://paperswithcode.com/\n",
    "#Roboflow pretrained models, computer vision projects and datasets\n",
    "    https://universe.roboflow.com/\t\n",
    "#Kaggle\n",
    "    https://www.kaggle.com/models\n",
    "# TensorFlow Hub\n",
    "    https://tfhub.dev/\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Introduction\n",
    "    # Tensors are the primary data structure in PyTorch and are similar to multi-dimensional arrays.\n",
    "    # They are the fundamental building blocks for deep learning models and computations.\n",
    "    # Tensors can be scalars (0-dimensional), vectors (1-dimensional), matrices (2-dimensional), or higher-dimensional arrays.\n",
    "\n",
    "%whos #check all the variables in the workspace (%who; %who_ls)\n",
    "\n",
    "#Creating Tensors:\n",
    "    # You can create tensors using various methods, such as:\n",
    "    torch.Tensor() #Creates an uninitialized tensor.    \n",
    "    torch.tensor() #Creates a tensor from existing data. i.e torch.tensor(array)\n",
    "    torch.zeros(), torch.ones() #Creates tensors of zeros or ones.\n",
    "    torch.rand(3,4), torch.randn(2,2) #Creates tensors with random values.\n",
    "    # You can specify the data type and device (CPU or GPU) while creating tensors.\n",
    "\n",
    "#Creating random tensors\n",
    "tensor = torch.randn(3, 4, 3)\n",
    "    # The first dimension represents the number of \"blocks\" or \"chunks.\" In this case, we have 3 blocks.\n",
    "    # The second dimension represents the number of rows within each block. Here, we have 4 rows.\n",
    "    # The third dimension represents the number of columns within each row. We have 3 columns.\n",
    "    \n",
    "tensor = torch.randn(3, 4, 3, 2)\n",
    "    # The first dimension represents the number of blocks or chunks. We have 3 blocks.\n",
    "    # The second dimension represents the number of rows within each block. Here, we have 4 rows.\n",
    "    # The third dimension represents the number of columns within each row. We have 3 columns.\n",
    "    # The fourth dimension represents the depth or the number of elements in each cell. Each cell has 2 elements.\n",
    "\n",
    "tensor = torch.randn([3, 4, 3, 2, 5])\n",
    "    # The first dimension represents the number of \"blocks\" or \"chunks.\" In this case, we have 3 blocks.\n",
    "    # The second dimension represents the number of rows within each block. Here, we have 4 rows.\n",
    "    # The third dimension represents the number of columns within each row. We have 3 columns.\n",
    "    # The fourth dimension represents the depth or the number of elements in each cell. Each cell has 2 elements.\n",
    "    # The fifth dimension represents the number of values within each element. Each element has 5 values.\n",
    "\n",
    "# Create a 2D tensor with random values from a uniform distribution between 0 and 1\n",
    "random_tensor = torch.rand(3, 4)\n",
    "# Create a 3D tensor with random values from a normal distribution\n",
    "random_tensor = torch.randn(2, 3, 4)\n",
    "# Create a random tensor with dtype=torch.float32 and allocate it on the GPU\n",
    "random_tensor = torch.randn(3, 4, dtype=torch.float32, device='cuda')\n",
    "# Create a random tensor with integer values between 0 and 9\n",
    "random_tensor = torch.randint(10, size=(3, 4))\n",
    "\n",
    "# Set the random seed\n",
    "torch.manual_seed(42)\n",
    "\n",
    "#convert numpy to tensor\n",
    "arr = np.array([10,23,23])\n",
    "arr = torch.tensor(arr)\n",
    "\n",
    "def set_seeds(seed=1234):\n",
    "    \"\"\"Set seeds for reproducibility.\"\"\"\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed) # multi-GPU\n",
    "\n",
    "# convert tensor to numpy\n",
    "tensor = torch.randint(10, size=(3, 3, 4))\n",
    "numpy_array = tensor.numpy()\n",
    "\n",
    "torch.zeros(3,4)    #create tensors with zeros\n",
    "torch.zeros_like(tensor)    #create tensors with zeros in the shape of tensor 'tensor'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensor Operations:\n",
    "\n",
    "# PyTorch provides a wide range of operations to manipulate tensors efficiently.\n",
    "# Element-wise operations: Addition, subtraction, multiplication, division, etc.\n",
    "# Reduction operations: Sum (torch.sum(a)), mean (torch.mean(a)), min, max, etc.\n",
    "# Matrix operations: Matrix multiplication (a @ b), dot product (torch.dot(a,b)), transpose (torch.transpose(a, 0, 1)), etc.\n",
    "# Indexing and slicing: Accessing specific elements or subsets of a tensor.\n",
    "# Broadcasting: Performing operations on tensors with different shapes.\n",
    "# Concatenation and stacking: Combining tensors along specified dimensions (torch.stack((a, b), dim=0 or 1); \n",
    "                                                                                # d = torch.cat((a, b.T), dim=1))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU Acceleration\n",
    "\n",
    "# PyTorch supports GPU acceleration, which enables faster computations on compatible hardware.\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU is available!\")\n",
    "else:\n",
    "    print(\"GPU is not available.\")\n",
    "        \n",
    "#Device-agnostic code (using PyTorch on CPU, GPU or MPS)\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda:0\" # NVIDIA GPU\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = \"mps:0\" # Apple GPU\n",
    "else:\n",
    "    device = \"cpu\" # Defaults to CPU if NVIDIA GPU/Apple GPU aren't available\n",
    "\n",
    "print(f\"Using device: {device}\")\n",
    "# You can move tensors to the GPU using .to(device) or .cuda() methods.\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu') # Checking GPU availability\n",
    "    x = torch.tensor([1, 2, 3]) # Creating a tensor\n",
    "    x = x.to(device)    # Moving the tensor to the GPU\n",
    "# Performing computations on the GPU can significantly speed up training deep learning models.\n",
    "    # Creating tensors on the GPU\n",
    "    a = torch.tensor([1, 2, 3], device=device)\n",
    "    b = torch.tensor([4, 5, 6], device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatic Differentiation:\n",
    "\n",
    "# PyTorch provides automatic differentiation, a powerful feature for training neural networks.\n",
    "# You can track the operations on tensors and compute gradients using the torch.autograd module.\n",
    "    # Creating a tensor with requires_grad=True\n",
    "    x = torch.tensor([2.0], requires_grad=True)\n",
    "# Gradients represent the derivative of a tensor with respect to another tensor.\n",
    "# Autograd allows you to compute gradients efficiently for backpropagation during training.\n",
    "\n",
    "\n",
    "\n",
    "#Torch provides a module, `autograd`, for automatically calculating the gradients of tensors. We can use it to \n",
    "# calculate the gradients of all our parameters with respect to the loss. Autograd works by keeping track of \n",
    "# operations performed on tensors, then going backwards through those operations, calculating gradients along the \n",
    "# way. To make sure PyTorch keeps track of operations on a tensor and calculates the gradients, you need to set \n",
    "# `requires_grad = True` on a tensor. You can do this at creation with the `requires_grad` keyword, or at any time \n",
    "# with `x.requires_grad_(True)`.\n",
    "x = torch.tensor([1.0, 2.0, 3.0], requires_grad=True)\n",
    "y = torch.tensor([4.0, 5.0, 6.0], requires_grad=True)\n",
    "z = x + y   # Perform operations\n",
    "output = torch.sum(z)\n",
    "#or\n",
    "x.requires_grad_(True)\n",
    "# Once you have computed the output tensor, you can call the backward() method on the output tensor to compute gradients\n",
    "output.backward()\n",
    "\n",
    "\n",
    "# You can turn off gradients for a block of code with the torch.no_grad()\n",
    ">>> with torch.no_grad():\n",
    "...     y = x * 2\n",
    ">>> y.requires_grad\n",
    "False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced Tensor Manipulation:\n",
    "\n",
    "# PyTorch offers advanced tensor manipulation techniques for complex operations.\n",
    "# Reshaping tensors: Changing the shape or size of a tensor using view(), reshape(), or unsqueeze().\n",
    "# Tensor concatenation and splitting: Combining or splitting tensors along specified dimensions.\n",
    "    torch.cat(), torch.stack(), and torch.split()\n",
    "# Element-wise functions: Applying mathematical functions to each element of a tensor.\n",
    "    torch.sin(), torch.cos(), torch.exp(), torch.log()\n",
    "# Advanced indexing: Using advanced indexing techniques to access or modify specific elements of a tensor.\n",
    "# Broadcasting with advanced shapes: Handling tensors with different shapes during operations."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your neural network architecture by creating a custom model class that inherits from torch.nn.Module.\n",
    "\n",
    "# In the __init__ method, define the layers of your model using PyTorch's nn module. \n",
    "# This includes defining linear layers, activation functions, pooling layers, etc.\n",
    "\n",
    "# Implement the forward method to define the forward pass of your model. This method describes how the input flows \n",
    "# through the layers to produce an output.\n",
    "\n",
    "# NB:\n",
    "# Trainable Parameters in deep learning: weights, and biases\n",
    "#non-trainable parameters in deep learning: Hyperparameters, and Pretrained parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive') \n",
    "\n",
    "#install libraries \n",
    "!pip install -q -r '/content/drive/MyDrive/Colab Notebooks/requirements.txt' \n",
    "\n",
    "\n",
    "#keep alive (right click 'inspect', then 'console', clear console and paste the below code)\n",
    "function ConnectButton(){\n",
    "    console.log(\"Connect pushed\"); \n",
    "    document.querySelector(\"#top-toolbar > colab-connect-button\").shadowRoot.querySelector(\"#connect\").click() \n",
    "}\n",
    "\n",
    "var colab = setInterval(ConnectButton,600000);   #to connect for 60 seconds\n",
    "\n",
    "#clearInterval(connect)     #to clear the keep alive interval\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.datasets import load_iris \n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import KFold, train_test_split \n",
    "\n",
    "#deep learning libraries \n",
    "import torch.nn.init as init \n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR \n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset \n",
    "import torchmetrics \n",
    "from torchsummary import summary \n",
    "import torchinfo"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">>Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using Sequential\n",
    "#Sequential API allows you to create a model by stacking layers on top of each other in a sequential manner\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "#A simple feed-forward neural network with two hidden layers\n",
    "\n",
    "# Define the model architecture \n",
    "model = nn.Sequential(\n",
    "    nn.Linear(in_features=784, out_features=64),  # First hidden layer\n",
    "    nn.ReLU(),                                    # Activation function\n",
    "    nn.Linear(in_features=64, out_features=32),   # Second hidden layer\n",
    "    nn.ReLU(),                                    # Activation function\n",
    "    nn.Linear(in_features=32, out_features=10)    # Output layer\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> Custom function (Module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class paul_model(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(paul_model, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim \n",
    "        \n",
    "        self.fct1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fct2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.soft1 = nn.Softmax(dim=1)\n",
    "        self.fct3 = nn.Linear(hidden_dim, output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.fct1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.fct2(x)\n",
    "        x = self.soft1(x)\n",
    "        x = self.fct3(x)\n",
    "        return x\n",
    "\n",
    "# Create an instance of the custom model\n",
    "input_dim = ...  # specify the input dimension\n",
    "hidden_dim = ...  # specify the hidden dimension\n",
    "output_dim = ...  # specify the output dimension\n",
    "model = paul_model(input_dim, hidden_dim, output_dim)\n",
    "\n",
    "# get output\n",
    "y_pred = model(X_train)\n",
    "\n",
    "model.state_dict()  #shows all the properties of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a custom function to define the model\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define a custom model class\n",
    "# Define your neural network architecture by creating a custom model class that inherits from torch.nn.Module.\n",
    "class MyModel(nn.Module):\n",
    "    \n",
    "    # In the __init__ method, define the layers of your model using PyTorch's nn module. \n",
    "    # This includes defining linear layers, activation functions, pooling layers, etc.\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)  #first hidden layer\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)   #second hidden layer\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(hidden_dim, output_dim)   #output layer\n",
    "\n",
    "# Implement the forward method to define the forward pass of your model. This method describes how the input flows \n",
    "# through the layers to produce an output.\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Create an instance of the custom model\n",
    "input_dim = ...  # specify the input dimension\n",
    "hidden_dim = ...  # specify the hidden dimension\n",
    "output_dim = ...  # specify the output dimension\n",
    "model = MyModel(input_dim, hidden_dim, output_dim)\n",
    "\n",
    "# get output\n",
    "y_pred = model(X_train)\n",
    "\n",
    "\n",
    "#Input features represents the number of features or variables in your input data\n",
    "#hidden features/dimensions represents the number of neurons in the hidden layers of your neural network\n",
    "#output dimension represents the number of neurons in the output layer of your neural network. \n",
    "    # If you have a multi-class classification problem with 10 classes, the output dimension would be 10\n",
    "    # In a regression dataset, the output dimension would typically be 1. This is because regression tasks \n",
    "        # involve predicting a continuous numerical value as the output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> Neural Networks and Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#asides the Linear and ReLu, we have other subclasses of nn.Module that can be used to define different layers \n",
    "# and operations in your neural network\n",
    "\n",
    "# Convolutional Layers:\n",
    "nn.Conv1d: #1D convolutional layer for processing sequential data (often used for text with a singular dimension).\n",
    "nn.Conv2d: #2D convolutional layer for processing images or spatial data (images with Height x Width dimensions).\n",
    "nn.Conv3d: #3D convolutional layer for processing volumetric data (often used for video with Height x Width x Time dimensions).\n",
    "    \n",
    "# Pooling Layers:\n",
    "nn.MaxPool1d: #1D max pooling layer \n",
    "nn.MaxPool2d: #2D max pooling layer\n",
    "nn.MaxPool3d: #3D max pooling layer\n",
    "nn.AvgPool1d: #1D average pooling layer\n",
    "nn.AvgPool2d: #2D average pooling layer\n",
    "nn.AvgPool3d: #3D average pooling layer.\n",
    "    \n",
    "# Recurrent Layers:\n",
    "nn.RNN: #Basic RNN layer.\n",
    "nn.LSTM: #LSTM layer.\n",
    "    nn.LSTMCell()   #create a single LSTM cell\n",
    "    nn.LSTM()   #stac together LSTM cells\n",
    "nn.GRU: #GRU layer.\n",
    "    nn.GRUCell()   #create a single GRU cell\n",
    "    nn.GRU()   #stac together GRU cells\n",
    "\n",
    "# Normalization Layers:\n",
    "nn.BatchNorm1d: #Batch normalization layer for 1D inputs.\n",
    "nn.BatchNorm2d: #Batch normalization layer for 2D inputs.\n",
    "nn.BatchNorm3d: #Batch normalization layer for 3D inputs.\n",
    "\n",
    "# Dropout and Regularization:\n",
    "nn.Dropout: #Dropout layer for regularization.\n",
    "nn.Dropout2d: #2D dropout layer.\n",
    "nn.Dropout3d: #3D dropout layer.\n",
    "\n",
    "# Activation Functions:\n",
    "nn.Sigmoid: #Sigmoid activation function.\n",
    "nn.Tanh: #Hyperbolic tangent activation function.\n",
    "nn.Softmax: #Softmax activation function.\n",
    "nn.LeakyReLU: #Leaky ReLU activation function. \n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#an example \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Preprocess the data\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert the data to PyTorch tensors\n",
    "X_train = torch.Tensor(X_train)\n",
    "y_train = torch.LongTensor(y_train)\n",
    "\n",
    "# Define the custom model\n",
    "class CustomModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(CustomModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "# Set the dimensions for the input, hidden, and output layers\n",
    "input_dim = X_train.shape[1]\n",
    "hidden_dim = 16\n",
    "output_dim = 3\n",
    "\n",
    "# Create an instance of the custom model\n",
    "model = CustomModel(input_dim, hidden_dim, output_dim)\n",
    "model.train()\n",
    "outputs = model(X_train) #\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> Activation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sigmoid Function (nn.Sigmoid() or F.sigmoid())\n",
    "    # Range: (0, 1)\n",
    "    # Smooth, continuously differentiable function\n",
    "    # Used for 'binary classification' problems or when the output needs to be in the range of probabilities.\n",
    "    sigmoid_act = nn.Sigmoid()  #output = sigmoid_act(x)\n",
    "    output = F.sigmoid(x)\n",
    "\n",
    "# ReLU (Rectified Linear Unit) Function (nn.ReLU() or F.relu()) \n",
    "    # Range: [0, +∞)\n",
    "    # Simple and computationally efficient activation function\n",
    "    # Commonly used as a default choice for most deep learning models. often used for most hidden layers\n",
    "    relu = nn.ReLU()    #output = relu(x)\n",
    "    output = F.relu(x)\n",
    "\n",
    "# Leaky ReLU Function (nn.LeakyReLU() or F.leaky_relu())\n",
    "    # Range: (-∞, +∞)\n",
    "    # Similar to ReLU but allows small negative values for negative inputs\n",
    "    # Helps prevent \"dying ReLU\" problem by allowing a small gradient for negative inputs.\n",
    "    leaky_relu = nn.LeakyReLU(0.2)  # Set the negative slope.    output = leaky_relu(x)\n",
    "    output = F.leaky_relu(x, negative_slope=0.2)  # Set the negative slope\n",
    "\n",
    "# Tanh Function (nn.Tanh() or F.tanh())     - Hyperbolic tangent (tanh)\n",
    "    # Range: (-1, 1)\n",
    "    # S-shaped activation function that maps values between -1 and 1\n",
    "    # Used in some models as an alternative to sigmoid function.\n",
    "    tanh = nn.Tanh()    #output = tanh(x)\n",
    "    output = F.tanh(x)\n",
    "\n",
    "#Softmax Function (nn.Softmax(dim=) or F.softmax(dim=))\n",
    "    # Converts a vector of arbitrary real values into a probability distribution\n",
    "    # Typically used in the output layer for multi-class classification problems.\n",
    "    softmax = nn.Softmax(dim=1)  # Set the appropriate dimension\n",
    "    output = F.softmax(x, dim=1)  # Set the appropriate dimension\n",
    "    \n",
    "    #ln-softmax works fine on problems with a 'small number' of categories, \n",
    "    # or when categories are easily differentiable. But when categories are large, use log_softmax()\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> Hyperparameters/Metaparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some common hyperparameters/metaparameters in deep learning include:\n",
    "\n",
    "#Model architecture:\n",
    "    # Determines the overall structure and complexity of the neural network.\n",
    "\n",
    "# Learning rate: \n",
    "    # Determines the step size during gradient descent optimization and affects the convergence speed \n",
    "    # and accuracy of the model.\n",
    "\n",
    "# Number of hidden layers:  \n",
    "    # Determines the depth of the neural network architecture and influences the model's capacity to learn complex \n",
    "    # patterns.\n",
    "\n",
    "# Number of neurons per layer: \n",
    "    # Defines the width of the neural network architecture and affects the model's representational capacity and \n",
    "    # computational efficiency.\n",
    "\n",
    "# Activation functions: \n",
    "    # Determines the non-linear transformation applied to the output of each neuron, introducing non-linearity into \n",
    "    # the model.\n",
    "\n",
    "# Dropout rate: \n",
    "    # Controls the regularization technique of randomly dropping out a fraction of neurons during training, which\n",
    "    # helps prevent overfitting. \n",
    "\n",
    "# Batch size: \n",
    "    # Specifies the number of training samples propagated through the network before updating the model's weights.\n",
    "\n",
    "# Number of epochs: \n",
    "    # Specifies the number of times the entire training dataset is passed through the model during training.\n",
    "\n",
    "# Regularization techniques: \n",
    "    # Include methods like L1 and L2 regularization, which help prevent overfitting by adding penalties to the \n",
    "    # loss function. \n",
    "\n",
    "# Optimizer: \n",
    "    # Specifies the optimization algorithm used to update the model's weights during training, such as \n",
    "    # Stochastic Gradient Descent (SGD), Adam, or RMSprop.\n",
    "\n",
    "# Loss function: \n",
    "    # Defines the objective function used to measure the discrepancy between the predicted output and the \n",
    "    # true output during training.\n",
    "\n",
    "# Cross-validation sizes:\n",
    "    # Determines the size of the data splits used in cross-validation.\n",
    "\n",
    "# Weight and Data Normalization:\n",
    "    # Techniques like min-max normalization and z-score scaling to normalize the weights and input dat\n",
    "    \n",
    "# Weight Initialization:\n",
    "    # Defines the initial values of the weights in the neural network."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> Model Info/summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary \n",
    "\n",
    "model = ConvNet() #define your model\n",
    "summary(model, ( 28, 28))   #input tensor of size (28, 28) \n",
    "\n",
    "\n",
    "# Get the trainable parameters\n",
    "trainable_params = model.parameters()\n",
    "\n",
    "# Get the non-trainable parameters\n",
    "non_trainable_params = [p for p in model.parameters() if not p.requires_grad]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regularization is a technique used in deep learning to prevent overfitting and improve the generalization ability \n",
    "# of the model.\n",
    "\n",
    "# Node Regularization: Modify the model (dropout)\n",
    "# Loss Regularization: Add a cost to the loss function (L1/2)\n",
    "# Data Regularization: Modify or add data (batch training, data augmentation, normalization) \n",
    "\n",
    "\n",
    "# L2 Regularization (Weight Decay):\n",
    "    # L2 regularization, also known as weight decay, adds a penalty term to the loss function that discourages large \n",
    "    # weights in the model.\n",
    "    # It helps prevent overfitting by encouraging the model to use smaller weights, effectively reducing the \n",
    "    # complexity of the model.\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.01, weight_decay=0.001)#Define the optimizer with weight decay\n",
    "\n",
    "# Dropout:\n",
    "    # Dropout is a regularization technique that randomly sets a fraction of the input units (nodes) to 0 during training.\n",
    "    # It helps prevent overfitting by introducing noise and reducing the interdependence of neurons.\n",
    "    #dropout is not a good idea for simple models or small data. \n",
    "    class MyModel(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(MyModel, self).__init__()\n",
    "            self.fc1 = nn.Linear(64, 128)\n",
    "            self.dropout = nn.Dropout(0.5)\n",
    "            self.fc2 = nn.Linear(128, 10)\n",
    "        \n",
    "        def forward(self, x):\n",
    "            x = self.fc1(x)\n",
    "            x = self.dropout(x)  # Apply Dropout\n",
    "            x = torch.relu(x)\n",
    "            x = self.fc2(x)\n",
    "            return x \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> Weight Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#key points for weight initialization:\n",
    "    # Weights should be small\n",
    "    # Weights should not be the same\n",
    "    # Weights should have good variance\n",
    "    \n",
    "\n",
    "#to Visualise the weights and ensure that they meet all three requirements: (Use a Histogram)\n",
    "def get_layers(model):\n",
    "  \"\"\"Gets a list of all the layers in a model.\"\"\"\n",
    "  layers = []\n",
    "  for name, _ in model.named_modules():\n",
    "    if '.' in name:\n",
    "      if 'dropout' not in name:\n",
    "        layers.append(name.split('.')[1])\n",
    "  return layers\n",
    "\n",
    "def plot_weights(model):\n",
    "  \"\"\"Plots the weights of all the layers in a model.\"\"\"\n",
    "  layers = get_layers(model)\n",
    "  for i in layers:\n",
    "    weight_i = model.layers[i].weight.detach()\n",
    "    plt.hist(weight_i, bins=30, edgecolor='black')\n",
    "    plt.title(f'Weight Initialization - {i}')\n",
    "    plt.xlabel('Weight Values')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.show()\n",
    "\n",
    "  # Plot the weights\n",
    "plot_weights(model=model)\n",
    "\n",
    "\n",
    "#another way to initialize weights:\n",
    "for p in model.named_parameters():\n",
    "  if 'weight' in p[0]:\n",
    "    nn.init.xavier_uniform_(p[1].data) \n",
    "\n",
    "\n",
    "#Pytorch Default weight initializations: \n",
    "\n",
    "# Linear and Convolutional Layers:\n",
    "# PyTorch uses the Kaiming (He) (nn.init.kaiming_uniform) initialization as the default for these layers.\n",
    "# Kaiming initialization (nn.init.kaiming_normal) initializes the weights with a normal distribution scaled by the square root of 2 divided by \n",
    "# the fan-in (number of input units).\n",
    "\n",
    "# Recurrent Layers: \n",
    "# PyTorch uses the orthogonal initialization as the default for recurrent layers, such as LSTM or GRU. \n",
    "# Orthogonal initialization initializes the recurrent weights as orthogonal matrices. \n",
    "\n",
    "# Batch Normalization Layers:\n",
    "# PyTorch uses the uniform initialization with a mean of 0 and variance of 1 for the learnable scaling factor.\n",
    "# The bias term is initialized to zero by default.\n",
    "\n",
    "# Other Layers:\n",
    "# For other types of layers, such as activation layers (ReLU, Sigmoid, etc.), PyTorch does not apply any specific\n",
    "# default initialization. The default initialization for these layers is typically random or zero initialization."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> Model Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Help\n",
    "help(nn.Module) #or help(nn.Linear)\n",
    "\n",
    "#Weights and Biases of each layer:\n",
    "model.layers.input_bn.weight    #replace input_bn with the name of the desired layer (model.fc1.weight) \n",
    "model.layers.input_bn.bias      #replace input_bn with the name of the desired layer\n",
    "for module in model.modules():   #to get the shape of the weights \n",
    "    if hasattr(module, 'weight'):\n",
    "        print(module.weight.shape)\n",
    "\n",
    "# model.parameters(): This function returns an iterator over all the learnable parameters of the model. \n",
    "    # It is typically used when defining the optimizer to specify which parameters should be updated during training\n",
    "for param in model.parameters(): #for name, param in model.named_parameters(): #for both parameter name and tensor\n",
    "    print(param)\n",
    "#or \n",
    "# Print the weights of trainable parameters\n",
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, param.data)\n",
    "        \n",
    "# model.children(): This function returns an iterator over the immediate child modules of the model. It can be used, \n",
    "        # for example, to access and modify specific layers or modules within the model.\n",
    "for child in model.children():  #for name, child in model.named_children(): for both the child name and the module\n",
    "    print(child)\n",
    "\n",
    "#visualize weight initialization\n",
    "layers = [name.split('.')[1] for name, _ in model.named_modules() if '.' in name if 'dropout' not in name]\n",
    "for i in layers:\n",
    "  weight_i = model.layers[i].weight.detach()\n",
    "  # print(weight_i)\n",
    "  plt.hist(weight_i, bins=30, edgecolor='black')\n",
    "  plt.title(f'Weight Initialization - {i}')\n",
    "  plt.xlabel('Weight Values')\n",
    "  plt.ylabel('Frequency')\n",
    "  plt.show()\n",
    "\n",
    "# model.state_dict(): This function returns a dictionary containing the model's state, including the learnable \n",
    "        # parameters and buffers. It is commonly used for saving and loading model checkpoints.\n",
    "state_dict = model.state_dict()\n",
    "torch.save(state_dict, 'model_checkpoint.pth')\n",
    "\n",
    "# model.load_state_dict(): This method loads a state dictionary into the model, restoring the model's parameters \n",
    "        # and buffers from a saved checkpoint\n",
    "state_dict = torch.load('model_checkpoint.pth')\n",
    "model.load_state_dict(state_dict)\n",
    "\n",
    "model.eval()    #sets the model to evaluation mode\n",
    "model.train()   #sets the model to training mode\n",
    "model.freeze()  #freezes all the parameters in the model, making them not trainable\n",
    "model.unfreeze()    #unfreezes all the parameters in the model, making them trainable\n",
    "model.fc1.weight.requires_grad = False  #freezes the weights of a specific layer\n",
    "model.fc1.bias.requires_grad = False    #freezes the bias of a specific layer\n",
    "for param in model.named_parameters():    #freezes all the layers except input\n",
    "    if 'input' not in param[0]:\n",
    "        param[1].requires_grad = False \n",
    "    \n",
    "#counting the number of parameters in the model:\n",
    "total_params = sum(p.numel() for p in model.parameters()) #.numel() is number of elements.\n",
    "print(f\"Total parameters: {total_params}\")\n",
    "\n",
    "#Visualizing model architectures:\n",
    "from torchsummary import summary \n",
    "summary(model, input_size = ( 28, 28))   # Print a summary of the model architecture\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "\n",
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Load datasets and apply transformations\n",
    "train_dataset = torchvision.datasets.ImageFolder(root='train_data/', transform=transform)\n",
    "test_dataset = torchvision.datasets.ImageFolder(root='test_data/', transform=transform)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True, drop_last = False)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False, drop_last = False)\n",
    "                                        #drop_last wil drop the last batch if its not the same size as the rest"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> ANN Data (Use this)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "inputs = data[:,:-1]\n",
    "labels = data[:,-1]\n",
    "\n",
    "# train, test = torch.utils.data.random_split(train_dataset, [800, 200]) #train/test split \n",
    "X_train, X_test, y_train, y_test = train_test_split(inputs, labels, random_state=23, train_size=0.9)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "\n",
    "# inputs \n",
    "X_train = torch.tensor(np.array(X_train), dtype=torch.float32)\n",
    "X_test = torch.tensor(np.array(X_test), dtype=torch.float32)\n",
    "y_train = torch.tensor(np.array(y_train), dtype=torch.long)\n",
    "y_test = torch.tensor(np.array(y_test), dtype=torch.long)\n",
    "\n",
    "#dataset \n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "\n",
    "#dataloader\n",
    "batch_size = 32\n",
    "shuffle = True\n",
    "drop_last = True\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=shuffle, drop_last=drop_last)\n",
    "test_dataloader = DataLoader(test_dataset, shuffle = False, batch_size=test_dataset.tensors[0].shape[0]) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "\n",
    "# From DataFrame  \n",
    "df = pd.read_csv('your_dataset.csv') #inputs, targets = load_iris(return_X_y = True, as_frame = True)\n",
    "\n",
    "# Extract the input features and target labels from the DataFrame\n",
    "inputs = df[['feature1', 'feature2', ...]].values\n",
    "targets = df['target'].values\n",
    "\n",
    "\n",
    "\n",
    "# Convert the data to PyTorch tensors\n",
    "inputs = torch.tensor(inputs, dtype=torch.float32, #use float for input data, and long for labels. \n",
    "                    device=None,    #can use 'cpu', or 'cuda'\n",
    "                    requires_grad=True) #or False\n",
    "targets = torch.tensor(targets, dtype=torch.long)   #or LongTensor for cuda\n",
    "\n",
    "# Create a TensorDataset\n",
    "dataset = TensorDataset(inputs, targets) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loaders in deep learning are utility classes or functions that help in efficiently loading and \n",
    "# processing training, validation, and testing data. They are an essential component of training deep learning models \n",
    "# and provide several benefits such as Data Batching, Data Shuffling, Data Augmentation, Data Transformation, \n",
    "# Efficient Memory Management, Parallel Data Loading.\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True) # Load the training data\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True) #data loader \n",
    "                        # are used to move the input data and labels to a specified device (e.g., CPU or GPU) for computation\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> Other ways to load data (torchvision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision \n",
    "from torchvision import datasets \n",
    "from torchvision.datasets import DatasetFolder\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Define the transformation to apply to the images\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize images to a fixed size\n",
    "    transforms.ToTensor(),          # Convert images to tensors\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize image tensors\n",
    "])\n",
    "\n",
    "#1. Using ImageFolder\n",
    "# Load the dataset from the image folders\n",
    "dataset = torchvision.datasets.ImageFolder(root='Dataset/', transform=transform)\n",
    "class_labels = dataset.classes # Get the class labels\n",
    "print(class_labels) # Print the class labels\n",
    "\n",
    "\n",
    "#2. Using a DatasetFolder\n",
    "# Create an instance of the DatasetFolder\n",
    "dataset = torchvision.datasets.DatasetFolder(\n",
    "                            root='Dataset/',\n",
    "                            loader=torchvision.datasets.folder.default_loader,  # Use the default image loader\n",
    "                            extensions=\".jpg\",  # Specify the file extensions of the images\n",
    "                            transform=transform  # Apply the defined transformation pipeline\n",
    "                        )\n",
    "\n",
    "#3. Built-in Datasets \n",
    "# Load the CIFAR-10 dataset\n",
    "train_dataset = datasets.CIFAR10(root='./data', train=True, download=True)\n",
    "test_dataset = datasets.CIFAR10(root='./data', train=False, download=True)\n",
    "\n",
    "\n",
    "#4. Custom Dataset\n",
    "from torch.utils.data import Dataset\n",
    "# torch.utils.data.Dataset is an abstract class representing a dataset. Your custom dataset should inherit Dataset \n",
    "# and override the following methods:\n",
    "    # __len__ so that len(dataset) returns the size of the dataset.\n",
    "    # __getitem__ to support the indexing such that dataset[i] can be used to get ith sample.\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, targets, transform=None):\n",
    "        #initialise the model\n",
    "        self.data = data\n",
    "        self.targets = targets\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        # Return the total number of samples in the dataset\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Retrieve and preprocess a single sample from the dataset\n",
    "        sample = self.data[index]\n",
    "        target = self.targets[index]\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample, target\n",
    "\n",
    "\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.data = pd.read_csv(csv_file)  # Read the CSV file\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.data.iloc[idx, 0]  # Get the image file name from the CSV\n",
    "        img_path = os.path.join(self.root_dir, img_name)\n",
    "        image = Image.open(img_path).convert('RGB')  # Open and convert the image to RGB\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)  # Apply transformations if provided\n",
    "\n",
    "        label = self.data.iloc[idx, 1]  # Get the corresponding label from the CSV\n",
    "\n",
    "        return image, label\n",
    "\n",
    "face_dataset = CustomImageDataset(csv_file='data/faces/face_landmarks.csv',\n",
    "                                    root_dir='data/faces/')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> Data Transforms / Image Processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "\n",
    "#Compose: used to chain multiple image transforms together in a sequence\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor()\n",
    "            ])\n",
    "\n",
    "# Here are some commonly used data augmentation techniques for images using PyTorch:\n",
    "\n",
    "# Resizing and Cropping:\n",
    "    Resize: #Resize the image to a specified size.\n",
    "    RandomResizedCrop: #Crop and resize the image to a random size and aspect ratio.\n",
    "    CenterCrop: #Crop the center portion of the image.\n",
    "    RandomCrop: #Randomly crops the input PIL image\n",
    "\n",
    "# Flipping and Rotation:\n",
    "    RandomHorizontalFlip: #Flip the image horizontally with a specified probability.\n",
    "    RandomVerticalFlip: #Flip the image vertically with a specified probability.\n",
    "    RandomRotation: #Rotate the image by a random angle within a specified range.\n",
    "\n",
    "# Color and Lighting:\n",
    "    ColorJitter: #Adjust the brightness, contrast, saturation, and hue of the image randomly.\n",
    "    RandomGrayscale: #Convert the image to grayscale with a specified probability.\n",
    "    RandomPosterize: #Apply random posterization to the image.\n",
    "\n",
    "# Noise and Blur:\n",
    "    RandomNoise: #Add random noise to the image.\n",
    "    GaussianBlur: #Apply Gaussian blur to the image with a specified kernel size.\n",
    "\n",
    "# Tensor Conversions and Normalization:\n",
    "    ToTensor: #Convert the image to a PyTorch tensor. \n",
    "    Normalize: #Normalize the image by subtracting mean and dividing by standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn.functional as F \n",
    "import torchvision.transforms.functional as TF \n",
    "# Here are some commonly used operations in image processing:\n",
    "\n",
    "# Image Filtering:\n",
    "    # Convolution: Applying a kernel or filter to an image to perform operations such as blurring, sharpening, \n",
    "        # edge detection, or noise reduction.\n",
    "    # Gaussian Filtering: Applying a Gaussian filter to blur an image and reduce noise.\n",
    "        input_image = torch.randn(1, 3, 256, 256)  # Assuming input image dimensions are 256x256\n",
    "        blurred_image = F.gaussian_blur(input_image, kernel_size=5, sigma=1.0)\n",
    "        print(blurred_image.shape) \n",
    "    # Median Filtering: Replacing each pixel value with the median value of its neighborhood to reduce salt-and-pepper noise.\n",
    "    \n",
    "\n",
    "# Image Enhancement:\n",
    "    # Histogram Equalization: Adjusting the pixel intensity distribution to enhance contrast and improve the visual \n",
    "        # appearance of an image.\n",
    "        input_image = torch.randn(1, 1, 256, 256)  # Assuming input image dimensions are 256x256\n",
    "        equalized_image = TF.equalize(input_image)\n",
    "        print(equalized_image.shape)\n",
    "    # Contrast Stretching: Expanding the pixel intensity range to increase the contrast of an image.\n",
    "        stretched_image = TF.adjust_contrast(input_image, contrast_factor=2.0)\n",
    "        print(stretched_image.shape)\n",
    "    # Gamma Correction: Adjusting the gamma value to correct the brightness and improve image quality.\n",
    "\n",
    "\n",
    "# Image Transformation:\n",
    "    # Scaling: Resizing an image to a desired size.\n",
    "    # Rotation: Rotating an image by a specified angle.\n",
    "    # Translation: Shifting an image horizontally or vertically.\n",
    "        translated_image = TF.affine(input_image, angle=0, translate=(50, 50), scale=1.0, shear=0)\n",
    "\n",
    "\n",
    "# Color Manipulation:\n",
    "    # Color Conversion: Converting an image from one color space to another, such as RGB to grayscale or RGB to HSV.\n",
    "    # Color Quantization: Reducing the number of colors in an image.\n",
    "    # Color Balancing: Adjusting the color balance to correct color cast or enhance specific color components.\n",
    "\n",
    "\n",
    "# Image Segmentation:\n",
    "    # Thresholding: Dividing an image into regions based on pixel intensity values.\n",
    "    # Edge Detection: Detecting edges or boundaries of objects in an image.\n",
    "    # Region Growing: Grouping pixels based on similarities in intensity or texture.\n",
    "\n",
    "\n",
    "# Morphological Operations:\n",
    "    # Erosion: Shrinking or eroding regions in an image.\n",
    "    # Dilation: Expanding or dilating regions in an image.\n",
    "    # Opening: Erosion followed by dilation, used to remove noise or small objects.\n",
    "    # Closing: Dilation followed by erosion, used to close gaps or fill holes in objects.\n",
    "\n",
    "\n",
    "# Feature Extraction:\n",
    "    # Corner Detection: Identifying and locating corners or interest points in an image.\n",
    "    # Blob Detection: Detecting regions of interest with similar properties, such as size, color, or texture.\n",
    "    # Edge Extraction: Extracting edges or contours of objects in an image.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a data loader\n",
    "batch_size = 32\n",
    "shuffle = True\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle, drop_last = False)\n",
    "\n",
    "#visualize the data in dataloader\n",
    "for inputs, labels in dataloader:\n",
    "    print(\"Inputs:\", inputs) \n",
    "    print(\"Labels:\", labels)\n",
    "    print()\n",
    "#or\n",
    "data_list = list(dataloader)\n",
    "print(data_list)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> Feature Scaling (Normalization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalization techniques are used to preprocess the input data in order to improve the training process and the \n",
    "# overall performance of deep learning models.\n",
    "\n",
    "#It is always a good idea to perform both data normalization (i.e z-score, minmax, T.ToTensor() etc.) and batch normalization. \n",
    "#However, transforming to data using (transforms.ToTensor()) automatically normalizes it to a range of (0-1)\n",
    "\n",
    "# Batch Normalization:\n",
    "    # Batch Normalization is a technique that normalizes the inputs within each mini-batch during training.\n",
    "    #i.e It normalizes the activations within a mini-batch during training by adjusting the mean and standard deviation\n",
    "    # It helps stabilize and accelerate the training process by reducing internal covariate shift.\n",
    "    # should only be applied during training - use model.eval()\n",
    "    class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(64, 128)\n",
    "        self.bn1 = nn.BatchNorm1d(128)  # Batch Normalization\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.bn1(x)  # Apply Batch Normalization\n",
    "        x = torch.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x    \n",
    "    #  Batch Normalization requires a specified input size (e.g., nn.BatchNorm1d for 1D inputs, \n",
    "    # nn.BatchNorm2d for 2D inputs) depending on the dimensionality of the data\n",
    "\n",
    "\n",
    "#Layer Normalization:\n",
    "    # Layer Normalization is a technique that normalizes the inputs within each layer across the feature dimension.\n",
    "    # It helps improve the generalization ability of models and performs well on tasks with recurrent neural \n",
    "    # networks (RNNs).\n",
    "    class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(64, 128)\n",
    "        self.ln1 = nn.LayerNorm(128)  # Layer Normalization\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.ln1(x)  # Apply Layer Normalization\n",
    "        x = torch.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x    \n",
    "    # Layer Normalization normalizes across the feature dimension, so it doesn't require a specific input size\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Noise data Augmentation\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim \n",
    "import torch.nn.functional as F \n",
    "import torchvision.transforms.functional as TF\n",
    "\n",
    "def add_guassian_noise_to_dataset(dataset, mean=0, std=0.1):\n",
    "    \"\"\"\n",
    "    Adds random Gaussian noise to an image dataset.\n",
    "\n",
    "    Args:\n",
    "        dataset (torch.utils.data.Dataset): The image dataset.\n",
    "        mean (float): Mean of the Gaussian noise (default: 0).\n",
    "        std (float): Standard deviation of the Gaussian noise (default: 0.1).\n",
    "\n",
    "    Returns:\n",
    "        torch.utils.data.Dataset: The noisy image dataset.\n",
    "    \"\"\"\n",
    "    noisy_dataset = []\n",
    "    \n",
    "    for image, label in dataset:\n",
    "        # Convert the image to a tensor\n",
    "        tensor = TF.to_tensor(image)\n",
    "\n",
    "        # Generate random noise with the same shape as the image tensor\n",
    "        noise = torch.randn_like(tensor) * std + mean\n",
    "\n",
    "        # Add the noise to the image tensor\n",
    "        noisy_tensor = tensor + noise\n",
    "\n",
    "        # Convert the noisy tensor back to an image\n",
    "        noisy_image = TF.to_pil_image(noisy_tensor)\n",
    "\n",
    "        # Append the noisy image and label to the noisy dataset\n",
    "        noisy_dataset.append((noisy_image, label))\n",
    "    \n",
    "    concatenated_dataset = torch.utils.data.ConcatDataset([dataset, *noisy_dataset])\n",
    "    \n",
    "    return concatenated_dataset \n",
    "\n",
    "\n",
    "\n",
    "def add_uniform_noise(dataset, low=-0.1, high=0.1):     #always use this so that you can adjust the low and high\n",
    "    noisy_dataset = []    \n",
    "    for image, label in dataset:\n",
    "        tensor = TF.to_tensor(image)\n",
    "        noise = torch.empty_like(tensor).uniform_(low, high)\n",
    "        noisy_tensor = tensor + noise\n",
    "        noisy_image = TF.to_pil_image(noisy_tensor)\n",
    "        \n",
    "        # Append the noisy image and label to the noisy dataset\n",
    "        noisy_dataset.append((noisy_image, label))\n",
    "    \n",
    "    concatenated_dataset = torch.utils.data.ConcatDataset([dataset, *noisy_dataset])\n",
    "    return concatenated_dataset \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss Function: \n",
    "    # Choose an appropriate loss function based on the problem you are solving. Common loss functions include \n",
    "        # mean squared error (MSE), binary cross-entropy, or categorical cross-entropy, depending on the task.\n",
    "    # Create an instance of the chosen loss function from torch.nn module.\n",
    "\n",
    "# Optimizer:\n",
    "    # Select an optimizer that will update the model's parameters during training. Popular choices include \n",
    "        # Stochastic Gradient Descent (SGD), Adam, or RMSprop.\n",
    "    # Initialize the optimizer by passing the model parameters and setting the learning rate and other hyperparameters.\n",
    "    \n",
    "# Training Loop:\n",
    "    # Iterate over the training dataset in batches.\n",
    "    # Zero the gradients of the model parameters to avoid accumulation.\n",
    "    # Pass the input batch through the model to obtain predictions.\n",
    "    # Calculate the loss between the predictions and the target values.\n",
    "    # Backpropagate the gradients by calling backward() on the loss tensor.\n",
    "    # Update the model parameters using the optimizer's step() function.\n",
    "    # Optionally, track and record metrics like accuracy or loss during training.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss function\n",
    "\n",
    "#Regression \n",
    "loss_function = nn.MSELoss()  # Mean Squared Error loss: It is widely used in regression problems \n",
    "loss_function = nn.L1Loss() #Mean Absolute Error (MAE): It is often used in regression problems\n",
    "loss_function = nn.SmoothL1Loss() #Huber Loss: A robust loss function for regression problems that combines properties \n",
    "                                    #of both MSE and MAE. \n",
    "                                    \n",
    "#Classification \n",
    "loss_function = nn.CrossEntropyLoss( )  #Cross-Entropy Loss: It is commonly used in multi-class classification problems\n",
    "loss_function = nn.NLLLoss() #Negative log likelihood (NLL) loss: commonly used in multi-class classification problems\n",
    "            #The NLL loss is often used in combination with the nn.LogSoftmax() activation function for multi-class \n",
    "            # classification tasks.\n",
    "loss_function = nn.BCELoss() #Binary Cross-Entropy Loss: used in binary classification tasks, where the model's output \n",
    "                                #consists of probabilities instead of logits.\n",
    "loss_function = nn.BCEWithLogitsLoss() #Binary Cross-Entropy (BCE) Loss: It is commonly used in binary classification \n",
    "                                            #problems, where the model's output consists of logits \n",
    "                                            # (unbounded real numbers) rather than probabilities.\n",
    "                                            \n",
    "#Generative models\n",
    "loss_function = nn.KLDivLoss()  #Kullback-Leibler Divergence (KLD): Measuring the difference between two probability \n",
    "                                    #distributions, commonly used in generative models.\n",
    "\n",
    "\n",
    "\n",
    "# Calculate the loss\n",
    "loss = loss_function(outputs, target_data)\n",
    "\n",
    "# Print the loss\n",
    "print(\"Loss:\", loss.item())\n",
    "\n",
    "\n",
    "# Logits are the raw, unnormalized values produced by the model before applying any activation function like sigmoid or \n",
    "# softmax. They represent the model's predictions or scores for each class without being converted into probabilities \n",
    "# yet.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizers play a crucial role in training neural networks by updating the model's parameters to minimize the \n",
    "# loss function\n",
    "\n",
    "# Stochastic Gradient Descent (SGD):\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "# SGD is a classic optimization algorithm that updates the model parameters based on the gradients computed on \n",
    "# small subsets of the training data. It is great when all samples are similar to each other. \n",
    "# Stochastic gradient descent randomly picks a single sample to compute gradients and update parameters. \n",
    "\n",
    "# Adam:\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "# Adam (Adaptive Moment Estimation) is an optimization algorithm that adapts the learning rate for each parameter \n",
    "# based on the estimates of the first and second moments of the gradients\n",
    "\n",
    "# Adagrad:\n",
    "optimizer = torch.optim.Adagrad(model.parameters(), lr=learning_rate)\n",
    "# Adagrad (Adaptive Gradient) is an optimization algorithm that adapts the learning rate for each parameter based on \n",
    "# the historical gradients for that parameter. It is often used in natural language processing tasks. \n",
    "\n",
    "#RMSprop:\n",
    "optimizer = torch.optim.RMSprop(model.parameters(), lr=learning_rate)\n",
    "# RMSprop (Root Mean Square Propagation) is an optimization algorithm that adapts the learning rate for each parameter \n",
    "# based on the moving average of squared gradients. It helps mitigate the diminishing learning rate problem\n",
    "\n",
    "# Adadelta:\n",
    "optimizer = torch.optim.Adadelta(model.parameters(), lr=learning_rate)\n",
    "# Adadelta is an optimization algorithm that dynamically adapts the learning rate and accumulates only a limited \n",
    "# history of past gradients.\n",
    "\n",
    "\n",
    "#the most popular are: Stochastic Gradient Descent (SGD), Adam, RMSprop, and Adagrad.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Commonly used optimizers in deep learning are based on gradient descents, with three types: batch, stochastic, \n",
    "# and mini-batch. Mini-batch is often used for a balance between the other two. Stochastic gradient descent is a \n",
    "# classic optimizer that applies mini-batch gradient descent with fixed step size.\n",
    "\n",
    "# Gradient descent has three types: batch, stochastic, and mini-batch.\n",
    "    # •\tBatch gradient descent uses the entire dataset to compute gradients and update parameters.\n",
    "    # •\tStochastic gradient descent randomly picks a single sample to compute gradients and update parameters.\n",
    "    # •\tMini-batch gradient descent randomly picks a subset of the dataset to compute gradients and update parameters.\n",
    "\n",
    "# NB:\t# Batch gradient descent considers entire database, slowing down training\n",
    "        # Stochastic gradient descent uses one sample, causing fluctuation and difficulty in reaching global minimum. \n",
    "        # Mini-batch gradient descent balances both.\n",
    "\n",
    "# Adaptive learning rates address issues with sparse data\n",
    "    # •\tLearning rate applied throughout training can be problematic\n",
    "    # •\tAdaptive learning rates scale based on inverse sum of squared gradient\n",
    "    \n",
    "#Adaptive learning rates are used in optimizers to dynamically adjust the step size (learning rate) during the training\n",
    "# process. The main reason for using adaptive learning rates is to improve the efficiency and effectiveness of the \n",
    "# optimization algorithm. They are beneficial because of their convergence speed, robustness to different scales, \n",
    "# handling sparse data, robustness to initial learning rate. AdaGrad, RMSprop and Adam use adaptive learning rate.\n",
    "\n",
    "# RMSprop(Root Mean Square Propagation) and Adam are popular optimization methods in deep learning\n",
    "    # •\tRMSprop scales the gradient and uses a moving average of the squared gradient\n",
    "    # •\tAdam combines AdaGrad(Adaptive Gradient Algorithm), RMSprop, and momentum methods into one\n",
    "\n",
    "# Comparison between ATOMS and RMSProp\n",
    "    # •\tATOMS corrects moment estimates for bias towards zero, making it easier to achieve good performance without \n",
    "        # tuning hyperparameters.\n",
    "    # •\tAdaptive learning methods like ATOMS are preferred for better convergence and results, but finding a good \n",
    "        # learning rate can also be effective.\n",
    "\n",
    "# Final Note: Adam and RMSprop are good starting points for adaptive learning weight methods.\n",
    "    # - Adam(Adaptive Moment Estimation) and RMSprop are extensions of SGD with momentum.\n",
    "    # - RMSprop is preferred for sparse data, while Adam is better for faster gradients.\n",
    "    # - Towards the end of optimization, Adam may be the best overall choice for adaptive learning weight methods. \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop involves forward and backward pass to update weights\n",
    "    # Forward pass computes prediction\n",
    "    # Backward pass computes gradients, which are used to update weights\n",
    "\n",
    "# ----------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "# The training loop consists of two nested loops. The outer loop iterates over the specified number of epochs. \n",
    "# Inside the epoch loop, the model is set to train mode (model.train()) and the running loss is initialized. \n",
    "# Then, we iterate over the training data in batches using the train_loader.\n",
    "\n",
    "# For each batch, we perform the following steps:\n",
    "\n",
    "    # Zero the gradients using optimizer.zero_grad().\n",
    "    # Forward pass: Pass the input data through the model to obtain the predicted outputs.\n",
    "    # Compute the loss between the predicted outputs and the true labels.\n",
    "    # Backward pass: Compute the gradients of the loss with respect to the model parameters.\n",
    "    # Update the weights using the optimizer's step() method.\n",
    "    # Update the running loss by adding the current batch loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define your model, optimizer, and loss function\n",
    "model = MyModel()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "train_epoch = 100\n",
    "losses = torch.zeros(train_epoch)\n",
    "ongoing_accuracy = [] \n",
    "\n",
    "# Training loop\n",
    "for epoch in range(train_epoch):\n",
    "    # Set the model to train mode\n",
    "    model.train()\n",
    "    \n",
    "    # Initialize the running loss\n",
    "    running_loss = 0.0 \n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    \n",
    "    # Iterate over the training dataset (training batches)\n",
    "    for inputs, labels in train_loader:\n",
    "\n",
    "        inputs, labels = inputs.to(device), labels.to(device) \n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        # Compute the loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        losses[epoch] = loss\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        \n",
    "        # Update the weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Update the running loss\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    # Compute the average loss for the epoch\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    \n",
    "    accuracy = 100*torch.mean(((outputs>.5) == labels).float())   #Binary classification\n",
    "    ongoing_accuracy.append(accuracy) \n",
    "    print('Accuracy: ' accuracy) \n",
    "    # Print the loss for each epoch\n",
    "    print(f\"Epoch [{epoch+1}/{train_epoch}], Loss: {epoch_loss:.4f}\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> Train classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Binary classification\n",
    "    #see code above\n",
    "\n",
    "\n",
    "\n",
    "#multi-class classification\n",
    "\n",
    "# train the model \n",
    "loss_function = nn.CrossEntropyLoss()        # loss function \n",
    "optimizer =  torch.optim.SGD (model.parameters(), lr=0.05)  # optimizer\n",
    "train_epoch = 100\n",
    "losses = torch.zeros(train_epoch)\n",
    "ongoing_accuracy = [] \n",
    "\n",
    "# loop over the dataset multiple times\n",
    "for epoch in range(train_epoch):\n",
    "    running_loss = 0.0\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    for i, data in enumerate(dataloader, 0):\n",
    "        inputs, labels = data\n",
    "        # inputs = inputs.float()  # Convert inputs to float type\n",
    "        # labels = labels.long()  # Convert labels to long type or LongTensor for cuda\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # zero the parameter gradients \n",
    "        optimizer.zero_grad() \n",
    "\n",
    "        # forward + backward + optimize \n",
    "        y_pred = model(inputs) \n",
    "        loss = loss_function(y_pred, labels) \n",
    "        losses[epoch] = loss \n",
    "        \n",
    "        loss.backward() \n",
    "        optimizer.step() \n",
    "\n",
    "        running_loss += loss.item() \n",
    "        \n",
    "        # Calculate accuracy \n",
    "        predicted_labels = torch.argmax(y_pred, dim=1) \n",
    "        total_correct += torch.sum(predicted_labels == labels).item() \n",
    "        total_samples += labels.size(0) \n",
    "\n",
    "    accuracy = 100 * total_correct / total_samples\n",
    "    ongoing_accuracy.append(accuracy)\n",
    "    print('Epoch: {}, Loss: {:.4f}, Accuracy: {:.2f}%'.format(epoch + 1, running_loss, accuracy))\n",
    "\n",
    "    print('Loss: {}'.format(running_loss) )\n",
    "\n",
    "print('Finished Training')\n",
    "\n",
    "#y_pred_probabilities = F.softmax(y_pred, dim=1) #to view the probabilities by transforming into the softmax transfmtn.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> Plots to visualize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# report accuracy\n",
    "print('Model accuracy: %g%%' %accuracy)\n",
    "\n",
    "fig,ax = plt.subplots(1,2,figsize=(13,4))\n",
    "\n",
    "ax[0].plot(losses.detach())\n",
    "ax[0].set_ylabel('Loss')\n",
    "ax[0].set_xlabel('epoch')\n",
    "ax[0].set_title('Losses')\n",
    "\n",
    "ax[1].plot(ongoing_accuracy)\n",
    "ax[1].set_ylabel('accuracy')\n",
    "ax[1].set_xlabel('epoch')\n",
    "ax[1].set_title('Accuracy')\n",
    "plt.show()\n",
    "# run training again to see whether this performance is consistent"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> Use this code for training and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn.init.kaiming_uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #define the model \n",
    "\n",
    "class iris_model(nn.Module):\n",
    "    \"\"\"Some Information about iris_model\"\"\"\n",
    "    def __init__(self, weight_init='default'):\n",
    "        super(iris_model, self).__init__()\n",
    "        self.fc1 = nn.Linear(4, 64)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, 3)\n",
    "        \n",
    "        if weight_init == 'default':\n",
    "            pass  # Default weight initialization\n",
    "\n",
    "        elif weight_init == 'xavier_uniform':\n",
    "            self._init_weights_xavier_uniform()\n",
    "\n",
    "        elif weight_init == 'kaiming_normal':\n",
    "            self._init_weights_kaiming_normal()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.fc1(x))\n",
    "        # out = self.fca(out) \n",
    "        out = F.relu(self.fc2(out))\n",
    "        # out = self.fcb(out)\n",
    "        out = self.fc3(out)\n",
    "        return out\n",
    "\n",
    "    def _init_weights_xavier_uniform(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                init.xavier_uniform_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    init.constant_(m.bias, 0)\n",
    "\n",
    "    def _init_weights_kaiming_normal(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                init.kaiming_normal_(m.weight, mode='fan_in', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    init.constant_(m.bias, 0)\n",
    "\n",
    "model = iris_model()    #initializing the model  #model = iris_model(weight_init='xavier_uniform') \n",
    "\n",
    "\n",
    "\n",
    "# # A. create a class for the model \n",
    "# def create_model(nUnits, nLayers):\n",
    "#     class iris_model(nn.Module):\n",
    "#         def __init__(self):\n",
    "#             super().__init__()\n",
    "\n",
    "#             # create dictionary to store the layers\n",
    "#             self.layers = nn.ModuleDict()\n",
    "#             self.nLayers = nLayers \n",
    "\n",
    "#             ### input layer\n",
    "#             self.layers['input'] = nn.Linear(4, nUnits)\n",
    "            \n",
    "#             ### hidden layers\n",
    "#             for i in range(nLayers):\n",
    "#                 self.layers[f'hidden{i}'] = nn.Linear(nUnits, nUnits)\n",
    "\n",
    "#             ### output layer\n",
    "#             self.layers['output'] = nn.Linear(nUnits, 3)\n",
    "        \n",
    "#         # forward pass\n",
    "#         def forward(self, x):\n",
    "#             # input layer (note: the code in the video omits the relu after this layer)\n",
    "#             x = F.relu(self.layers['input'](x))\n",
    "\n",
    "#             # hidden layers\n",
    "#             for i in range(self.nLayers):\n",
    "#                 x = F.relu(self.layers[f'hidden{i}'](x))\n",
    "                \n",
    "#             # return output layer\n",
    "#             x = self.layers['output'](x)    #or x = F.sigmoid(self.layers['output](x)) for Binary classification \n",
    "#             return x \n",
    "        \n",
    "#     return iris_model() \n",
    "\n",
    "\n",
    "def create_model(nUnits, nLayers, weight_init):\n",
    "    class iris_model(nn.Module):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "\n",
    "            # Create dictionary to store the layers\n",
    "            self.layers = nn.ModuleDict()\n",
    "            self.nLayers = nLayers \n",
    "            self.weight_init = weight_init\n",
    "\n",
    "            ### Input layer\n",
    "            self.layers['input'] = nn.Linear(4, nUnits)\n",
    "            self.layers['input_bn'] = nn.BatchNorm1d(nUnits)\n",
    "            self.layers['input_dropout'] = nn.Dropout(0.2)\n",
    "            \n",
    "            ### Hidden layers\n",
    "            for i in range(nLayers):\n",
    "                self.layers[f'hidden{i}'] = nn.Linear(nUnits, nUnits)\n",
    "                self.layers[f'hidden{i}_bn'] = nn.BatchNorm1d(nUnits)\n",
    "                self.layers[f'hidden{i}_dropout'] = nn.Dropout(0.2)\n",
    "\n",
    "            ### Output layer\n",
    "            self.layers['output'] = nn.Linear(nUnits, 3)\n",
    "        \n",
    "            # Initialize weights\n",
    "            self._initialize_weights()\n",
    "            \n",
    "        \n",
    "        # Forward pass\n",
    "        def forward(self, x):\n",
    "            # Input layer\n",
    "            x = self.layers['input'](x)\n",
    "            x = self.layers['input_bn'](x)\n",
    "            x = F.relu(x)\n",
    "            x = self.layers['input_dropout'](x)\n",
    "\n",
    "            # Hidden layers\n",
    "            for i in range(self.nLayers):\n",
    "                x = self.layers[f'hidden{i}'](x)\n",
    "                x = self.layers[f'hidden{i}_bn'](x)\n",
    "                x = F.relu(x)\n",
    "                x = self.layers[f'hidden{i}_dropout'](x)\n",
    "                \n",
    "            # Output layer\n",
    "            x = self.layers['output'](x)    #or x = F.sigmoid(self.layers['output](x)) for Binary classification \n",
    "            \n",
    "            return x \n",
    "        \n",
    "        def _initialize_weights(self):\n",
    "            for name, module in self.layers.items():\n",
    "                if isinstance(module, nn.Linear):\n",
    "                    weight_init = self.weight_init.get(name, 'default') #works well with sigmoid (uniform distribution)\n",
    "                    if weight_init == 'xavier_uniform':     #works well with sigmoid\n",
    "                        init.xavier_uniform_(module.weight)\n",
    "                    elif weight_init == 'kaiming_normal':   #works well with ReLU activation \n",
    "                        init.kaiming_normal_(module.weight)\n",
    "                    if module.bias is not None:\n",
    "                        init.constant_(module.bias, 0)\n",
    "    \n",
    "    return iris_model()\n",
    "\n",
    "nUnits = 64\n",
    "nLayers = 5\n",
    "weight_init = {\n",
    "    'input': 'default',\n",
    "    'hidden0': 'kaiming_normal',\n",
    "    'hidden1': 'kaiming_normal',\n",
    "    'hidden2': 'kaiming_normal',\n",
    "    # 'hidden3': 'kaiming_normal',\n",
    "    'output': 'default'\n",
    "}\n",
    "\n",
    "model = create_model(nUnits, nLayers, weight_init)    #initializing the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model training \n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "## metric = torchmetrics.Accuracy(task='multiclass', num_classes=num_classes)    (.Precision(), .Recall(), .F1Score(), .ConfusionMatrix())\n",
    "                #see doc. https://torchmetrics.readthedocs.io/en/stable/classification/accuracy.html#functional-interface \n",
    "           \n",
    "num_epochs = 50\n",
    "learning_rate = 0.0032734813343726263\n",
    "losses = torch.zeros(num_epochs)\n",
    "ongoing_accuracy = []\n",
    "ongoing_accuracy_test = []\n",
    "num_classes = 10\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=0.0008018107002058151)\n",
    "\n",
    "# Define the learning rate scheduler\n",
    "scheduler = StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Move the model and data to the appropriate device (e.g., GPU if available)\n",
    "model.to(device)\n",
    "\n",
    "# Variables to track the best model and accuracy\n",
    "best_accuracy = 0.0\n",
    "best_model_state = None\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    batchAcc = []\n",
    "    batchLoss = []\n",
    "\n",
    "    # Iterate over the training dataloader\n",
    "    for inputs, labels in train_dataloader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        batchLoss.append(loss.item())\n",
    "\n",
    "        # Compute accuracy on the training set\n",
    "        predictions = torch.argmax(outputs, axis=1)\n",
    "        accuracy = torchmetrics.functional.classification.accuracy(predictions, labels, task='multiclass',\n",
    "                                                                    num_classes=num_classes) * 100\n",
    "        # accuracy = torchmetrics.functional.classification.accuracy(predictions, labels, task='multiclass', num_classes=num_classes) \n",
    "        #                                                     (or metric(predictions, labels))\n",
    "        # accuracy = torchmetrics.functional.classification.binary_accuracy (predicted, labels, threshold = 0.5)   #for binary classification\n",
    "        # r2score = torchmetrics.functional.r2_score(preds, target) \n",
    "        batchAcc.append(accuracy.item())\n",
    "\n",
    "    # Update the learning rate\n",
    "    scheduler.step()\n",
    "\n",
    "    ongoing_accuracy.append(np.mean(batchAcc.to(device)))\n",
    "    losses[epoch] = np.mean(batchLoss)\n",
    "\n",
    "    # Print loss and accuracy for the epoch\n",
    "    if epoch % 10 == 0:\n",
    "      print(f\"Epoch {epoch}/{num_epochs}: Loss = {np.mean(batchLoss):.4f}, Accuracy = {np.mean(batchAcc):.2f}%\")\n",
    "\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        batchAcc_test = []\n",
    "        for data in test_dataloader:\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            # Calculate predictions\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "            accuracy = torchmetrics.functional.classification.accuracy(predicted, labels,\n",
    "                                                                    task='multiclass', \n",
    "                                                                       num_classes=num_classes) * 100\n",
    "            batchAcc_test.append(accuracy.cpu())\n",
    "            \n",
    "    test_accuracy = np.mean(batchAcc_test)\n",
    "    ongoing_accuracy_test.append(test_accuracy)\n",
    "\n",
    "    if test_accuracy > best_accuracy:\n",
    "        best_accuracy = test_accuracy\n",
    "        best_model_state = model.state_dict().copy()\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Accuracy on test set: {test_accuracy:.2f}%\")\n",
    "\n",
    "print('Finished Training')\n",
    "print(' ')\n",
    "\n",
    "# Load the best model state\n",
    "model.load_state_dict(best_model_state)\n",
    "\n",
    "# Report accuracy\n",
    "print('Final accuracy (eval): {:.2f}%'.format(ongoing_accuracy_test[-1]))\n",
    "print('Best accuracy (eval): {:.2f}%'.format(best_accuracy)) \n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(13, 4))\n",
    "\n",
    "ax[0].plot(losses.detach())\n",
    "ax[0].set_ylabel('Loss')\n",
    "ax[0].set_xlabel('Epoch')\n",
    "ax[0].set_title('Losses')\n",
    "\n",
    "ax[1].plot(ongoing_accuracy, label='Training Accuracy')\n",
    "ax[1].plot(ongoing_accuracy_test, label='Evaluation Accuracy')\n",
    "ax[1].set_ylabel('Accuracy')\n",
    "ax[1].set_xlabel('Epoch')\n",
    "ax[1].set_title('Accuracy')\n",
    "ax[1].legend()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# run training again to see whether this performance is consistent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model evaluation (Test)\n",
    "\n",
    "# Validation Loop:\n",
    "    # Evaluate the model on the validation dataset to monitor its performance and make any necessary adjustments.\n",
    "    # Pass the input batch through the model to obtain predictions.\n",
    "    # Calculate the validation loss and any desired evaluation metrics.\n",
    "    \n",
    "# Hyperparameter Tuning:\n",
    "    # Experiment with different learning rates, batch sizes, architectures, activation functions, \n",
    "        # regularization techniques, and optimizer settings.\n",
    "    # Use the validation set to evaluate different combinations of hyperparameters and choose the best-performing ones.\n",
    "\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "# Disable gradient computation for evaluation\n",
    "with torch.inference_mode():        #or torch.no_grad()\n",
    "    for data in test_dataloader:\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Calculate predictions\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = torchmetrics.functional.classification.accuracy(predicted, labels, task='multiclass', num_classes=num_classes) \n",
    "\n",
    "print(f\"Accuracy on test set: {100 * accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "# from pathlib import Path \n",
    "\n",
    "# # Download helper functions from Learn PyTorch repo (if not already downloaded)\n",
    "# if Path(\"helper_functions.py\").is_file():\n",
    "#   print(\"helper_functions.py already exists, skipping download\")\n",
    "# else:\n",
    "#   print(\"Downloading helper_functions.py\")\n",
    "#   request = requests.get(\"https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/helper_functions.py\")\n",
    "#   with open(\"helper_functions.py\", \"wb\") as f:\n",
    "#     f.write(request.content)\n",
    "\n",
    "# from helper_functions import plot_predictions, plot_decision_boundary "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Optimization (Hyperparameter Tuning)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#How to prevent overfitting\n",
    "# Get more data\t\n",
    "    # Having more data gives the model more opportunities to learn patterns, patterns which may be more generalizable \n",
    "    # to new examples.\n",
    "# Simplify your model\t\n",
    "    # If the current model is already overfitting the training data, it may be too complicated of a model. \n",
    "    # This means it's learning the patterns of the data too well and isn't able to generalize well to unseen data. \n",
    "    # One way to simplify a model is to reduce the number of layers it uses or to reduce the number of hidden units in \n",
    "    # each layer.\n",
    "# Use data augmentation\t\n",
    "    # Data augmentation manipulates the training data in a way so that's harder for the model to learn as it artificially \n",
    "    # adds more variety to the data. If a model is able to learn patterns in augmented data, the model may be able to \n",
    "    # generalize better to unseen data.\n",
    "# Use transfer learning\t\n",
    "    # Transfer learning involves leveraging the patterns (also called pretrained weights) one model has learned to use as \n",
    "    # the foundation for your own task. In our case, we could use one computer vision model pretrained on a large variety \n",
    "    # of images and then tweak it slightly to be more specialized for food images.\n",
    "# Use dropout layers\t\n",
    "    # Dropout layers randomly remove connections between hidden layers in neural networks, effectively simplifying a model \n",
    "    # but also making the remaining connections better. See torch.nn.Dropout() for more.\n",
    "# Use learning rate decay\t\n",
    "    # The idea here is to slowly decrease the learning rate as a model trains. This is akin to reaching for a coin at the \n",
    "    # back of a couch. The closer you get, the smaller your steps. The same with the learning rate, the closer you get to \n",
    "    # convergence, the smaller you'll want your weight updates to be.\n",
    "# Use early stopping\t\n",
    "    # Early stopping stops model training before it begins to overfit. As in, say the model's loss has stopped decreasing \n",
    "    # for the past 10 epochs (this number is arbitrary), you may want to stop the model training here and go with the model \n",
    "    # weights that had the lowest loss (10 epochs prior).\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#How to prevent underfitting\n",
    "# Add more layers/units to your model\t\n",
    "    # If your model is underfitting, it may not have enough capability to learn the required patterns/weights/representations \n",
    "    # of the data to be predictive. One way to add more predictive power to your model is to increase the number of hidden \n",
    "    # layers/units within those layers.\n",
    "# Tweak the learning rate\t\n",
    "    # Perhaps your model's learning rate is too high to begin with. And it's trying to update its weights each epoch too \n",
    "    # much, in turn not learning anything. In this case, you might lower the learning rate and see what happens.\n",
    "# Use transfer learning\t\n",
    "    # Transfer learning is capable of preventing overfitting and underfitting. It involves using the patterns from a \n",
    "    # previously working model and adjusting them to your own problem.\n",
    "# Train for longer\t\n",
    "    # Sometimes a model just needs more time to learn representations of data. If you find in your smaller experiments \n",
    "    # your model isn't learning anything, perhaps leaving it train for a more epochs may result in better performance.\n",
    "# Use less regularization\t\n",
    "    # Perhaps your model is underfitting because you're trying to prevent overfitting too much. Holding back on \n",
    "    # regularization techniques can help your model fit the data better.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# How to deal with unbalanced data\n",
    "    # Get more data\n",
    "    # undersample\n",
    "    # Oversample\n",
    "        # create multiple copis of the rare data. (be careful because it increases the risk of overfitting)\n",
    "    # Data Augmentation\n",
    "        # Add new features as non-linear transformations of existing data\n",
    "    # Create synthetic samples\n",
    "        # you can use SMOTE\n",
    "    # Consider whether non-deep learning would be better\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> Auto Tuning using Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Define your model\n",
    "class MyModel(nn.Module):\n",
    "    # Your model definition here\n",
    "\n",
    "# Define your objective function\n",
    "def objective(trial):\n",
    "    # Define your hyperparameters to be tuned\n",
    "    learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1) \n",
    "    nUnits = trial.suggest_categorical('nUnits', 4, 128, step=8) \n",
    "    nLayers = trial.suggest_int('nLayers', 1, 6, step = 1) \n",
    "    weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
    "    dropout_rate = trial.suggest_uniform('dropout_rate', 0.0, 0.5)    \n",
    "    batch_size = trial.suggest_categorical('batch_size', [16, 32, 64])    \n",
    "    # weight_inits = trial.suggest_categorical('weight_init', ['default', 'kaiming_normal', 'xavier_uniform_']) \n",
    "    # num_epochs = trial.suggest_int('num_epochs', 30, 300)  \n",
    "    # optimizer = trial.suggest_categorical('optimizer', ['adam', 'sgd'])\n",
    "    # activation = trial.suggest_categorical('activation', ['relu', 'sigmoid', 'tanh'])\n",
    "    # patience = trial.suggest_int('patience', 5, 20)\n",
    "\n",
    "    # Define your model architecture with the hyperparameters\n",
    "    model = mnist_model(nUnits, nLayers, weight_inits, dropout_rate) \n",
    "\n",
    "    num_epochs = 50\n",
    "    learning_rate = learning_rate\n",
    "    losses = torch.zeros(num_epochs)\n",
    "    ongoing_accuracy = []\n",
    "    num_classes = 10\n",
    "\n",
    "    # Define the loss function and optimizer\n",
    "    criterion = nn.NLLLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay = weight_decay) \n",
    "\n",
    "    # Define the learning rate scheduler\n",
    "    scheduler = StepLR(optimizer, step_size=30, gamma=0.1)\n",
    "\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    # Move the model and data to the appropriate device (e.g., GPU if available)\n",
    "    model.to(device)\n",
    "\n",
    "    # Loop over the dataset for multiple epochs\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        batchAcc  = []\n",
    "        batchLoss = []\n",
    "\n",
    "        # Iterate over the training dataloader\n",
    "        for inputs, labels in train_dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            batchLoss.append(loss.item())\n",
    "\n",
    "            # Compute accuracy on the training set\n",
    "            predictions = torch.argmax(outputs, axis=1)\n",
    "            accuracy = torchmetrics.functional.classification.accuracy(predictions, labels, task='multiclass',\n",
    "                                                                        num_classes=num_classes) * 100\n",
    "            batchAcc.append(accuracy.item())\n",
    "\n",
    "        # Update the learning rate\n",
    "        scheduler.step()\n",
    "\n",
    "        ongoing_accuracy.append(np.mean(batchAcc))\n",
    "        losses[epoch] = np.mean(batchLoss)\n",
    "\n",
    "\n",
    "        #evaluation\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "    # Disable gradient computation for evaluation\n",
    "    with torch.inference_mode():        #or torch.no_grad()\n",
    "        for data in test_dataloader:\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            # Calculate predictions\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    # accuracy = 100 * (total_correct / total_samples)\n",
    "    accuracy = torchmetrics.functional.classification.accuracy(predicted, labels, task='multiclass', num_classes=num_classes) * 100\n",
    "\n",
    "    return accuracy \n",
    "\n",
    "# Define the study\n",
    "study = optuna.create_study(direction='maximize')\n",
    "\n",
    "# Run the optimization\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "print(\" Value: \", study.best_trial.value)\n",
    "print(\" Params: \")\n",
    "for key, value in study.best_trial.params.items():\n",
    "    print(f\"    {key}: {value}\")\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> Neurons vs Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A. create a class for the model \n",
    "def create_model(nUnits, nLayers):\n",
    "    class iris_model(nn.Module):\n",
    "        def __init__(self):\n",
    "            super().__init__()\n",
    "\n",
    "            # create dictionary to store the layers\n",
    "            self.layers = nn.ModuleDict()\n",
    "            self.nLayers = nLayers \n",
    "\n",
    "            ### input layer\n",
    "            self.layers['input'] = nn.Linear(4, nUnits)\n",
    "            \n",
    "            ### hidden layers\n",
    "            for i in range(nLayers):\n",
    "                self.layers[f'hidden{i}'] = nn.Linear(nUnits, nUnits)\n",
    "\n",
    "            ### output layer\n",
    "            self.layers['output'] = nn.Linear(nUnits, 3)\n",
    "        \n",
    "        # forward pass\n",
    "        def forward(self, x):\n",
    "            # input layer (note: the code in the video omits the relu after this layer)\n",
    "            x = F.relu(self.layers['input'](x))\n",
    "\n",
    "            # hidden layers\n",
    "            for i in range(self.nLayers):\n",
    "                x = F.relu(self.layers[f'hidden{i}'](x))\n",
    "                \n",
    "            # return output layer\n",
    "            x = self.layers['output'](x)\n",
    "            return x \n",
    "        \n",
    "    return iris_model() \n",
    "\n",
    "#B. Train the model (return 'final accuracy' and 'trainable parameters')\n",
    "def train_model():\n",
    "    loss_function = nn.CrossEntropyLoss()        # loss function \n",
    "    optimizer =  torch.optim.SGD (model.parameters(), lr=0.05)  # optimizer\n",
    "\n",
    "    # loop over the dataset multiple times\n",
    "    for epoch in range(train_epoch):\n",
    "        running_loss = 0.0\n",
    "        total_correct = 0\n",
    "        total_samples = 0\n",
    "        for i, data in enumerate(dataloader, 0):\n",
    "            inputs, labels = data\n",
    "            # inputs = inputs.float()  # Convert inputs to float type\n",
    "            # labels = labels.long()  # Convert labels to long type\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # zero the parameter gradients \n",
    "            optimizer.zero_grad() \n",
    "\n",
    "            # forward + backward + optimize \n",
    "            y_pred = create_model(inputs) \n",
    "            loss = loss_function(y_pred, labels) \n",
    "            losses[epoch] = loss \n",
    "            \n",
    "            loss.backward() \n",
    "            optimizer.step() \n",
    "\n",
    "            running_loss += loss.item() \n",
    "            \n",
    "            # Calculate accuracy \n",
    "            predicted_labels = torch.argmax(y_pred, dim=1) \n",
    "            total_correct += torch.sum(predicted_labels == labels).item() \n",
    "            total_samples += labels.size(0) \n",
    "\n",
    "        accuracy = 100 * total_correct / total_samples\n",
    "    # total number of trainable parameters in the model\n",
    "    nParams = sum(p.numel() for p in theModel.parameters() if p.requires_grad)\n",
    "    \n",
    "    print('Finished Training')\n",
    "    return accuracy, nParams\n",
    "\n",
    "\n",
    "\n",
    "#C. describe the ranges of hyperparameters to be tesed\n",
    "numlayers = range(1,6)          # number of hidden layers\n",
    "numunits  = np.arange(4,101,3)  # number of nodes \n",
    "\n",
    "# initialize output matrices\n",
    "accuracies  = np.zeros((len(numunits),len(numlayers)))  #as a matrix\n",
    "totalparams = np.zeros((len(numunits),len(numlayers)))  #as a matrix\n",
    "\n",
    "# number of training epochs\n",
    "numepochs = 500\n",
    "\n",
    "\n",
    "#D start the experiment!\n",
    "for unitidx in range(len(numunits)):\n",
    "  for layeridx in range(len(numlayers)):\n",
    "\n",
    "    # create a fresh model instance\n",
    "    net = create_model(numunits[unitidx],numlayers[layeridx]) \n",
    "\n",
    "    # run the model and store the results\n",
    "    accuracy, nParams = train_model(net)\n",
    "    accuracies[unitidx,layeridx] = accuracy\n",
    "\n",
    "    # store the total number of parameters in the model\n",
    "    totalparams[unitidx,layeridx] = nParams\n",
    "\n",
    "\n",
    "#E. visualize \n",
    "# show accuracy as a function of model depth\n",
    "fig,ax = plt.subplots(1,figsize=(12,6))\n",
    "\n",
    "ax.plot(numunits,accuracies,'o-',markerfacecolor='w',markersize=9)\n",
    "ax.plot(numunits[[0,-1]],[33,33],'--',color=[.8,.8,.8])\n",
    "ax.plot(numunits[[0,-1]],[67,67],'--',color=[.8,.8,.8])\n",
    "ax.legend(numlayers)\n",
    "ax.set_ylabel('accuracy')\n",
    "ax.set_xlabel('Number of hidden units')\n",
    "ax.set_title('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> Learning Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Saving and Loading"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> Saving the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Save the model checkpoint\n",
    "checkpoint = {\n",
    "    'epoch': 300,\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'loss': loss,\n",
    "    'learning_rate': optimizer.param_groups[0]['lr'],\n",
    "    'hyperparameters': {\n",
    "                'hidden_units': 64,\n",
    "                'batch_size': 32\n",
    "                        },\n",
    "    # 'other_info': 'Additional information about the checkpoint'\n",
    "}\n",
    "\n",
    "torch.save(checkpoint, 'model_checkpoint.pth')\n",
    "\n",
    "\n",
    "\n",
    "# Save the model without checkpoint information\n",
    "torch.save(model.state_dict(), 'model.pth')\n",
    "\n",
    "\n",
    "\n",
    "# Saving with a checkpoint (first code snippet) is recommended when:\n",
    "    # You want to save the complete training state, including the model's parameters, optimizer state, and other \n",
    "        # relevant information.\n",
    "    # You may need to resume training from the saved state in the future.\n",
    "    # You want to track and monitor training progress, such as the current epoch, loss, and learning rate.\n",
    "\n",
    "# Saving without a checkpoint (second code snippet) is recommended when:\n",
    "    # You only need to save the model's architecture and parameters for later use, such as inference or transfer learning.\n",
    "    # You do not intend to resume training from the saved state.\n",
    "    # You want a more lightweight and simplified model saving approach."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you saved a checkpoint, you can load it as follows:\n",
    "\n",
    "checkpoint = torch.load('model_checkpoint.pth')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epoch = checkpoint['epoch']\n",
    "loss = checkpoint['loss']\n",
    "hidden_units = checkpoint['hyperparameters']['hidden_units']\n",
    "batch_size = checkpoint['hyperparameters']['batch_size']\n",
    "\n",
    "\n",
    "#If you saved just the model without the checkpoint information,\n",
    "model = MyModel()\n",
    "model.load_state_dict(torch.load('model.pth'))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = torchvision.datasets.DataFolder('path/to/root', loader) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize an image\n",
    "\n",
    "import random\n",
    "from PIL import Image\n",
    "\n",
    "# Set seed\n",
    "random.seed(42) # <- try changing this and see what happens\n",
    "\n",
    "# 1. Get all image paths (* means \"any combination\")\n",
    "image_path_list = list(image_path.glob(\"*/*/*.jpg\"))\n",
    "\n",
    "# 2. Get random image path\n",
    "random_image_path = random.choice(image_path_list)\n",
    "\n",
    "# 3. Get image class from path name (the image class is the name of the directory where the image is stored)\n",
    "image_class = random_image_path.parent.stem\n",
    "\n",
    "# 4. Open image\n",
    "img = Image.open(random_image_path)\n",
    "\n",
    "# 5. Print metadata\n",
    "print(f\"Random image path: {random_image_path}\")\n",
    "print(f\"Image class: {image_class}\")\n",
    "print(f\"Image height: {img.height}\") \n",
    "print(f\"Image width: {img.width}\")\n",
    "img"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> Image Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The main difference between Conv1d, Conv2d, and Conv3d in PyTorch lies in the dimensionality of the data they operate on.\n",
    "\n",
    "#Conv1D\n",
    "    # Conv1d is used for 1-dimensional convolution. It is typically used for sequential data, such as time series \n",
    "    # or text data. It operates on inputs with three dimensions: (batch_size, channels, sequence_length). \n",
    "    # The convolutional kernel slides along the sequence length dimension.\n",
    "\n",
    "#Conv2D\n",
    "    # Conv2d is used for 2-dimensional convolution. It is commonly applied to image data, where each image has two \n",
    "    # spatial dimensions: height and width. Conv2d operates on inputs with four dimensions: \n",
    "    # (batch_size, RGB channels, height, width). The convolutional kernel slides spatially along the height and width \n",
    "    # dimensions.\n",
    "\n",
    "#Conv3D\n",
    "    # Conv3d is used for 3-dimensional convolution. It is typically used for volumetric data, such as 3D images \n",
    "    # or video frames. Conv3d operates on inputs with five dimensions: (batch_size, channels, depth, height, width). \n",
    "    # The convolutional kernel slides along all three spatial dimensions: depth, height, and width.\n",
    "\n",
    "# The main purpose of these different convolutional layers is to handle different types of data with varying \n",
    "# dimensionalities. By using the appropriate convolutional layer, you can effectively capture patterns and extract \n",
    "# features from different types of data structures.\n",
    "\n",
    "\n",
    "batch_size = 1  # Number of images in the batch\n",
    "in_channels = 3  # Number of input channels (e.g., for RGB images)\n",
    "out_channels = 64  # Number of output channels (i.e., the number of filters)\n",
    "kernel_size = 3  # Size of the convolutional kernel (e.g., 3x3)\n",
    "stride = 1  # Stride for the convolution operation\n",
    "padding = 1  # Padding applied to the input (if needed)\n",
    "height = 256  # Height of each image\n",
    "width = 256  # Width of each image \n",
    "\n",
    "conv_layer = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)\n",
    "input_data = torch.randn(batch_size, in_channels, height, width)\n",
    "\n",
    "# other common values for in_channels\n",
    "    # Grayscale Images (1 channel)\n",
    "    # RGB Images (3 channels)\n",
    "    # Binary Images (1 channel)\n",
    "    # RGBA Images (4 channels)\n",
    "    # Multi-channel Images (e.g., 6 channels)\n",
    "    # Time Series Data (would depend on the number of variables)\n",
    "    # Audio Data (2 channels i.e., left and right audio source)\n",
    "\n",
    "# color models used in Deep learning\n",
    "    # RGB (Red, Green, Blue) --> most common \n",
    "    # CMYK (Cyan, Magenta, Yellow, Key/Black) --> mainly used for printing\n",
    "    # HSV (Hue, Saturation, Value)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here's the equation to calculate the number of pixels after convolution and pooling operations: \n",
    "\n",
    "# Convolution:\n",
    "    # The formula to calculate the number of pixels after a convolutional layer is given by:\n",
    "    Output Size = ((Input Size - Filter Size + 2 * Padding) / Stride) + 1\n",
    "\n",
    "# Where:\n",
    "    # Input Size: The size (height or width) of the input feature map.\n",
    "    # Filter Size: The size (height or width) of the convolutional filter/kernel.\n",
    "    # Padding: The number of zero-padding pixels added to the input feature map.\n",
    "    # Stride: The stride or the step size used for the convolution operation.\n",
    "# Note: The formula assumes that the stride and padding values are the same for both height and width dimensions of \n",
    "# the input.\n",
    "\n",
    "# Pooling:\n",
    "    # The formula to calculate the number of pixels after a pooling layer is given by:\n",
    "    Output Size = ((Input Size - Pooling Size) / Stride) + 1\n",
    "\n",
    "# Where:\n",
    "    # Input Size: The size (height or width) of the input feature map.\n",
    "    # Pooling Size: The size (height or width) of the pooling window.\n",
    "    # Stride: The stride or the step size used for the pooling operation.\n",
    "\n",
    "# Note: Similar to the convolution formula, the stride value and padding values are assumed to be the same for both \n",
    "# height and width dimensions of the input."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> Image Annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Types of Image Annotations\n",
    "\n",
    "#1. Bounding box annotation\n",
    "#2. 3D bounding boxes or Cuboids (can show length, width, and depth of the target objects)\n",
    "#3. Polygon annotations (this is a more precise annotations - dots are used to carve out the area to be annotated)\n",
    "#4. Lines (and Splines) - used to train machines to recognize lanes and boundaries. (e.g autonomous vehicles)\n",
    "#5. Semantic Segmentation (more precise, every pixel is labeled). \n",
    "\n",
    "\n",
    "#Best Annotation Tools for COmputer Vision\n",
    "\n",
    "# Free:\n",
    "# 1. Make Sense: https://www.makesense.ai/      - very good (recommended -1)\n",
    "# 2. VGG Image Annotator: https://www.robots.ox.ac.uk/~vgg/software/via/    - very common (recommended -2)\n",
    "# 3. Computer Vision Annotator Tool (CVAT): https://github.com/openvinotoolkit/cvat\n",
    "# 4. Labelme: http://labelme.csail.mit.edu/\n",
    "# 5. Dash Doodler: https://github.com/Doodleverse/dash_doodler \n",
    "# 6. LabelImg: https://github.com/tzutalin/labelImg\n",
    "# 7. Label Studio: https://labelstud.io/        - very good for CV, timeseries and multi-domain. (recommended -3)\n",
    "\n",
    "# Paid:\n",
    "# 8. LabelBox: https://labelbox.com/    - very common \n",
    "# 9. Scale: https://scale.com/\n",
    "# 10. Superannotate: https://www.superannotate.com/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> Image Classification Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LeNet:\n",
    "    # One of the earliest convolutional neural network (CNN) architectures, LeNet consists of several convolutional \n",
    "    # and pooling layers followed by fully connected layers. It was designed for handwritten digit recognition and \n",
    "    # laid the foundation for modern CNNs\n",
    "    \n",
    "        # Convolutional Layer (6 filters, 5x5 kernel, ReLU activation)\n",
    "        # Average Pooling Layer (2x2 pool size)\n",
    "        # Convolutional Layer (16 filters, 5x5 kernel, ReLU activation)\n",
    "        # Average Pooling Layer (2x2 pool size)\n",
    "        # Fully Connected Layer (120 units, ReLU activation)\n",
    "        # Fully Connected Layer (84 units, ReLU activation)\n",
    "        # Output Layer (number of classes, softmax activation)\n",
    "        \n",
    "# AlexNet:\n",
    "    # AlexNet gained prominence after winning the ImageNet Large Scale Visual Recognition Challenge (ILSVRC) in 2012. \n",
    "    # It introduced deeper architectures and the use of rectified linear units (ReLU) as activation functions. \n",
    "    # It consists of multiple convolutional and fully connected layers\n",
    "    \n",
    "        # Convolutional Layer (96 filters, 11x11 kernel, stride 4, ReLU activation)\n",
    "        # Max Pooling Layer (3x3 pool size, stride 2)\n",
    "        # Convolutional Layer (256 filters, 5x5 kernel, ReLU activation)\n",
    "        # Max Pooling Layer (3x3 pool size, stride 2)\n",
    "        # Convolutional Layer (384 filters, 3x3 kernel, ReLU activation)\n",
    "        # Convolutional Layer (384 filters, 3x3 kernel, ReLU activation)\n",
    "        # Convolutional Layer (256 filters, 3x3 kernel, ReLU activation)\n",
    "        # Max Pooling Layer (3x3 pool size, stride 2)\n",
    "        # Fully Connected Layer (4096 units, ReLU activation)\n",
    "        # Fully Connected Layer (4096 units, ReLU activation)\n",
    "        # Output Layer (number of classes, softmax activation)\n",
    "        \n",
    "# VGGNet:\n",
    "    # VGGNet is known for its simplicity and uniformity. It utilizes a series of 3x3 convolutional layers with \n",
    "    # max pooling, followed by fully connected layers. VGGNet comes in different variants, such as VGG16 and VGG19, \n",
    "    # denoting the number of layers.\n",
    "    \n",
    "        # Convolutional Layers (multiple layers with 3x3 filters, ReLU activation)\n",
    "        # Max Pooling Layer (2x2 pool size)\n",
    "        # (Repeats several times with increasing number of filters)\n",
    "        # Fully Connected Layer (4096 units, ReLU activation)\n",
    "        # Fully Connected Layer (4096 units, ReLU activation)\n",
    "        # Output Layer (number of classes, softmax activation)\n",
    "        \n",
    "# GoogLeNet (Inception):\n",
    "    # GoogLeNet introduced the Inception module, which allows for the use of multiple filter sizes within a \n",
    "    # single layer. This model employed 1x1, 3x3, and 5x5 convolutions to capture different scales of features. \n",
    "    # It also made use of global average pooling and auxiliary classifiers\n",
    "    \n",
    "        # Inception Modules (various branches with 1x1, 3x3, 5x5 convolutions, pooling, ReLU activations)\n",
    "        # (Repeats several times with different configurations)\n",
    "        # Auxiliary Classifiers (additional branches with fully connected layers and softmax activation)\n",
    "        # Global Average Pooling Layer\n",
    "        # Fully Connected Layer (number of classes, softmax activation)\n",
    "        \n",
    "# ResNet:\n",
    "    # ResNet introduced the concept of residual learning, using skip connections to tackle the vanishing \n",
    "    # gradient problem. ResNet architectures are deeper, with up to hundreds of layers\n",
    "    \n",
    "        # Convolutional Layer (7x7 kernel, stride 2, ReLU activation)\n",
    "        # Max Pooling Layer (3x3 pool size, stride 2)\n",
    "        # Residual Blocks (multiple layers with 3x3 convolutions, skip connections)\n",
    "        # (Repeats several times with varying number of layers)\n",
    "        # Average Pooling Layer\n",
    "        # Fully Connected Layer (number of classes, softmax activation)\n",
    "        \n",
    "# DenseNet:\n",
    "    # DenseNet introduced densely connected blocks, where each layer receives input from all previous layers in \n",
    "    # a block. This approach encourages feature reuse and enhances gradient flow. DenseNet architectures have \n",
    "    # significantly fewer parameters compared to traditional CNNs\n",
    "    \n",
    "        # Initial Convolutional Layer (7x7 kernel, stride 2, ReLU activation)\n",
    "        # Dense Blocks (multiple layers with 1x1 and 3x3 convolutions, concatenation)\n",
    "        # (Repeats several times with varying number of layers)\n",
    "        # Transition Blocks (1x1 convolutions, pooling)\n",
    "        # Average Pooling Layer\n",
    "        # Fully Connected Layer (number of classes, softmax activation)\n",
    "        \n",
    "# MobileNet:\n",
    "    # MobileNet is designed for mobile and embedded devices with limited computational resources. It utilizes \n",
    "    # depth-wise separable convolutions to reduce the number of computations while maintaining accuracy. \n",
    "    # MobileNet models are efficient and lightweight\n",
    "    \n",
    "        # Depth-wise Separable Convolution (3x3 depth-wise, 1x1 point-wise, ReLU activation)\n",
    "        # (Repeats several times with varying number of layers and filters)\n",
    "        # Average Pooling Layer\n",
    "        # Fully Connected Layer (number of classes, softmax activation)\n",
    "        \n",
    "# EfficientNet:\n",
    "    # EfficientNet uses a compound scaling method to balance model depth, width, and resolution to achieve \n",
    "    # higher accuracy and efficiency. It leverages a neural architecture search to optimize these scaling coefficients. \n",
    "    # EfficientNet models are known for achieving state-of-the-art performance on various image classification tasks\n",
    "    \n",
    "        # Compound Scaling (balancing depth, width, and resolution)\n",
    "        # Base Architecture (repeats several times with different scaling coefficients)\n",
    "        # (Combines convolutional layers, normalization, activation, and pooling)\n",
    "        # Fully Connected Layer (number of classes, softmax activation)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paul_flask",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
