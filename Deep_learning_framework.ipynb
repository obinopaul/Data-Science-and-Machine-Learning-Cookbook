{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#keep alive (right click 'inspect', then 'console', clear console and paste the below code)\n",
    "function ConnectButton(){\n",
    "    console.log(\"Connect pushed\"); \n",
    "    document.querySelector(\"#top-toolbar > colab-connect-button\").shadowRoot.querySelector(\"#connect\").click() \n",
    "}\n",
    "\n",
    "var colab = setInterval(ConnectButton,600000);   #to connect for 60 seconds\n",
    "\n",
    "#clearInterval(connect)     #to clear the keep alive interval"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mounting Drive and Installing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive') \n",
    "\n",
    "#install libraries \n",
    "!pip install -q -r '/content/drive/MyDrive/Colab Notebooks/requirements.txt' \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.datasets import load_iris \n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.model_selection import KFold, train_test_split \n",
    "\n",
    "#deep learning libraries \n",
    "import torch.nn.init as init \n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR \n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset \n",
    "import torchmetrics \n",
    "from torchsummary import summary "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the Data Ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image \n",
    "import torchvision \n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset, random_split\n",
    "from torchvision import datasets \n",
    "from torchvision.datasets import DatasetFolder\n",
    "import torchvision.transforms as transforms "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> Load the Data (generic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "data_mnist = np.loadtxt(open(r\"/content/sample_data/mnist_train_small.csv\" , 'rb'), delimiter = ',' )\n",
    "print(\"shape: \", data_mnist.shape)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "inputs = data_mnist[:,1:]\n",
    "inputs = scaler.fit_transform(inputs)\n",
    "labels = data_mnist[:,0] \n",
    "\n",
    "# train, test = torch.utils.data.random_split(train_dataset, [800, 200]) #train/test split \n",
    "X_train, X_test, y_train, y_test = train_test_split(inputs, labels, random_state=23, train_size=0.9)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "\n",
    "# inputs \n",
    "X_train = torch.tensor(np.array(X_train), dtype=torch.float32)\n",
    "X_test = torch.tensor(np.array(X_test), dtype=torch.float32)\n",
    "y_train = torch.tensor(np.array(y_train), dtype=torch.long)\n",
    "y_test = torch.tensor(np.array(y_test), dtype=torch.long)\n",
    "\n",
    "#dataset \n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> Load the Data (torchvision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the transformation to apply to the images\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Resize images to a fixed size\n",
    "    transforms.ToTensor(),          # Convert images to tensors\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalize image tensors\n",
    "]) \n",
    "\n",
    "#1. Using ImageFolder\n",
    "# Load the dataset from the image folders \n",
    "dataset = torchvision.datasets.ImageFolder(root='Dataset/', transform=transform)\n",
    "class_labels = dataset.classes # Get the class labels\n",
    "print(class_labels) # Print the class labels\n",
    "\n",
    "\n",
    "#2. Using a DatasetFolder\n",
    "# Create an instance of the DatasetFolder\n",
    "dataset = torchvision.datasets.DatasetFolder(\n",
    "                            root='Dataset/',\n",
    "                            loader=torchvision.datasets.folder.default_loader,  # Use the default image loader\n",
    "                            extensions=\".jpg\",  # Specify the file extensions of the images\n",
    "                            transform=transform  # Apply the defined transformation pipeline\n",
    "                            )\n",
    "\n",
    "\n",
    "#3. Using Custom Dataset\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.data = pd.read_csv(csv_file)  # Read the CSV file\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.data.iloc[idx, 0]  # Get the image file name from the CSV\n",
    "        img_path = os.path.join(self.root_dir, img_name)\n",
    "        image = Image.open(img_path).convert('RGB')  # Open and convert the image to RGB\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)  # Apply transformations if provided\n",
    "\n",
    "        label = self.data.iloc[idx, 1]  # Get the corresponding label from the CSV\n",
    "\n",
    "        return image, label\n",
    "\n",
    "face_dataset = CustomImageDataset(csv_file='data/faces/face_landmarks.csv',\n",
    "                                    root_dir='data/faces/')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#When using ImageFolder, DatasetFolder, or a custom dataset to load your data, you can split it into training and \n",
    "# testing sets using the random_split function from PyTorch\n",
    "\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "train_size = int(0.8 * len(dataset))  # 80% for training, adjust as desired\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> Data Augmentation (only to train dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Noise Data Augmentation \n",
    "\n",
    "import torchvision.transforms.functional as TF\n",
    "\n",
    "def add_guassian_noise_to_dataset(dataset, mean=0, std=0.1):\n",
    "    \"\"\"\n",
    "    Adds random Gaussian noise to an image dataset.\n",
    "\n",
    "    Args:\n",
    "        dataset (torch.utils.data.Dataset): The image dataset.\n",
    "        mean (float): Mean of the Gaussian noise (default: 0).\n",
    "        std (float): Standard deviation of the Gaussian noise (default: 0.1).\n",
    "\n",
    "    Returns:\n",
    "        torch.utils.data.Dataset: The noisy image dataset.\n",
    "    \"\"\"\n",
    "    noisy_dataset = []\n",
    "    \n",
    "    for image, label in dataset:\n",
    "        # Convert the image to a tensor\n",
    "        tensor = TF.to_tensor(image)\n",
    "\n",
    "        # Generate random noise with the same shape as the image tensor\n",
    "        noise = torch.randn_like(tensor) * std + mean\n",
    "\n",
    "        # Add the noise to the image tensor\n",
    "        noisy_tensor = tensor + noise\n",
    "\n",
    "        # Convert the noisy tensor back to an image\n",
    "        noisy_image = TF.to_pil_image(noisy_tensor)\n",
    "    \n",
    "    return noisy_image \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To Augment samples of the loaded dataset and then concatenate it with the original dataset (remember to only use \n",
    "# transforms.ToTensor() when loading the original datasets)\n",
    "\n",
    "from torch.utils.data import Dataset, ConcatDataset\n",
    "\n",
    "class AugmentedDataset(Dataset):\n",
    "    def __init__(self, original_dataset, augmentation_transforms, augmentation_ratio ):\n",
    "        self.original_dataset = original_dataset\n",
    "        self.augmentation_transforms = augmentation_transforms\n",
    "        self.augmentation_ratio  = augmentation_ratio \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Retrieve an item from the original dataset\n",
    "        original_image, original_label = self.original_dataset[index]\n",
    "\n",
    "        augmented_images = []\n",
    "        augmented_labels = []\n",
    "\n",
    "        # Randomly select samples for augmentation\n",
    "        num_augmented_samples = int(len(self.original_dataset) * self.augmentation_ratio)\n",
    "        selected_indices = random.sample(range(len(self.original_dataset)), num_augmented_samples)\n",
    "\n",
    "        # Generate augmented samples for selected indices\n",
    "        for idx in selected_indices:\n",
    "            original_image, _ = self.original_dataset[idx]\n",
    "            augmented_image = self.augmentation_transforms(original_image)\n",
    "            augmented_images.append(augmented_image)\n",
    "            augmented_labels.append(original_label)\n",
    "\n",
    "        # Concatenate the original sample with the augmented samples\n",
    "        augmented_images.append(original_image)\n",
    "        augmented_labels.append(original_label)\n",
    "\n",
    "        # Return concatenated tensors\n",
    "        return torch.stack(augmented_images), torch.tensor(augmented_labels)\n",
    "\n",
    "    def __len__(self):\n",
    "        # Calculate the length of the augmented dataset\n",
    "        return len(self.original_dataset) * (self.augmentation_ratio + 1) \n",
    "\n",
    "# Define the transformations for augmentation\n",
    "augmentation_transforms = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(degrees=10),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.Lambda(lambda x: add_guassian_noise_to_dataset(x, mean=0, std=0.1)),  #noise data augmentation (uniform)\n",
    "    transforms.ToTensor()\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augment the train dataset\n",
    "\n",
    "# Set the augmentation ratio (e.g., 50%)\n",
    "augmentation_ratio = 0.5\n",
    "\n",
    "# Create the augmented dataset by concatenating augmented samples with the original dataset\n",
    "augmented_dataset = AugmentedDataset(train_dataset, augmentation_transforms, augmentation_ratio)\n",
    "\n",
    "# Now, you can use the combined_dataset for training or further processing "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> Data Balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "\n",
    "# Assuming you already have the augmented_dataset\n",
    "\n",
    "# Calculate the class frequencies in the augmented dataset\n",
    "class_counts = [0] * len(augmented_dataset.classes)\n",
    "for _, label in augmented_dataset:\n",
    "    class_counts[label] += 1\n",
    "\n",
    "# Calculate the weights for each sample based on class frequencies\n",
    "weights = [1.0 / class_counts[label] for _, label in augmented_dataset]\n",
    "\n",
    "# Create a sampler with weighted sampling\n",
    "sampler = WeightedRandomSampler(weights, len(augmented_dataset), replacement=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataloader\n",
    "batch_size = 32\n",
    "shuffle = True \n",
    "drop_last = True\n",
    "\n",
    "train_dataloader = DataLoader(augmented_dataset, batch_size=batch_size, shuffle=shuffle, \n",
    "                                drop_last=drop_last, sampler=sampler)\n",
    "test_dataloader = DataLoader(test_dataset, shuffle = False, batch_size=test_dataset.tensors[0].shape[0]) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> Build the Model from Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model \n",
    "\n",
    "#1\n",
    "\n",
    "class iris_model(nn.Module):\n",
    "    \"\"\"Some Information about iris_model\"\"\"\n",
    "    def __init__(self, weight_init='default'):\n",
    "        super(iris_model, self).__init__()\n",
    "        self.fc1 = nn.Linear(4, 64)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, 3)\n",
    "        \n",
    "        if weight_init == 'default':\n",
    "            pass  # Default weight initialization\n",
    "\n",
    "        elif weight_init == 'xavier_uniform':\n",
    "            self._init_weights_xavier_uniform()\n",
    "\n",
    "        elif weight_init == 'kaiming_normal':\n",
    "            self._init_weights_kaiming_normal()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.fc1(x))\n",
    "        # out = self.fca(out) \n",
    "        out = F.relu(self.fc2(out))\n",
    "        # out = self.fcb(out)\n",
    "        out = self.fc3(out)\n",
    "        return out\n",
    "\n",
    "    def _init_weights_xavier_uniform(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                init.xavier_uniform_(m.weight)\n",
    "                if m.bias is not None:\n",
    "                    init.constant_(m.bias, 0)\n",
    "\n",
    "    def _init_weights_kaiming_normal(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                init.kaiming_normal_(m.weight, mode='fan_in', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    init.constant_(m.bias, 0)\n",
    "\n",
    "model = iris_model(weight_init='default')    #initializing the model  #model = iris_model(weight_init='xavier_uniform') \n",
    "\n",
    "\n",
    "#2\n",
    "\n",
    "# def create_model(nUnits, nLayers, weight_init):\n",
    "#     class iris_model(nn.Module):\n",
    "#         def __init__(self):\n",
    "#             super().__init__()\n",
    "\n",
    "#             # Create dictionary to store the layers\n",
    "#             self.layers = nn.ModuleDict()\n",
    "#             self.nLayers = nLayers \n",
    "#             self.weight_init = weight_init\n",
    "\n",
    "#             ### Input layer\n",
    "#             self.layers['input'] = nn.Linear(4, nUnits)\n",
    "#             self.layers['input_bn'] = nn.BatchNorm1d(nUnits)\n",
    "#             self.layers['input_dropout'] = nn.Dropout(0.2)\n",
    "            \n",
    "#             ### Hidden layers\n",
    "#             for i in range(nLayers):\n",
    "#                 self.layers[f'hidden{i}'] = nn.Linear(nUnits, nUnits)\n",
    "#                 self.layers[f'hidden{i}_bn'] = nn.BatchNorm1d(nUnits)\n",
    "#                 self.layers[f'hidden{i}_dropout'] = nn.Dropout(0.2)\n",
    "\n",
    "#             ### Output layer\n",
    "#             self.layers['output'] = nn.Linear(nUnits, 3)\n",
    "        \n",
    "#             # Initialize weights\n",
    "#             self._initialize_weights()\n",
    "            \n",
    "        \n",
    "#         # Forward pass\n",
    "#         def forward(self, x):\n",
    "#             # Input layer\n",
    "#             x = self.layers['input'](x)\n",
    "#             x = self.layers['input_bn'](x)\n",
    "#             x = F.relu(x)\n",
    "#             x = self.layers['input_dropout'](x)\n",
    "\n",
    "#             # Hidden layers\n",
    "#             for i in range(self.nLayers):\n",
    "#                 x = self.layers[f'hidden{i}'](x)\n",
    "#                 x = self.layers[f'hidden{i}_bn'](x)\n",
    "#                 x = F.relu(x)\n",
    "#                 x = self.layers[f'hidden{i}_dropout'](x)\n",
    "                \n",
    "#             # Output layer\n",
    "#             x = self.layers['output'](x)    #or x = F.sigmoid(self.layers['output](x)) for Binary classification \n",
    "            \n",
    "#             return x \n",
    "        \n",
    "#         def _initialize_weights(self):\n",
    "#             for name, module in self.layers.items():\n",
    "#                 if isinstance(module, nn.Linear):\n",
    "#                     weight_init = self.weight_init.get(name, 'default') #works well with sigmoid (uniform distribution)\n",
    "#                     if weight_init == 'xavier_uniform':     #works well with sigmoid\n",
    "#                         init.xavier_uniform_(module.weight)\n",
    "#                     elif weight_init == 'kaiming_normal':   #works well with ReLU activation \n",
    "#                         init.kaiming_normal_(module.weight)\n",
    "#                     if module.bias is not None:\n",
    "#                         init.constant_(module.bias, 0)\n",
    "    \n",
    "#     return iris_model()\n",
    "\n",
    "# nUnits = 64\n",
    "# nLayers = 5\n",
    "# weight_init = {\n",
    "#     'input': 'default',\n",
    "#     'hidden0': 'kaiming_normal',\n",
    "#     'hidden1': 'kaiming_normal',\n",
    "#     'hidden2': 'kaiming_normal',\n",
    "#     # 'hidden3': 'kaiming_normal',\n",
    "#     'output': 'default'\n",
    "# }\n",
    "\n",
    "# model = create_model(nUnits, nLayers, weight_init)    #initializing the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> Use a Pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model training \n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "## metric = torchmetrics.Accuracy(task='multiclass', num_classes=num_classes)    (.Precision(), .Recall(), .F1Score(), .ConfusionMatrix())\n",
    "                #see doc. https://torchmetrics.readthedocs.io/en/stable/classification/accuracy.html#functional-interface \n",
    "           \n",
    "num_epochs = 50\n",
    "learning_rate = 0.0032734813343726263\n",
    "losses = torch.zeros(num_epochs)\n",
    "ongoing_accuracy = []\n",
    "ongoing_accuracy_test = []\n",
    "num_classes = 10\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=0.0008018107002058151)\n",
    "\n",
    "# Define the learning rate scheduler\n",
    "scheduler = StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Move the model and data to the appropriate device (e.g., GPU if available)\n",
    "model.to(device)\n",
    "\n",
    "# Variables to track the best model and accuracy\n",
    "best_accuracy = 0.0\n",
    "best_model_state = None\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    batchAcc = []\n",
    "    batchLoss = []\n",
    "\n",
    "    # Iterate over the training dataloader\n",
    "    for inputs, labels in train_dataloader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        batchLoss.append(loss.item())\n",
    "\n",
    "        # Compute accuracy on the training set\n",
    "        predictions = torch.argmax(outputs, axis=1)\n",
    "        accuracy = torchmetrics.functional.classification.accuracy(predictions, labels, task='multiclass',\n",
    "                                                                    num_classes=num_classes) * 100\n",
    "        # accuracy = torchmetrics.functional.classification.accuracy(predictions, labels, task='multiclass', num_classes=num_classes) \n",
    "        #                                                     (or metric(predictions, labels))\n",
    "        # accuracy = torchmetrics.functional.classification.binary_accuracy (predicted, labels, threshold = 0.5)   #for binary classification\n",
    "        # r2score = torchmetrics.functional.r2_score(preds, target) \n",
    "        batchAcc.append(accuracy.item())\n",
    "\n",
    "    # Update the learning rate\n",
    "    scheduler.step()\n",
    "\n",
    "    ongoing_accuracy.append(np.mean(batchAcc.to(device)))\n",
    "    losses[epoch] = np.mean(batchLoss)\n",
    "\n",
    "    # Print loss and accuracy for the epoch\n",
    "    if epoch % 10 == 0:\n",
    "      print(f\"Epoch {epoch}/{num_epochs}: Loss = {np.mean(batchLoss):.4f}, Accuracy = {np.mean(batchAcc):.2f}%\")\n",
    "\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        batchAcc_test = []\n",
    "        for data in test_dataloader:\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            # Calculate predictions\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "            accuracy = torchmetrics.functional.classification.accuracy(predicted, labels,\n",
    "                                                                    task='multiclass', \n",
    "                                                                       num_classes=num_classes) * 100\n",
    "            batchAcc_test.append(accuracy.cpu())\n",
    "            \n",
    "    test_accuracy = np.mean(batchAcc_test)\n",
    "    ongoing_accuracy_test.append(test_accuracy)\n",
    "\n",
    "    if test_accuracy > best_accuracy:\n",
    "        best_accuracy = test_accuracy\n",
    "        best_model_state = model.state_dict().copy()\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Accuracy on test set: {test_accuracy:.2f}%\")\n",
    "\n",
    "print('Finished Training')\n",
    "print(' ')\n",
    "\n",
    "# Load the best model state\n",
    "model.load_state_dict(best_model_state)\n",
    "\n",
    "# Report accuracy\n",
    "print('Final accuracy (eval): {:.2f}%'.format(ongoing_accuracy_test[-1]))\n",
    "print('Best accuracy (eval): {:.2f}%'.format(best_accuracy)) \n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(13, 4))\n",
    "\n",
    "ax[0].plot(losses.detach())\n",
    "ax[0].set_ylabel('Loss')\n",
    "ax[0].set_xlabel('Epoch')\n",
    "ax[0].set_title('Losses')\n",
    "\n",
    "ax[1].plot(ongoing_accuracy, label='Training Accuracy')\n",
    "ax[1].plot(ongoing_accuracy_test, label='Evaluation Accuracy')\n",
    "ax[1].set_ylabel('Accuracy')\n",
    "ax[1].set_xlabel('Epoch')\n",
    "ax[1].set_title('Accuracy')\n",
    "ax[1].legend()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# run training again to see whether this performance is consistent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> Confusion Matrix, Precision, Recall, Accuracy, F1-Score, AUC ROC Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (roc_auc_score,roc_curve,precision_recall_curve, auc,\n",
    "                             classification_report, confusion_matrix, average_precision_score,\n",
    "                             accuracy_score,silhouette_score,mean_squared_error)\n",
    "from inspect import signature\n",
    "\n",
    "\n",
    "#confusion matrix\n",
    "# accuracy = accuracy_score(y_test, y_pred) \n",
    "class_names = digits.target_names\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                        normalize=False,\n",
    "                        title='Confusion matrix',\n",
    "                        cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function plots a confusion matrix.\n",
    "    \"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    \n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    \n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    \n",
    "    for i, j in np.ndindex(cm.shape):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                horizontalalignment=\"center\",\n",
    "                color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    \n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "\n",
    "plot_confusion_matrix(y_test, y_pred, classes=class_names,\n",
    "                    title='Confusion matrix, Accuracy = {:.2f}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AUC ROC curve (use this for binary classification)\n",
    "\n",
    "def plot_roc(y_actual, y_pred):\n",
    "    \"\"\"\n",
    "    Function to plot AUC-ROC curve\n",
    "    \"\"\"\n",
    "    fpr, tpr, thresholds = roc_curve(y_actual, y_pred)\n",
    "    plt.plot(\n",
    "        fpr,\n",
    "        tpr,\n",
    "        color=\"b\",\n",
    "        label=r\"Model (AUC = %0.2f)\" % (roc_auc_score(y_actual, y_pred)),\n",
    "        lw=2,\n",
    "        alpha=0.8,\n",
    "    )\n",
    "    plt.plot(\n",
    "        [0, 1],\n",
    "        [0, 1],\n",
    "        linestyle=\"--\",\n",
    "        lw=2,\n",
    "        color=\"r\",\n",
    "        label=\"Luck (AUC = 0.5)\",\n",
    "        alpha=0.8,\n",
    "    )\n",
    "    plt.xlim([-0.05, 1.05])\n",
    "    plt.ylim([-0.05, 1.05])\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(\"Receiver operating characteristic example\")\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "    #To choose the threshold value that maximizes the Youden's J statistic\n",
    "    # calculate Youden's J statistic for each threshold value\n",
    "    J = tpr - fpr\n",
    "    best_threshold = thresholds[np.argmax(J)]\n",
    "    print('Best threshold:', best_threshold)\n",
    "    \n",
    "plot_roc(y_actual, y_pred) \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#OR\n",
    "from yellowbrick.classifier import ROCAUC #yellow brick can be used for multiclass classification\n",
    "\n",
    "visualizer = ROCAUC(model, classes=[\"win\", \"loss\", \"draw\"])\n",
    "visualizer.fit(X_train, y_train)        # Fit the training data to the visualizer\n",
    "visualizer.score(X_test, y_test)        # Evaluate the model on the test data\n",
    "visualizer.show()                       # Finalize and render the figure\n",
    "\n",
    "# roc_auc(model, X_train, y_train, X_test=X_test, y_test=y_test, classes=['not_defaulted', 'defaulted']) #quick_method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Classification Report (Precision, Recall, F1-Score)\n",
    "from sklearn.metrics import classification_report\n",
    "from yellowbrick.classifier import classification_report \n",
    "\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# precision measures how many of the positive predictions made by the model are actually correct. \n",
    "# A high precision score indicates that the model is making very few false positive predictions.\n",
    "\n",
    "# recall measures how many of the actual positive instances in the dataset are correctly predicted as positive \n",
    "# by the model. A high recall score indicates that the model is correctly identifying a large proportion of the \n",
    "# positive instances in the dataset.\n",
    "\n",
    "#F1- Score is used to compare precision/recall numbers\n",
    "\n",
    "\n",
    "#OR\n",
    "# Instantiate the visualizer\n",
    "visualizer = classification_report(\n",
    "    model, X_train, y_train, X_test, y_test, classes=classes, support=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Precision - Recall\n",
    "\n",
    "def plot_precisionrecall(y_actual, y_pred):\n",
    "    \"\"\"\n",
    "    Function to plot AUC-ROC curve\n",
    "    \"\"\"\n",
    "    average_precision = average_precision_score(y_actual, y_pred)\n",
    "    precision, recall, _ = precision_recall_curve(y_actual, y_pred)\n",
    "    # In matplotlib < 1.5, plt.fill_between does not have a 'step' argument\n",
    "    step_kwargs = (\n",
    "        {\"step\": \"post\"} if \"step\" in signature(plt.fill_between).parameters else {}\n",
    "    )\n",
    "\n",
    "    plt.figure(figsize=(9, 6))\n",
    "    plt.step(recall, precision, color=\"b\", alpha=0.2, where=\"post\")\n",
    "    plt.fill_between(recall, precision, alpha=0.2, color=\"b\", **step_kwargs)\n",
    "\n",
    "    plt.xlabel(\"Recall\")\n",
    "    plt.ylabel(\"Precision\")\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.title(\"Precision-Recall curve: AP={0:0.2f}\".format(average_precision))\n",
    "\n",
    "plot_precisionrecall(y_actual, y_pred)\n",
    "\n",
    "#from the plot, we can pick a trade-off threshold where both precision and recall are high\n",
    "\n",
    "\n",
    "\n",
    "#OR\n",
    "from yellowbrick.classifier import PrecisionRecallCurve\n",
    "# Create the visualizer, fit, score, and show it\n",
    "viz = PrecisionRecallCurve(model, per_class=True,\n",
    "                            cmap=\"Set1\", iso_f1_curves=True, \n",
    "                            micro=False)\n",
    "viz.fit(X_train, y_train)\n",
    "viz.score(X_test, y_test)\n",
    "viz.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> Analyze Error Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if the errors are normally distributed around zero, it may indicate that the model is making unbiased predictions. \n",
    "# If there is a pattern or trend in the errors, it may suggest that the model has systematic biases or is making \n",
    "# consistent errors in certain regions of the input space\n",
    "\n",
    "\n",
    "\n",
    "def analyze_error_distribution(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Function to analyze the error distribution by plotting histograms and scatter plots.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    y_true : array-like\n",
    "        Array of true labels or ground truth.\n",
    "    y_pred : array-like\n",
    "        Array of predicted values.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    None\n",
    "    \"\"\"\n",
    "    # Calculate errors\n",
    "    errors = y_true - y_pred\n",
    "\n",
    "    # Plot histogram of errors\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.hist(errors, bins=20, alpha=0.75)\n",
    "    plt.xlabel('Error')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Error Distribution (Histogram)')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    # Plot scatter plot of true labels vs. errors\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(y_true, errors, alpha=0.75)\n",
    "    plt.xlabel('True Labels')\n",
    "    plt.ylabel('Error')\n",
    "    plt.title('Error Distribution (Scatter Plot)')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    # Plot scatter plot of predicted values vs. errors\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.scatter(y_pred, errors, alpha=0.75)\n",
    "    plt.xlabel('Predicted Values')\n",
    "    plt.ylabel('Error')\n",
    "    plt.title('Error Distribution (Scatter Plot)')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "analyze_error_distribution(y_val, y_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> Error Analysis - Diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Error analysis is the process of analyzing the errors made by a machine learning model and identifying the patterns \n",
    "# or trends that may be causing the errors. The goal of error analysis is to gain insight into the behavior of the \n",
    "# model and identify areas for improvement.\n",
    "\n",
    "# The steps involved in error analysis:\n",
    "    # Collect error data\n",
    "    # Categorize errors\n",
    "    # Identify patterns\n",
    "    # Analyze causes\n",
    "    # Prioritize fixes\n",
    "    \n",
    "# Based on the insights gained from the error analysis, you can perform the following.\n",
    "# False negatives:\n",
    "# False negatives occur when the model predicts that a customer will not churn when they actually do churn. \n",
    "# To fix this issue, you may consider the following:\n",
    "#     Increase the weight of the features that are more indicative of churn for low-usage customers, \n",
    "#         such as frequency of usage or specific product usage. (adjust the model parameters)\n",
    "#     Add new features that may be predictive of churn, such as customer sentiment or customer service interactions.\n",
    "#     Use a different model architecture that is better suited for handling imbalanced data, such as a decision tree \n",
    "#         or ensemble model.\n",
    "# False positives:\n",
    "# False positives occur when the model predicts that a customer will churn when they actually do not churn. \n",
    "# To fix this issue, you may consider the following:\n",
    "#     Decrease the weight of features that are causing false positives, such as age or income, if they are not as \n",
    "#         indicative of churn for low-usage customers. (adjust the model parameters)\n",
    "#     Remove features that are causing false positives altogether, if they are not providing significant value to the \n",
    "#         model.\n",
    "#     Increase the size of the training dataset to capture a more representative sample of customers who do not churn, \n",
    "#         which may help the model learn more accurately which customers are likely to churn.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot confusion matrix to visualize false positives and false negatives\n",
    "    #By default, scikit-learn will assume that the \"positive\" class is the last label (or highest label value) \n",
    "    # in the list of labels. [0, 1] where 1 is Positive and is the class_of_interest.\n",
    "\n",
    "\n",
    "class_names = [0, 1] #or iris().target_names #this is an example and should be edited. [0, 1] for binary classification\n",
    "class_of_interest = 1 #this selects a specific class of interest other than 1 or the highest value. \n",
    "                        #always select the highest one because that is what Scikit learn uses. \n",
    "\n",
    "def false_positives(X_test, y_true, y_pred, classes):\n",
    "    \"\"\" \n",
    "    This function identifies and plots the false positives in a classification problem. \n",
    "    \"\"\" \n",
    "    fp_indices = np.where((y_true != class_of_interest) & (y_pred == class_of_interest))[0] \n",
    "    fp_features = X_test[fp_indices] # assuming X_test is a numpy array of input data \n",
    "    # fp_features = X_test.iloc[fp_indices]\n",
    "    fp_labels = y_pred[fp_indices] # assuming y_pred is a numpy array of predicted labels \n",
    "    # fp_labels = pd.Series(y_pred).iloc[fp_indices]\n",
    "\n",
    "    print(\"False positives: \", len(fp_indices))\n",
    "    return fp_features, fp_labels\n",
    "\n",
    "\n",
    "#false negatives \n",
    "def false_negatives(X_test, y_true, y_pred, classes):\n",
    "    \"\"\" \n",
    "    This function identifies and plots the false negatives in a classification problem. \n",
    "    \"\"\" \n",
    "    fn_indices = np.where((y_true == class_of_interest) & (y_pred != class_of_interest))[0] \n",
    "    fn_features = X_test[fn_indices] # assuming X_test is a numpy array of input data\n",
    "    # fn_features = X_test.iloc[fn_indices] \n",
    "    fn_labels = y_pred[fn_indices] # assuming y_pred is a numpy array of predicted labels \n",
    "    # fn_labels = pd.Series(y_pred).iloc[fn_indices]\n",
    "\n",
    "    print(\"False negatives: \", len(fn_indices))\n",
    "    return fn_features, fn_labels\n",
    "\n",
    "\n",
    "# Plot the confusion matrix to evaluate the performance of the model\n",
    "plot_confusion_matrix(y_test, y_pred, classes=classes,\n",
    "                    title='Confusion matrix, Accuracy = {:.2f}'.format(accuracy))\n",
    "\n",
    "# Identify and plot the false positives\n",
    "X_fp, y_fp = false_positives(X_test, y_test, y_pred, class_names)\n",
    "\n",
    "# Identify and plot the false negatives\n",
    "X_fn, y_fn = false_negatives(X_test, y_test, y_pred, class_names)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Optimization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> Auto Tune using Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# Define your objective function\n",
    "def objective(trial):\n",
    "    # Define your hyperparameters to be tuned\n",
    "    learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1) \n",
    "    nUnits = trial.suggest_categorical('nUnits', 4, 128, step=8) \n",
    "    nLayers = trial.suggest_int('nLayers', 1, 6, step = 1) \n",
    "    weight_decay = trial.suggest_loguniform('weight_decay', 1e-6, 1e-3)\n",
    "    dropout_rate = trial.suggest_uniform('dropout_rate', 0.0, 0.5)    \n",
    "    batch_size = trial.suggest_categorical('batch_size', [16, 32, 64])    \n",
    "    # weight_inits = trial.suggest_categorical('weight_init', ['default', 'kaiming_normal', 'xavier_uniform_']) \n",
    "    # num_epochs = trial.suggest_int('num_epochs', 30, 300)  \n",
    "    # optimizer = trial.suggest_categorical('optimizer', ['adam', 'sgd'])\n",
    "    # activation = trial.suggest_categorical('activation', ['relu', 'sigmoid', 'tanh'])\n",
    "    # patience = trial.suggest_int('patience', 5, 20)\n",
    "\n",
    "    # Define your model architecture with the hyperparameters\n",
    "    model = mnist_model(nUnits, nLayers, weight_inits, dropout_rate) \n",
    "\n",
    "    num_epochs = 50\n",
    "    learning_rate = learning_rate\n",
    "    losses = torch.zeros(num_epochs)\n",
    "    ongoing_accuracy = []\n",
    "    num_classes = 10\n",
    "\n",
    "    # Define the loss function and optimizer\n",
    "    criterion = nn.NLLLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay = weight_decay) \n",
    "\n",
    "    # Define the learning rate scheduler\n",
    "    scheduler = StepLR(optimizer, step_size=30, gamma=0.1)\n",
    "\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    # Move the model and data to the appropriate device (e.g., GPU if available)\n",
    "    model.to(device)\n",
    "\n",
    "    # Loop over the dataset for multiple epochs\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        batchAcc  = []\n",
    "        batchLoss = []\n",
    "\n",
    "        # Iterate over the training dataloader\n",
    "        for inputs, labels in train_dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            batchLoss.append(loss.item())\n",
    "\n",
    "            # Compute accuracy on the training set\n",
    "            predictions = torch.argmax(outputs, axis=1)\n",
    "            accuracy = torchmetrics.functional.classification.accuracy(predictions, labels, task='multiclass',\n",
    "                                                                        num_classes=num_classes) * 100\n",
    "            batchAcc.append(accuracy.item())\n",
    "\n",
    "        # Update the learning rate\n",
    "        scheduler.step()\n",
    "\n",
    "        ongoing_accuracy.append(np.mean(batchAcc))\n",
    "        losses[epoch] = np.mean(batchLoss)\n",
    "\n",
    "\n",
    "        #evaluation\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "    # Disable gradient computation for evaluation\n",
    "    with torch.inference_mode():        #or torch.no_grad()\n",
    "        for data in test_dataloader:\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            # Calculate predictions\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    # accuracy = 100 * (total_correct / total_samples)\n",
    "    accuracy = torchmetrics.functional.classification.accuracy(predicted, labels, task='multiclass', num_classes=num_classes) * 100\n",
    "\n",
    "    return accuracy \n",
    "\n",
    "# Define the study\n",
    "study = optuna.create_study(direction='maximize')\n",
    "\n",
    "# Run the optimization\n",
    "study.optimize(objective, n_trials=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best hyperparameters\n",
    "print(\" Value: \", study.best_trial.value)\n",
    "print(\" Params: \")\n",
    "for key, value in study.best_trial.params.items():\n",
    "    print(f\"    {key}: {value}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Save the model checkpoint\n",
    "checkpoint = {\n",
    "    'epoch': 300,\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'loss': loss,\n",
    "    'learning_rate': optimizer.param_groups[0]['lr'],\n",
    "    'hyperparameters': {\n",
    "                'hidden_units': 64,\n",
    "                'batch_size': 32\n",
    "                        },\n",
    "    # 'other_info': 'Additional information about the checkpoint'\n",
    "}\n",
    "\n",
    "torch.save(checkpoint, 'model_checkpoint.pth')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "paul_flask",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
