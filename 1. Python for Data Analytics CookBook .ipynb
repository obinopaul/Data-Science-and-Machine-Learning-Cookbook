{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0637b7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "https://www.kaggle.com/prashant111/code \n",
    "\n",
    "#for all the notebook tutorials on Machine Learning "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79c2c80",
   "metadata": {},
   "source": [
    "#### Python Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f3b5cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Operators \n",
    "    # - Arithmetic operators: +, -, *, **, /, // (floor division), % (modulus) \n",
    "    # - Comparison operators: ==, !=, >, <, >=, <= (returns True or False) \n",
    "    # - Logical operators: and, or, not \n",
    "    # - Identity Operators: is, is not\n",
    "    # - Assignment operators: =, +=, -=, *=, /=, //=, %=, &=, |=, \n",
    "    # - Membership operators: in, not in \n",
    "    # - Bitwise shift operators: <<, >> \n",
    "    # - Unary operators: +, -, ~, not \n",
    "    # - String concatenation operator: \"+\" \n",
    "\n",
    "\n",
    "# # Lambda Function\n",
    "    # - The lambda function can be used to create small anonymous functions.\n",
    "    #   Syntax: lambda arguments : expression\n",
    "        # Example: f = lambda x : 2*x+3\n",
    "        #          print(f(5)) -> prints 16\n",
    "\n",
    "\n",
    "# Data types\n",
    "    myInt = int() # 1. Integer: A whole number like 4203987654.\n",
    "    myFloat = float() # 2. Floats/Doubles: Decimal numbers with a decimal point such as 3.14159.\n",
    "    myString = \"\" # 3. String: Text enclosed by quotes \"example\" or 'example'.\n",
    "    myBool = False # 4. Boolean: True of False.\n",
    "    myList = [] # 5. Lists: ordered collection of items inside square brackets [].\n",
    "    myTuple = () # 6. Tuples: ordered collection of immutable items inside parentheses ().\n",
    "    mySet = set() # 7. Sets: unordered collection of unique elements {}.\n",
    "    myDict = {} # 8. Dictionaries: key : value pairs {}\n",
    "\n",
    "        # String to Other Types\n",
    "        int_value = int(\"123\")  # String to Integer: Converts \"123\" to 123\n",
    "        float_value = float(\"123.45\")  # String to Float: Converts \"123.45\" to 123.45\n",
    "        list_value = list(\"abc\")  # String to List: Converts \"abc\" to ['a', 'b', 'c']\n",
    "        tuple_value = tuple(\"abc\")  # String to Tuple: Converts \"abc\" to ('a', 'b', 'c')\n",
    "        dict_value = eval(\"{'key': 'value'}\")  # String to Dictionary: Converts \"{'key': 'value'}\" to {'key': 'value'}\n",
    "\n",
    "        # Integer/Float to Other Types\n",
    "        str_from_int_float = str(123)  # Integer/Float to String: Converts 123 to \"123\"\n",
    "        float_from_int = float(123)  # Integer to Float: Converts 123 to 123.0\n",
    "        int_from_float = int(123.45)  # Float to Integer: Converts 123.45 to 123\n",
    "\n",
    "        # List to Other Types\n",
    "        str_from_list = ''.join(['a', 'b', 'c'])  # List to String: Converts ['a', 'b', 'c'] to \"abc\"\n",
    "        tuple_from_list = tuple(['a', 'b', 'c'])  # List to Tuple: Converts ['a', 'b', 'c'] to ('a', 'b', 'c')\n",
    "        dict_from_list = dict([('key1', 'value1'), ('key2', 'value2')])  # List to Dictionary: Converts [('key1', 'value1'), ('key2', 'value2')] to {'key1': 'value1', 'key2': 'value2'}\n",
    "        numpy_array_from_list = np.array([1, 2, 3])  # List to NumPy Array: Converts [1, 2, 3] to NumPy array\n",
    "\n",
    "        # Tuple to Other Types\n",
    "        str_from_tuple = ''.join(('a', 'b', 'c'))  # Tuple to String: Converts ('a', 'b', 'c') to \"abc\"\n",
    "        list_from_tuple = list(('a', 'b', 'c'))  # Tuple to List: Converts ('a', 'b', 'c') to ['a', 'b', 'c']\n",
    "        dict_from_tuple = dict((('key1', 'value1'), ('key2', 'value2')))  # Tuple to Dictionary: Converts (('key1', 'value1'), ('key2', 'value2')) to {'key1': 'value1', 'key2': 'value2'}\n",
    "\n",
    "        # Dictionary to Other Types\n",
    "        list_from_dict = list({'key': 'value'}.items())  # Dictionary to List: Converts {'key': 'value'} to [('key', 'value')]\n",
    "        tuple_from_dict = tuple({'key': 'value'}.items())  # Dictionary to Tuple: Converts {'key': 'value'} to (('key', 'value'),)\n",
    "        str_from_dict = str({'key': 'value'})  # Dictionary to String: Converts {'key': 'value'} to \"{'key': 'value'}\"\n",
    "\n",
    "        # Converting to and from JSON\n",
    "        json_str_from_dict = json.dumps({'key': 'value'})  # Dictionary to JSON String: Converts {'key': 'value'} to '{\"key\": \"value\"}'\n",
    "        dict_from_json_str = json.loads('{\"key\": \"value\"}')  # JSON String to Dictionary: Converts '{\"key\": \"value\"}' to {'key': 'value'}\n",
    "        \n",
    "        # Converting to and from Pandas DataFrame\n",
    "        df_from_dict = pd.DataFrame({'col1': [1, 2], 'col2': [3, 4]})  # Dictionary to DataFrame\n",
    "        dict_from_df = df_from_dict.to_dict()  # DataFrame to Dictionary\n",
    "        list_from_series = pd.Series([1, 2, 3]).tolist()  # Converts Series to list\n",
    "        dict_from_series = pd.Series([1, 2, 3]).to_dict()  # Converts Series to dictionary\n",
    "        numpy_array_from_df_column = df['A'].to_numpy()  # Converts specific DataFrame column to NumPy array\n",
    "\n",
    "        # Converting to and from NumPy Arrays\n",
    "        numpy_array_from_list_tuple = np.array([1, 2, 3])  # List/Tuple to NumPy Array\n",
    "        list_from_numpy_array = numpy_array_from_list_tuple.tolist()  # NumPy Array to List\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Control Flow Statements\n",
    "    # 1. if statement: checks condition and executes code block if true.\n",
    "    # 2. elif statement: else if clause to an if statement.\n",
    "    # 3. else statement: executes when no other conditions are met.\n",
    "    # 4. while loop: repeats until specified condition is false.\n",
    "    # 5. break statement: breaks out of current closest looping structure.\n",
    "    # 6. continue statement: skips rest of current iteration and goes back to beginning of next iteration.\n",
    "    # 7. for loops: iterate over each item in something iterable(list, tuple etc.).\n",
    "    \n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterable:\n",
    "# Iterable: An object is called iterable if we can get an iterator from it. Examples of iterables include all sequence types \n",
    "# (such as list, str, tuple) and some non-sequence types like dict, file objects, and objects of any classes you define with an __iter__() \n",
    "# or __getitem__() method.\n",
    "\n",
    "# Iterator:\n",
    "# Iterator: An iterator is an object that can be iterated upon and which returns data, one element at a time when next() is called on it. \n",
    "# In Python, an iterator must implement two methods:  \n",
    "    # __iter__() which returns the iterator object itself. This is used in for and in statements.\n",
    "    # __next__() which returns the next value from the iterator. If there is no more items to return, it should raise StopIteration exception.\n",
    "    my_list = [\"go\", \"hello\", 23, 10, 12, 19]\n",
    "    my_iter = iter(my_list)  # Create an iterator\n",
    "\n",
    "    for _ in range(4):\n",
    "        print(next(my_iter))\n",
    "    \n",
    "    \n",
    "    \n",
    "#basic Python Functions and Operations\n",
    "# built in functions\n",
    "\n",
    "int, bool, tuple, str, chr, list, set, dict, \n",
    "all, any, dir, type, help,\n",
    "enumerate, filter, zip, zip(*zipped)-> unzip, input, isinstance, iter or __iter__(), next or __next__(),\n",
    "len, map, min, max, pow, print, range, reversed, round, sorted, sum, super, \n",
    "\n",
    "#functions of list, strings, dictionary, tuples etc\n",
    "dir(list)\n",
    "dir(str)\n",
    "dir(dict)\n",
    "dir(tuple)\n",
    "\n",
    "# python built-in functions\n",
    "import builtins\n",
    "dir(builtins)\n",
    "\n",
    "# other python libraries\n",
    "import pkgutil\n",
    "standard_lib = sorted([module for _, module, _ in pkgutil.iter_modules()])  # sorted list of all standard library module names.\n",
    "\n",
    "for module in standard_lib:\n",
    "    print(module)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8cb913c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#List Manipulation\n",
    "val = [10, 12, 23, 24, 22]  # Sample List for reference\n",
    "\n",
    "\" \".join(my_list)   # convert a list to string\n",
    "my_string.split(\" \") # convert a string to list | or list(my_string)\n",
    "del val[1]  # Removing an item by index (delete)\n",
    "first_item = val[0]  # Accessing an item\n",
    "first_two = val[:2]  # Slicing the list\n",
    "list('Hello') # Creates a list from the string.\n",
    "list(range(5)) # Creates a list from the range object.\n",
    "list.append('Hello') # Adds an item to the end of the list.\n",
    "list.count('Hello') # Counts the occurrences of an item in the list.\n",
    "list.extend('Hello') # Adds all items of an iterable to the end of the list.\n",
    "list.index('Hello') # Returns the index of an item in the list.\n",
    "list.insert(0, 'Hello') # Inserts an item at a specified position in the list.\n",
    "list.pop() # Removes an item from the list.\n",
    "list.remove('Hello') # Removes the first occurrence of an item from the list.\n",
    "list.reverse() # Reverses the order of the items in the list.\n",
    "list.sort() # Sorts the items in the list.\n",
    "val.sort(key=lambda x: x[0])  # Sorting the list by the first element\n",
    "for i in val:\n",
    "    if isinstance(i, list):\n",
    "        print(\"List\")\n",
    "print(\",\".join(sorted(list(set(words)))))\n",
    "\n",
    "\n",
    "# List Operations\n",
    "val.clear()  # Clearing the list\n",
    "copied = val.copy()  # Copying the list\n",
    "repeated = val * 2  # Multiplying the list (repeating it)\n",
    "\n",
    "\n",
    "#List Comprehensions (with Lambda Functions)\n",
    "        # Expression: [expression for item in iterable if condition]\n",
    "filtered = [item for item in val if item[0] == 20]  # Filtering the list\n",
    "[num for sublist in val for num in sublist]  # Flattening the list\n",
    "[[x+1, y+1] for x, y in val]  # Increase each element\n",
    "[i**3 if i %2 else i**2 for i in numbers]\n",
    "are_all_greater_than_20 = all(x[0] > 20 for x in val)  # Check if all items meet a condition\n",
    "is_any_greater_than_50 = any(x[1] > 50 for x in val)  # Check if any item meets a condition\n",
    "flattened_even = [y for x in val for y in x if y % 2 == 0]  # Nested list comprehension\n",
    "\n",
    "\n",
    "# Advanced List Processing\n",
    "another_list = [[30, 40], [40, 50]]  # Combining with another list using zip\n",
    "combined = list(zip(val, another_list))\n",
    "first_elements, second_elements = zip(*val)  # Unzipping a list of pairs\n",
    "as_dict = dict(val)  # Converting list of pairs to a dictionary\n",
    "\n",
    "\n",
    "# List Statistics and Queries\n",
    "count = val.count([20, 45])  # Counting occurrences\n",
    "length = len(val)  # Length of the list\n",
    "exists = [20, 45] in val  # Checking if an item exists in the list\n",
    "maximum = max(val, key=lambda x: x[0])  # Finding the maximum based on the first element\n",
    "minimum = min(val, key=lambda x: x[0])  # Finding the minimum based on the first element\n",
    "total = sum(item[0] for item in val)  # Summing the first elements\n",
    "unique_set = set(tuple(item) for item in val)  # Converting list to a set (for unique values) - set is an unordered collection of unique items\n",
    "\n",
    "\n",
    "# Functional Programming with Lambda\n",
    "        # Expression: lambda arguments: expression\n",
    "            add = lambda x, y: x + y\n",
    "filtered_lambda = list(filter(lambda x: x[0] > 20, val))  # Filtering using a lambda function\n",
    "mapped_lambda = list(map(lambda x: [x[0]*2, x[1]*2], val))  # Mapping using a lambda function\n",
    "max_num = lambda x, y: x if x > y else y  # Using lambda to find the max value\n",
    "\n",
    "\n",
    "# String Manipulation\n",
    "my_string = \"Hello World\"\n",
    "reversed_joined_string = \" \".join(reversed(string.split()))  # Split, reverse, and join to a string\n",
    "new_string = string[:4] + string[4+1:]    # using string concatenation to delete an item\n",
    "new_string = string.replace('0', \"\") # using replace to delete an item\n",
    "new_string = reversed(string)  # Reverse order strings\n",
    "\n",
    "# Advanced List and String Manipulation\n",
    "joined = ', '.join(map(str, val))  # Joining the list into a string\n",
    "str_val = str(val)  # Converting to string and back to list\n",
    "back_to_list = eval(str_val)\n",
    "k = 2  # Rotate by 2 positions\n",
    "rotated = val[k:] + val[:k]  # Rotate the list\n",
    "half = len(val)//2  # Split the list into two halves\n",
    "first_half, second_half = val[:half], val[half:]\n",
    "\n",
    "\n",
    "my_string.lower() # Converts all characters in the string to lowercase. Frequently used for case-insensitive comparisons.\n",
    "my_string.upper() # Converts all characters in the string to uppercase. Often used for standardizing text input.\n",
    "my_string.replace() # Replaces occurrences of a specified substring with another substring.\n",
    "my_string.split() # Divides a string into a list based on a specified delimiter.\n",
    "my_string.join() # Combines a list of strings into a single string, using a specified separator.\n",
    "my_string.find() # Searches for a substring within a string and returns the lowest index where the substring is found.\n",
    "my_string.strip() # Removes leading and trailing characters (spaces by default) from a string.\n",
    "my_string.startswith() # Checks if the string starts with the specified substring.\n",
    "my_string.endswith() # Checks if the string ends with the specified substring.\n",
    "my_string.count() #  Counts occurrences of a substring within the string.\n",
    "my_string.format() # Formats the string in a specified format.\n",
    "my_string.capitalize() # Capitalizes the first character of the string.\n",
    "my_string.title() # Converts the first character of each word to uppercase and the rest to lowercase.\n",
    "\n",
    "\n",
    "my_string.isalnum()   # Checks if all characters in the text are alphanumeric. \n",
    "my_string.isalpha()   # Checks if all characters in the text are letters.\n",
    "my_string.isnumeric() # Checks if all characters in the text are numeric.\n",
    "my_string.isdigit()   # Checks if all characters in the text are digits.\n",
    "my_string.is_integer() # Checks if a floating-point number is an integer.\n",
    "my_string.isdecimal() # Checks if all characters in the text are decimals.\n",
    "my_string.isascii()   # Checks if all characters in the text are ASCII. (ord('A) or chr(65))\n",
    "my_string.isupper()   # Checks if all characters in the text are uppercase.\n",
    "my_string.islower()   # Checks if all characters in the text are lowercase.\n",
    "my_string.isinstance()    # Checks if an object is an instance of a specified type.\n",
    "my_string.issubclass()    # Checks if a class is a subclass of a specified class.\n",
    "my_string.isidentifier()  # Checks if the string is a valid identifier.\n",
    "my_string.isprintable()   # Checks if all characters in the text are printable.\n",
    "my_string.isspace()   # Checks if all characters in the text are whitespaces.\n",
    "my_string.istitle()   # Checks if the string follows the title case style.\n",
    "\n",
    "\n",
    "# Dictionary \n",
    "    my_dict = {'key1': 'value1', 'key2': 'value2', 'key3': 'value3'}\n",
    "    new_dict = {'a': 1, 'b': 2}\n",
    "    my_dict_2 = {'b': 3, 'c': 4}\n",
    "\n",
    "new_dict.update(dict2) # merge dictionaries (similar to append or extend for lists)\n",
    "my_dict.items()    # provides a view on the key-value pairs.\n",
    "my_dict.keys() # provides a view on the keys.\n",
    "my_dict.values()   # provides a view on the values.\n",
    "my_dict[key]    # accessing values\n",
    "my_dict[key] = value    # adding or updating\n",
    "dict1.copy()   # copying a dictionary\n",
    "dict1.clear() # clearing all items\n",
    "dict1.pop('a', 'default value if key not found')   # removes a key-value pair and returns the value.\n",
    "dict1.get('b', 'default value')    # access the value associated with a key, while providing a default value if the key is not found.\n",
    "del dict1['b'] #delete a key\n",
    "{value : key for key, value in dict_one.items() if condition}    #swap keys and values in a dictionary\n",
    "\n",
    "\n",
    "# Using external moduls\n",
    "import itertools\n",
    "chained = list(itertools.chain.from_iterable(val))  # Using itertools.chain to flatten\n",
    "combinations = list(itertools.combinations(val, 2))  # Using itertools.combinations\n",
    "permutations = list(itertools.permutations(val, 2))  # Using itertools.permutations\n",
    "\n",
    "sorted_val = sorted(val, key=lambda x: x[0])  # Using sorted and itertools.groupby\n",
    "grouped = {k: list(g) for k, g in itertools.groupby(sorted_val, key=lambda x: x[0])}\n",
    "\n",
    "import random\n",
    "random.shuffle(val)  # Shuffling the list\n",
    "sample = random.sample(val, 2)  # Taking random samples\n",
    "\n",
    "\n",
    "#Others\n",
    "from functools import reduce\n",
    "total_sum = reduce(lambda acc, x: acc + x[0] + x[1], val, 0)  # Using reduce to sum elements\n",
    "\n",
    "for idx, item in enumerate(val):  # Using enumerate to get index and item\n",
    "    print(idx, item)\n",
    "\n",
    "index_of_first_greater_than_20 = next((i for i, x in enumerate(val) if x[0] > 20), None)  # Finding index with a condition\n",
    "\n",
    "import copy\n",
    "deep_copied = copy.deepcopy(val)  # Deep copy of the list\n",
    "\n",
    "\n",
    "\n",
    "# working with time\n",
    "import time\n",
    "from datetime import datetime, time\n",
    "import pytz #this is much easier to work with time\n",
    "\n",
    "nigeria_timezone = pytz.timezone('Africa/Lagos')    # Set the timezone to Nigeria\n",
    "current_time = datetime.now(nigeria_timezone)   # Get the current time\n",
    "current_time = datetime.datetime.now(nigeria_timezone) # Get the current time in Nigeria\n",
    "formatted_time = current_time.strftime(\"%H:%M:%S\")  # Format the time as desired\n",
    "start_time = time.time()\n",
    "end_time = = time.time()\n",
    "print(\"Time taken by function is %s seconds\" % (end_time - start_time))\n",
    "\n",
    "\n",
    "\n",
    "#Getting Help and Documentation\n",
    "?list.pop  # Get help on the pop method of a list\n",
    "?max # or max? - if it is a baseline function\n",
    "??list.pop  # View the source code of the pop method if possible\n",
    "help(list.pop)  # Get help on the pop method of a list\n",
    "print(list.pop.__doc__)  # Print the documentation string of the pop method\n",
    "print(dir(list))  # List all attributes and methods of the list class\n",
    "\n",
    "import numpy as np  #checking documentation from external libraries\n",
    "help(np.some_function)\n",
    "\n",
    "# Each datatype has its own unique methods, hence its own way of finding documentation\n",
    "my_string = \"Hello, World!\"     # for string\n",
    "help(str.upper)\n",
    "help(my_list.append)    # for list\n",
    "help(my_dict.get)   # for dictionary\n",
    "help(my_tuple.index)   # for tuple\n",
    "help(my_float.is_integer)  # for floating point number\n",
    "\n",
    "\n",
    "import builtins\n",
    "\n",
    "# List all built-in functions and classes\n",
    "builtins_list = dir(builtins)\n",
    "print(builtins_list)\n",
    "print(dir(list))\n",
    "print(dir(str))\n",
    "print(dir(dict))\n",
    "print(dir(tuple))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89347b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Lambda Functions: Anonymous functions defined using the lambda keyword.\n",
    "    # Expression: lambda arguments: expression\n",
    "add = lambda x, y: x + y\n",
    "result = add(3, 5)  # result is 8\n",
    "\n",
    "\n",
    "# List Comprehensions: Concise syntax for creating lists.\n",
    "    # Expression: [expression for item in iterable if condition]\n",
    "numbers = [1, 2, 3, 4, 5]\n",
    "squares = [x ** 2 for x in numbers if x % 2 == 0]\n",
    "# squares will be [4, 16]\n",
    "\n",
    "\n",
    "# Generators: Functions that yield values one at a time using the yield keyword.\n",
    "    # Expression: def generator_function(): yield value\n",
    "def count_up_to(n):\n",
    "    i = 1\n",
    "    while i <= n:\n",
    "        yield i\n",
    "        i += 1\n",
    "\n",
    "gen = count_up_to(5)\n",
    "for num in gen:\n",
    "    print(num)  # Prints 1, 2, 3, 4, 5\n",
    "\n",
    "# Classes:\n",
    "class Person:\n",
    "    def __init__(self, height, shoe_size, shirt_size, pant_size):\n",
    "        self.height = height\n",
    "        self.shoe_size = shoe_size\n",
    "        self.shirt_size = shirt_size\n",
    "        self.pant_size = pant_size\n",
    "\n",
    "    def school(self):   # object functions (methods)\n",
    "        if (self.height > 6) and (self.pant_size) > 35:\n",
    "            return \"University of Oklahoma'\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def work(self, name): # object function (methods)\n",
    "        print(\"{name} is going to work.\")\n",
    "\n",
    "Paul = Person(6.5, 13, \"XXL\", 38)  #instantiating the class (an object)\n",
    "Paul.height # assessing an attribute in the object\n",
    "Paul.school()       # calling a method of the class\n",
    "dir(class_name) # this gives you a list of all the methods of the class.\n",
    "\n",
    "\n",
    "# Decorators: Functions that modify other functions or methods.\n",
    "    # Expression: @decorator_function\n",
    "def my_decorator(func):\n",
    "    def wrapper():\n",
    "        print(\"Something is happening before the function is called.\")\n",
    "        func()\n",
    "        print(\"Something is happening after the function is called.\")\n",
    "    return wrapper\n",
    "\n",
    "@my_decorator\n",
    "def say_hello():\n",
    "    print(\"Hello!\")\n",
    "\n",
    "say_hello()\n",
    "\n",
    "\n",
    "def fibonacci (numb):\n",
    "    if numb < 1:\n",
    "        return \"enter a valid integer > 0\"\n",
    "    elif numb == 1:\n",
    "        return [0]\n",
    "    elif numb == 2:\n",
    "        return [0, 1]\n",
    "    else:\n",
    "        fibonacci = [0, 1]\n",
    "        for i in range(2, numb):\n",
    "            fibonacci.append(fibonacci[-1] + fibonacci[-2])\n",
    "        return fibonacci\n",
    "        \n",
    "\n",
    "print(fibonacci(9))\n",
    "# Context Managers: Used with the with statement to manage resources.\n",
    "    # Expression: with context_manager as resource:\n",
    "with open(\"file.txt\", \"r\") as file:\n",
    "    data = file.read()\n",
    "# File is automatically closed when exiting the 'with' block.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a723f559",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_library (module)\n",
    "|\n",
    "|--- Animal (class)\n",
    "|    |\n",
    "|    |--- __init__(self, name) (method)\n",
    "|    |    |--- self.name (attribute)\n",
    "|    |\n",
    "|    |--- speak(self) (method)\n",
    "|\n",
    "|--- Dog (class, inherits from Animal)\n",
    "|    |\n",
    "|    |--- __init__(self, name, breed) (method)\n",
    "|    |    |--- self.breed (attribute)\n",
    "|    |\n",
    "|    |--- speak(self) (method)\n",
    "|    |--- fetch(self, item) (method)\n",
    "|\n",
    "|--- Cat (class, inherits from Animal)\n",
    "     |\n",
    "     |--- __init__(self, name, color) (method)\n",
    "     |    |--- self.color (attribute)\n",
    "     |\n",
    "     |--- speak(self) (method)\n",
    "     |--- purr(self) (method)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Define the Animal base class\n",
    "class Animal:\n",
    "    def __init__(self, name):\n",
    "        self.name = name  # All animals will have a name\n",
    "\n",
    "    def introduce(self):\n",
    "        return f\"I am an animal and my name is {self.name}.\"\n",
    "\n",
    "# Define the Dog class which inherits from Animal\n",
    "class Dog(Animal):\n",
    "    def __init__(self, name, breed):\n",
    "        super().__init__(name)  # Call the superclass constructor to set the name\n",
    "        self.breed = breed  # Dog-specific attribute\n",
    "\n",
    "    def introduce(self):\n",
    "        # Override the method to include breed specific introduction\n",
    "        return f\"I am a {self.breed} dog and my name is {self.name}.\"\n",
    "\n",
    "# Create an instance of Dog\n",
    "my_dog = Dog(\"Buddy\", \"Golden Retriever\")\n",
    "\n",
    "# Call the introduce method\n",
    "print(my_dog.introduce())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489178c2",
   "metadata": {},
   "source": [
    "> Random Tips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a5dc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(a=None, version=2) # Initialize the random number generator with an optional integer or system time.\n",
    "random.random() # Return the next random floating point number between 0.0 and 1.0.\n",
    "random.uniform(a, b) # Generate a random float r, such that a <= r <= b.\n",
    "random.randint(a, b) # Return a random integer N such that a <= N <= b.\n",
    "random.randrange(start, stop[, step]) # Return a randomly selected element from range(start, stop, step).\n",
    "random.choice(seq) # Return a random element from the non-empty sequence seq.\n",
    "random.choices(population, weights=None, *, cum_weights=None, k=1) # Return a k sized list of elements chosen from the population with replacement. \n",
    "random.shuffle(x[, random]) # Shuffle the sequence x in place. The optional argument random is a 0-argument function returning a random float in [0.0, 1.0).\n",
    "random.sample(population, k) # Return a k length list of unique elements chosen from the population sequence.\n",
    "random.getstate() # Return an object capturing the current internal state of the generator.\n",
    "random.setstate(state) # Restore the internal state of the generator to a state previously captured with getstate().\n",
    "random.getrandbits(k) # Return a python integer with k random bits.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Numpy Tips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Numpy \n",
    "#1D - Vectors\n",
    "#2D - Matrices\n",
    "import numpy as np\n",
    "\n",
    "arr = np.array([[1,2,3], [1,2,3]])\n",
    "arr\n",
    "arr[~np.isnan(arr)] #filter array 'arr' where there are no missing values.\n",
    "\n",
    "\n",
    "#Numpy built-in functions\n",
    "    #creating arrays\n",
    "np.arange(0,11,2) #(start, stop, step)\n",
    "np.linspace(1,5,10) #(start, stop, number of items)\n",
    "np.zeros((3,3)) #(row, col)\n",
    "np.zeros_like(arr)\n",
    "np.ones((2,3)) #(row, col)\n",
    "np.ones_like(arr)\n",
    "np.eye(4) #identity matrix\n",
    "np.empty_like()\n",
    "\n",
    "\n",
    "#creating arrays of random numbers\n",
    "np.random.rand(5) #random samples of a uniform distribution from 0-1\n",
    "    np.random.rand (5,5) #2D random samples from 0-1\n",
    "np.random.randn(2) #random samples from a standard normal distribution centered around zero (0)\n",
    "np.random.randint(5) #returns random integers from a low to a high number\n",
    "    np.random.randint(1,100,10) #(low, high, size) #inclusive on the low end, exclusive on the high end\n",
    "np.random.permutation(np.arange(10)) #to shuffle\n",
    "np.random.choice(a=(3, 10), size=(3,5), replace=False) # returns a random sample from a range of 'a' values for the inputted size. \n",
    "np.random.sample(size=(1, 5), k = 5) #returns k random samples of the inputted size \n",
    "\n",
    "\n",
    "#attributes and methods of Array\n",
    "arr = np.array(range(10))\n",
    "arr.reshape(5,5) #reshape an array (row, col)\n",
    "arr.shape #find the shape of an array\n",
    "\n",
    "\n",
    "#Numpy Indexing and Slicing\n",
    "arr[1:3] = array([1,2]) #for 1D #inclusive on the low end and exclusive on the high end\n",
    "arr[1:2, 0:1] #for 2-D (row, col)\n",
    "arr[0][2] #[row][col]\n",
    "\n",
    "arr[1:2] = 10 #Broadcasting an array #its always best to make a copy before broadcasting an array\n",
    "    arr.copy() #to copy an array\n",
    "\n",
    "\n",
    "#Conditional selection\n",
    "arr[arr>3]\n",
    "arr[(arr<8) & (arr > 4)] #and\n",
    "arr[(arr>5) | (arr < 3)] #or\n",
    "\n",
    "\n",
    "#Useful functions in Numpy\n",
    "np.where(arr==3), np.argwhere(arr==3) or np.unravel_index(3, arr) #find index of 3 in array \"arr\"\n",
    "np.repeat(3,5) or np.tile(arr,5) #repeat number 3, 5 times. #repeat - 1D; tile - 2D\n",
    "    np.tile(arr, (2,2)) #repeat array \"arr\" in 2 rows and 2 cols\n",
    "# we can also have: np.where(condition, x, y), which means \"Replace elements in x with y where the condition is False.\"\n",
    "\n",
    "#plot\n",
    "np.polyfit(x,y)\n",
    "np.polyval(p,x)\n",
    "np.histogram(a, bins=10, range=None, normed=None)\n",
    "\n",
    "np.full((2,4), fill_value=2) #fill an array of 2 rows, 4 cols with the value 2\n",
    "np.unique(arr, return_counts=True) #return_counts = If True, also return the number of times each unique item appears\n",
    "np.T(arr) or arr.T (transpose)\n",
    "\n",
    "#maths\n",
    "np.mean()\n",
    "np.describe()\n",
    "np.sum()\n",
    "np.sort()\n",
    "np.flatten(arr) #flatten from x-dim to 1D\n",
    "np.add(arr_1, arr_2)\n",
    "np.subtract(x,y)\n",
    "np.multiply(x,y)\n",
    "np.divide(x,y)\n",
    "np.min(arr)\n",
    "np.max(arr)\n",
    "np.power(arr)\n",
    "np.sqrt(arr)\n",
    "np.sin(arr)\n",
    "np.floor(arr)\n",
    "np.round(arr)\n",
    "np.std(arr)\n",
    "np.abs(arr)\n",
    "np.var(arr)\n",
    "\n",
    "np.digitize(x, bins, right=False) #to xxxx\n",
    "np.shape or np.reshape()\n",
    "np.expand_dims(ar, axis=0) or np.flatten(arr, axis=0) or np.squeeze(arr, axis=0)\n",
    "np.count_nonzero(arr) #count all non-zero elements\n",
    "np.argwhere(arr)\n",
    "np.argmin(arr) or np.argmax(arr)\n",
    "arr.clip(0,5) #to keep all values of an array within a range\n",
    "np.put(arr, [1,2], [6,7]) #(arr, (indices = [where to replace]), (value = [what to replace it with]))\n",
    "np.astype(int) #change the datatype to integer\n",
    "np.astype(float) #change the datatype to float\n",
    "np.transpose(image, (1, 2, 0)) \n",
    "\n",
    "#set operations\n",
    "np.intersect1d(arr1,arr2) #(arr1 n arr2 ) returns all unique values from the two arrays\n",
    "np.setdiff1d(a,b) #returns al unique elements of a not in b\n",
    "np.setxor1d(a,b) #same with above but in sorted order\n",
    "np.union1d(a,b) (a U b)\n",
    "\n",
    "#splitting\n",
    "np.hsplit(arr, 2) #split the data horizontally (rows) into two equal parts\n",
    "np.vsplit (arr, 3) #split the data vertically (cols) into three equal parts\n",
    "\n",
    "#stacking\n",
    "np.hstack((a, b)) #stack/appends b unto a horizontally (rows)\n",
    "np.vstack((a,b)) #stack/appends b unto a vertically (cols)\n",
    "\n",
    "#comparing\n",
    "np.allclose(a,b, tolerance) #compares two array base in tolerance level\n",
    "np.equal(a,b) #compares elements of both arrays\n",
    "\n",
    "#print options\n",
    "np.set_printoptions(precision=2) #show floats within two decimal points\n",
    "np.set_printoptions(threshold=np.inf) #print array to its max (np.inf - positive infinity)\n",
    "np.printoptions(linewidth = 100) #increase the number of elements in a line\n",
    "\n",
    "#save and load array\n",
    "np.savetxt(\"array.txt\", arr)\n",
    "np.loadtxt(\"array.txt\")\n",
    "\n",
    "#multiply\n",
    "np.multiply(a,b) #multiply two arrays of the same shape\n",
    "np.dot(a,b) #multiply two arrays of different shapes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pandas Tips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "\n",
    "df = pd.Dataframe()\n",
    "\n",
    "# Most used Pandas DataFrame methods - dir(pd.DataFrame)\n",
    "\n",
    "df.head() / df.tail() # Display the first or last few rows of the DataFrame.\n",
    "df.loc[] / df.iloc[] # Access a group of rows and columns by label(s) or integer index.\n",
    "df.columns.get_loc(col) / df.columns.get_index(col) # Get the index of a column in the DataFrame.\n",
    "df.at[3, 'Column B'] / df.iat[-1, 1] # Access a single value for a row/column label pair. \n",
    "df.columns()\n",
    "df.index() / df.reset_index() / df.set_index()  # Set or Reset the index of the DataFrame, and use the default one.\n",
    "& | # and, or df[(df[\"col_4\"] > 0) & (df[\"col_7\" < 7])]\n",
    "pd.isnull() | pd.notnull()  # Detect missing values (NaN in numeric arrays, None/NaN in object arrays).\n",
    "df.melt(id_vars='xx', var_name='xx', value_name='xx')   # Unpivot a DataFrame from wide format to long format.\n",
    "\n",
    "df.groupby() / df.groupby().get_group()  # Group DataFrame using a mapper or by a series of columns.\n",
    "pd.merge(df_1, df_2, how=\"inner\", on = \" \") # Merge DataFrame objects with a database-style join. - (merges on columns)\n",
    "df.concat() \n",
    "df.join(df_2, on=\"inner\") # Join columns with other DataFrame either on index or on a key column.   - (merges on index)\n",
    "df['Name'].str.contains('Sum')  // df.filter(like='Sum', axis=1) // df['Name'].str.startswith('Sum')   # filter a specific column/row (df.filter) or its contents (str.contains)\n",
    "df.sort_values() # Sort by the values along either axis.\n",
    "df.value_counts() # Return a Series containing counts of unique values.\n",
    "df.describe() # Generate descriptive statistics.\n",
    "df.info() # Provide a concise summary of the DataFrame.\n",
    "df.unique(), nunique() # Find unique values / count of unique values.\n",
    "df.sum(), mean(), median(), std(), count() # Compute the sum / mean / median / standard deviation of the values.\n",
    "df.dtypes / df.astype(float) / df.select_dtypes(include=[\"float64\", \"int64\"]) # check the datatype / Cast a pandas object to a specified dtype.\n",
    "pd.to_datetime(df[\"dob\"], infer_datetime_format=True)\n",
    "df.duplicated()\n",
    "df.isin()\n",
    "df.itterrows()  # Iterate over DataFrame rows as (index, Series) pairs.\n",
    "df.drop() / df.pop() / dropna() / df.drop_duplicates() # Remove rows or columns / rows with missing values.\n",
    "df.fillna() / df.ffill# Fill NA/NaN values.\n",
    "df.isna(), isnull() # Detect missing values.\n",
    "df.shape() / df.size()\n",
    "df.copy()\n",
    "df.rename() / df.replace() # Rename or Replace values given in 'to_replace' with 'value'.\n",
    "df.filter(items=[\"lab1\", \"lab2\"], regex='e$', axis=1) # Subset rows or columns of DataFrame according to labels in the specified index.\n",
    "df.apply() / df.applymap(lambda x:x[1:]) # Apply a function along an axis of the DataFrame. use applymap if you want to apply to only an element.\n",
    "df.map() #\n",
    "df.to_csv(), to_excel(), to_json(), to_sql() # Methods to save DataFrame in different formats.\n",
    "df.query('col1 > 30 and col2 == \"Male\"') / df.query('col1.str.startswith(\"J\")')  # pay attention to the single, double quotes and backsticks\n",
    "df.query('index2 == \"Hotel room\" and `col3` <= 300') # Query the columns of a DataFrame with a boolean expression\n",
    "df.apply(pd.to_numeric, errors='coerce') # Convert the DataFrame to numeric values, and coerce the non-convertible values to NaN.\n",
    "pd.to_numeric, pd.to_datetime, pd.to_timedelta, pd.wide_to_long, pd.to_pickle\n",
    "df.to_csv, df.to_dict, df.to_excel, df.to_markdown, df.to_string, df.to_numpy, df.to_pickle, df.to_sql, df.to_stata, df.to_timestamp,\n",
    "\n",
    "\n",
    "df.corr()\n",
    "df.pivot_table() # Create a spreadsheet-style pivot table as a DataFrame.\n",
    "df.plot() # Make plots of DataFrame using matplotlib / plotly.\n",
    "df.copy() # Make a copy of this object's indices and data.\n",
    "df.sample() # Return a random sample of items from an axis of the object.\n",
    "df.notna() / notnull() # Detect existing (non-missing) values.\n",
    "df.idxmax(), idxmin() # Return index of first occurrence of maximum / minimum over requested axis.\n",
    "df.melt() # Unpivot a DataFrame from wide format to long format.\n",
    "df.transpose() # Transpose index and columns of the DataFrame.\n",
    "df.clip() # Trim values at input threshold(s).\n",
    "df = df[~((df['column1'] == value1) & (df['column2'] == value2))]   #How to remove specific row based on condition\n",
    "\n",
    "\n",
    "#How to add an empty column to DataFrame\n",
    "df[\"Blank_Column\"] = \" \" // np.nan // None\n",
    "df2 = df.assign(Blank_Column=\" \", NaN_Column = np.nan, None_Column=None) # Add an empty columns using the assign() method\n",
    "df2 = df.reindex(columns = df.columns.tolist() + [\"None_Column\", \"None_Column_2\"]) # Add multiple columns with NaN , uses columns param\n",
    "df2 = df.reindex(df.columns.tolist() + [\"None_Column\", \"None_Column_2\"],axis=1) # Add multiple columns with NaN, , uses axis param \n",
    "df.insert(0,\"Blank_Column\", \" \") # Using insert(), add empty column at first position\n",
    "df[\"Blank_Column\"] = df.apply(lambda _: ' ', axis=1) # Using apply() & lambda function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Visualization (Matplotlib, Searborn etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "markdown_table = \"\"\"\n",
    "| Plot Type             | Complexity Level | Data Type               | Variable Type | Description |\n",
    "|-----------------------|------------------|-------------------------|---------------|-------------|\n",
    "| Histogram             | Basic            | Numeric                 | Univariate    | Shows the distribution of a single numeric variable. |\n",
    "| Bar Chart             | Basic/Intermediate | Categorical           | Univariate/Bivariate | Shows numeric comparison across categories; can be extended to show multiple categories (stacked bar). |\n",
    "| Box Plot              | Intermediate     | Numeric vs Categorical  | Bivariate     | Displays the distribution of a numeric variable across different categories. |\n",
    "| Violin Plot           | Intermediate     | Numeric vs Categorical  | Bivariate     | Similar to box plots but with a kernel density estimation for better distribution visualization. |\n",
    "| Scatter Plot          | Basic/Intermediate | Numeric               | Bivariate     | Visualizes the relationship between two numeric variables. |\n",
    "| Line Plot             | Basic/Intermediate | Numeric               | Bivariate/Multivariate | Used for numeric x and y data; often for time series. |\n",
    "| Heatmap               | Intermediate     | Categorical/Numeric    | Bivariate/Multivariate | Visualizes data in matrix format; effective for correlation matrices, cross-tabulations. |\n",
    "| Pair Plot             | Intermediate     | Numeric                | Multivariate  | Showcases pairwise relationships in a dataset. |\n",
    "| KDE Plot              | Intermediate     | Numeric                | Bivariate/Multivariate | Kernel Density Estimation for visualizing the distribution of one or more variables. |\n",
    "| Joint Plot            | Intermediate     | Numeric                | Bivariate     | Combines scatter and histogram plots for joint distributions. |\n",
    "| Hexbin Plot           | Intermediate     | Numeric                | Bivariate     | Represents bivariate data using hexagons. |\n",
    "| Bubble Chart          | Intermediate     | Numeric                | Bivariate/Multivariate | Scatter plot variation where bubble size adds a third dimension. |\n",
    "| Swarm Plot            | Intermediate     | Numeric vs Categorical | Bivariate     | Similar to strip plot, but adjusts points to avoid overlap. |\n",
    "| Strip Plot            | Intermediate     | Numeric vs Categorical | Bivariate     | Displays individual data points as strips, providing a clear visualization of distribution. |\n",
    "| Facet Grid            | Intermediate     | Any                    | Multivariate  | Enables plotting of multiple plots on a grid for complex data comparisons. |\n",
    "| Ridge Plot            | Intermediate/Advanced | Numeric vs Categorical | Multivariate | Overlapping KDE plots for visualizing distributions across different categories. |\n",
    "| Parallel Coordinates  | Advanced         | Numeric/Categorical    | Multivariate  | Visualizes data points in terms of their features; good for comparing many variables. |\n",
    "| Contour Plot          | Advanced         | Numeric                | Bivariate     | Represents three-dimensional data in two dimensions using contours. |\n",
    "| Radar Chart             | Advanced           | Numeric/Categorical     | Multivariate        | Displays multivariate data in terms of a two-dimensional chart with one axis for each variable, typically used for performance analysis. |\n",
    "| Treemap                 | Intermediate       | Categorical/Numeric     | Multivariate        | Visualizes hierarchical data using nested rectangles, where size and color can represent different dimensions. |\n",
    "| Sunburst Chart          | Intermediate       | Categorical/Numeric     | Multivariate        | Visual representation of a hierarchy in a radial layout, useful for showing levels of a tree diagram. |\n",
    "| Sankey Diagram          | Advanced           | Categorical/Numeric     | Multivariate        | Visualizes the flow from one set of values to another, commonly used in data flow and financial transaction mapping. |\n",
    "| Choropleth Map          | Intermediate/Advanced | Geospatial Data      | Multivariate        | Maps where areas are shaded in proportion to a statistical variable; useful in geographical data visualization. |\n",
    "| 3D Scatter Plot         | Advanced           | Numeric                 | Multivariate        | A three-dimensional scatter plot, useful for visualizing multivariate data in 3D space. |\n",
    "| 3D Surface Plot         | Advanced           | Numeric                 | Multivariate        | Represents three-dimensional data as a surface in 3D space. |\n",
    "| Streamgraph             | Advanced           | Numeric/Categorical     | Multivariate        | A type of stacked area graph which is displaced around a central axis, resulting in a flowing, organic shape. |\n",
    "| Word Cloud              | Intermediate       | Textual Data            | Univariate          | Visual representation of text data where size of each word indicates its frequency or importance. |\n",
    "| Polar Chart             | Intermediate       | Numeric/Categorical     | Multivariate        | Displays data in a circular graph, where each variable is represented along a separate axis. |\n",
    "| Network/Graph Diagram   | Advanced           | Categorical/Numeric     | Multivariate        | Visualizes relationships and flows between nodes and connections in a network. |\n",
    "| Candlestick Chart       | Advanced           | Numeric                 | Bivariate/Multivariate | Used in financial analysis to represent the price movements of stocks, derivatives, etc. |\n",
    "| Gantt Chart             | Intermediate       | Categorical/Numeric     | Multivariate        | A type of bar chart that illustrates a project schedule or timelines. |\n",
    "| Density Plot            | Intermediate       | Numeric                 | Bivariate/Multivariate | Similar to KDE Plot, visualizes the distribution of a continuous variable. |\n",
    "| Dot Plot                | Intermediate       | Numeric/Categorical     | Bivariate/Multivariate | Represents data points as dots along an axis; useful for small to medium-sized datasets. |\n",
    "\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Important Plots\n",
    "    # Bar Chart\n",
    "    # Line Chart\n",
    "    # Pie Chart\n",
    "    # Scatter Plot\n",
    "    # Histogram\n",
    "    # Heat Map\n",
    "    # Box Plot and Violin Plot\n",
    "    # Density Plot and KDE plots\n",
    "\n",
    "\n",
    "# Bar Chart:\n",
    "    # Column Chart: Vertical bar chart.\n",
    "        plt.figure(figsize=(6, 4))\n",
    "        plt.bar(df_bar['Category'], df_bar['Value1'], color='b')\n",
    "        # sns.barplot(data=df, x='category', y='value', hue='sub_category') # to add hue\n",
    "        # sns.pairplot(data=df, hue='sub_category')\n",
    "        plt.title('Horizontal Bar Chart')\n",
    "        plt.xlabel('Value')\n",
    "        plt.ylabel('Category')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "        \n",
    "    # Stacked Bar Chart: Bars divided into sub-parts to show cumulative effect.\n",
    "        plt.figure(figsize=(6, 4))\n",
    "        plt.bar(df_bar['Category'], df_bar['Value1'], color='b', label='Value1')\n",
    "        plt.bar(df_bar['Category'], df_bar['Value2'], color='r', bottom=df_bar['Value1'], label='Value2')\n",
    "\n",
    "    # Grouped Bar Chart: Bars for different groups placed next to each other for comparison.\n",
    "        x = np.arange(len(df_bar['Category']))\n",
    "        width = 0.35\n",
    "        plt.figure(figsize=(6, 4))\n",
    "        plt.bar(x - width/2, df_bar['Value1'], width, label='Value1')\n",
    "        plt.bar(x + width/2, df_bar['Value2'], width, label='Value2')\n",
    "        plt.xticks(x, df_bar['Category'])\n",
    "        \n",
    "    # Horizontal Bar Chart: Bars are displayed horizontally instead of vertically.\n",
    "        plt.figure(figsize=(6, 4))\n",
    "        plt.barh(df_bar['Category'], df_bar['Value1'], color='b')\n",
    "        plt.title('Horizontal Bar Chart')\n",
    "        plt.xlabel('Value')\n",
    "        plt.ylabel('Category')\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "# Line Chart:\n",
    "    # Basic Line Chart: Single line showing a trend over time.\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.plot(df_line['A'], marker='o', color='b')\n",
    "    # sns.lineplot(data=df, x='time', y='value', hue='category') # to add hue\n",
    "    \n",
    "    # Multi-Line Chart: Multiple lines representing different categories for comparison.\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    for column in df_line.columns:\n",
    "        plt.plot(df_line[column], marker='o', label=column)\n",
    "        plt.legend()\n",
    "    \n",
    "    # Area Chart: Similar to a line chart but with the area below the line filled in.\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.fill_between(df_line.index, df_line['A'], color='skyblue', alpha=0.5)\n",
    "    plt.plot(df_line['A'], color='Slateblue', alpha=0.6)\n",
    "\n",
    "    # Stacked Area Chart: Multiple area charts stacked on top of one another.\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.stackplot(df_line.index, df_line['A'], df_line['B'], df_line['C'], labels=['A', 'B', 'C'])\n",
    "\n",
    "    \n",
    "# Pie Chart:\n",
    "    sizes = df['gender'].value_counts() # Count the occurrences of each gender\n",
    "\n",
    "    # Basic Pie Chart: Standard pie with different slices.\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=140)\n",
    "    \n",
    "    # Doughnut Chart: Similar to a pie chart but with a round hole in the center.\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=140, wedgeprops=dict(width=0.3))\n",
    "\n",
    "    # Exploded Pie Chart: Pie slices slightly separated from each other.\n",
    "    explode = (0, 0.1, 0, 0)  # only \"explode\" the 2nd slice (i.e. 'B')\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    plt.pie(sizes, explode=explode, labels=labels, autopct='%1.1f%%', startangle=140)\n",
    "    \n",
    "    \n",
    "# Scatter Plot:\n",
    "    # Basic Scatter Plot: Plots individual data points on a two-dimensional graph.\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.scatter(df_scatter['X'], df_scatter['Y'])   #hue = df_scatter['Z']\n",
    "    # sns.scatterplot(data=df, x='variable_x', y='variable_y', hue='category') # to add hue \n",
    "    \n",
    "    # Bubble Chart: Similar to scatter plots but uses bubble size as an additional variable.\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.scatter(df_scatter['X'], df_scatter['Y'], s=df_scatter['Size'], sizes=(20, 200), alpha=0.5, edgecolors='w', linewidth=0.5)   # hue = df_scatter['Z']\n",
    "    \n",
    "    # 3D Scatter Plot: Uses three dimensions to plot data points.\n",
    "    \n",
    "    \n",
    "# Histogram:\n",
    "    # Frequency Histogram: Shows the frequency of each data bin.\n",
    "    sns.set(style=\"whitegrid\")\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.hist(hist_data, bins=30, color='skyblue', edgecolor='black')\n",
    "    # sns.histplot(df[df['fire_occured'] == 'Yes']['RH'], color=\"red\", label='Fire Days', kde=True)\n",
    "    plt.title('Distribution of Relative Humidity on Days With and Without Forest Fires')\n",
    "    plt.xlabel('Relative Humidity (RH)')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # Density Histogram: Similar to a frequency histogram but shows the probability density.\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.hist(hist_data, bins=30, density=True, color='green', alpha=0.6, edgecolor='black')\n",
    "\n",
    "    # Cumulative Histogram: Displays the cumulative count of data points.\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.hist(hist_data, bins=30, cumulative=True, color='orange', alpha=0.6, edgecolor='black')\n",
    "\n",
    "    \n",
    "# Heat Map:\n",
    "    # Geographical Heat Map: Displays data density on maps.\n",
    "    # Matrix Heat Map: Represents data in a matrix format with colors indicating magnitude.\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(df.select_dtypes(exclude='object').corr(), annot=True, cmap='viridis')\n",
    "\n",
    "    # Tree Map: Uses nested rectangles to represent hierarchical data with color and size.\n",
    "    import squarify\n",
    "    colors = ['red', 'green', 'blue', 'yellow']\n",
    "\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    squarify.plot(sizes=df['Value'], label=df['Category'], color=colors, alpha=0.6)\n",
    "    plt.title('Tree Map')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Box Plots and Violin Plots\n",
    "    np.random.seed(0)\n",
    "    box_violin_data = np.random.randn(100, 3)\n",
    "    df_box_violin = pd.DataFrame(box_violin_data, columns=['A', 'B', 'C'])\n",
    "    \n",
    "    # Box Plots: used to show the distribution of quantitative data and effectively highlights the median, quartiles, and outlier\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.boxplot(data=df_box_violin)\n",
    "    # sns.boxplot(data=df, x='category', y='value', hue='sub_category') # to add hue\n",
    "\n",
    "    # Violin Plot: combines features of the box plot with a kernel density estimation\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.violinplot(data=df_box_violin)\n",
    "    # sns.violinplot(data=df, x='category', y='value', hue='sub_category', split=True) # to add hue\n",
    "\n",
    "\n",
    "# Density/KDE Plots: visualizes the distribution of data over a continuous interval\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.histplot(data, kde=True, color='blue', bins=30)\n",
    "    # or\n",
    "    df_density['Value'].plot(kind='density', color='blue')\n",
    "    # or\n",
    "    sns.kdeplot(df_density['Value'], shade=True, color='green') # use this\n",
    "    \n",
    "\n",
    "\n",
    "# WordCloud\n",
    "    from wordcloud import WordCloud\n",
    "    \n",
    "    # Join all the strings in the column to create one large string\n",
    "    text = ' '.join(df['Text'])\n",
    "\n",
    "    # Create a word cloud object\n",
    "    wordcloud = WordCloud(width = 800, height = 800, \n",
    "                    background_color ='white', \n",
    "                    stopwords = None, \n",
    "                    min_font_size = 10).generate(text)\n",
    "\n",
    "    # Plot the WordCloud image                        \n",
    "    plt.figure(figsize = (8, 8), facecolor = None) \n",
    "    plt.imshow(wordcloud) \n",
    "    plt.axis(\"off\") \n",
    "    plt.tight_layout(pad = 0) \n",
    "    \n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scikit-Learn Tips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Here are some of the popular modules within scikit-learn (sklearn) grouped by functionality:\n",
    "\n",
    "dir(sklearn)\n",
    "# Data Processing and Preprocessing:\n",
    "    sklearn.preprocessing # Contains functions and classes for data preprocessing and feature scaling.\n",
    "    sklearn.impute #contains functions to input missing values (e.g. IterativeImputer(estimator = RandomForest())\n",
    "\n",
    "# Machine Learning Models:\n",
    "    sklearn.linear_model # Includes linear regression, logistic regression, and other linear models.\n",
    "    sklearn.cluster # Provides clustering algorithms such as K-Means and hierarchical clustering.\n",
    "    sklearn.tree # Contains decision tree and ExtraTree.\n",
    "    sklearn.svm # Support Vector Machines for classification and regression.\n",
    "    sklearn.ensemble # Ensemble methods like AdaBoost, Bagging, and Gradient Boosting, RandomForest.\n",
    "    sklearn.neighbors # Nearest Neighbors algorithms.\n",
    "    sklearn.naive_bayes # Naive Bayes classifiers.\n",
    "    sklearn.discriminant_analysis # Linear and Quadratic Discriminant Analysis.\n",
    "    sklearn.neural_network # Neural network-based models.\n",
    "    sklearn.decomposition # Matrix decomposition techniques like PCA and NMF.\n",
    "    sklearn.kernel_approximation # Approximation techniques for kernel methods.\n",
    "    sklearn.isotonic # Isotonic regression.\n",
    "\n",
    "# Model Evaluation and Selection:\n",
    "    sklearn.model_selection # Tools for model selection, hyperparameter tuning, and cross-validation.(sklearn.model_selection.cross_validate)\n",
    "    sklearn.metrics # Metrics for evaluating model performance (e.g., accuracy, ROC-AUC, etc.).\n",
    "    sklearn.feature_selection #used to select the most relevant features from a dataset for training machine learning models\n",
    "    sklearn.feature_extraction #contains functions for feature extraction from raw data, such as text data, including Bag of Words, CountVectorizer, and TfidfVectorizer\n",
    "\n",
    "# Data Manipulation and Utility:\n",
    "    sklearn.base # Base classes and utility functions.\n",
    "    sklearn.utils # Various utility functions and classes.\n",
    "\n",
    "# Other:\n",
    "    sklearn.pipeline # provides tools for building machine learning pipelines, which allows you to chain together multiple steps.\n",
    "    sklearn.datasets    # datasets\n",
    "    sklearn.exceptions # Custom exceptions.\n",
    "    sklearn.externals # External dependencies.\n",
    "    sklearn.manifold # Dimensionality reduction techniques.\n",
    "    sklearn.logger and logging # Logging utilities.\n",
    "    sklearn.config_context # Context for configuration settings.\n",
    "    sklearn.get_config # Function to get global configuration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ed569b",
   "metadata": {},
   "source": [
    "> How to find any function in SKlearn, Pytorch Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9303e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import pkgutil\n",
    "# import importlib \n",
    "\n",
    "def find_all_instances_in_sklearn(search_term):\n",
    "    search_term_lower = search_term.lower()\n",
    "    locations = []\n",
    "    for importer, modname, ispkg in pkgutil.walk_packages(path=sklearn.__path__, prefix=sklearn.__name__ + '.'):\n",
    "        try:\n",
    "            module = importlib.import_module(modname)\n",
    "            for attribute_name in dir(module):\n",
    "                if search_term_lower in attribute_name.lower():\n",
    "                    locations.append(f'{modname}.{attribute_name}')\n",
    "        except (ImportError, SystemError):\n",
    "            pass  # Handle cases where a module can't be imported\n",
    "    return locations\n",
    "\n",
    "# Example usage\n",
    "search_term = 'logistic'  # This can be 'tsne', 'randomforestregressor', 'random', etc.\n",
    "locations = find_all_instances_in_sklearn(search_term)\n",
    "if locations:\n",
    "    print(f'Instances matching \"{search_term}\" found in:')\n",
    "    for location in locations:\n",
    "        print(f'  - {location}')\n",
    "else:\n",
    "    print(f'No instances matching \"{search_term}\" found in sklearn.')\n",
    "\n",
    "# you can replace sklearn with your preferred library. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37017fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9e5d7e71",
   "metadata": {},
   "source": [
    "#### OpenCV Tips"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d92031",
   "metadata": {},
   "source": [
    "> os  | zipfile   | PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767c070d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Operating System\n",
    "import os\n",
    "\n",
    "os.listdir(path='.') # Lists files and directories in a given directory. Useful for accessing image datasets.\n",
    "os.path.join(path, *paths) # Combines paths intelligently; key for building file paths in data processing.\n",
    "os.getcwd() # Gets the current working directory, often used in setting up paths for data input/output.\n",
    "os.chdir(path) # Changes the current working directory, useful in scripts that require relative paths.\n",
    "os.path.exists(path) # Checks if a given path exists, important for verifying data paths or model checkpoint existence.\n",
    "os.makedirs(path, mode=0o777, exist_ok=False) # Creates directories recursively, useful for creating structured directories to store \n",
    "    # processed images or models.\n",
    "os.rename(src, dst) # Renames files, can be used in organizing or re-labeling datasets.\n",
    "os.path.isdir(path) / os.path.isfile(path) # Checks if a path is a directory or a file, respectively. These are crucial in handling \n",
    "    # data files and directories.\n",
    "os.path.getsize(path) # Gets the size of a file, which can be important when handling large datasets or models.\n",
    "os.walk(top, topdown=True, onerror=None, followlinks=False) # Traverses directory trees, essential for processing datasets stored in \n",
    "    # nested directory structures. \n",
    "    for dirpath, dirnames, filenames in os.walk(file_path):\n",
    "        pass \n",
    "os.path.split(path) # Splits a pathname into head and tail components, useful for parsing file paths.\n",
    "os.remove(path) / os.unlink(path) # Removes files, which can be useful for cleaning up temporary files or outputs.\n",
    "\n",
    "\n",
    "=====================================================================================================================================\n",
    "# when working with datasets that have been zipped \n",
    "import zipfile \n",
    "from zipfile import ZipFile, is_zipfile \n",
    "\n",
    "data_path = 'lung-and-colon-cancer-histopathological-images.zip'\n",
    "\n",
    "zipfile.is_zipfile(data_path)    # check if the file is a zip filed.\n",
    "with ZipFile(data_path,'r') as zip:\n",
    "  zip.extractall()\n",
    "  print('The data set has been extracted.')\n",
    "  \n",
    "  \n",
    "===================================================================================================================================\n",
    "# using the PIL library (PIL - Python Imaging Library)  \n",
    "from PIL import Image\n",
    "\n",
    "Image.open(filepath) # Opens and identifies the given image file.\n",
    "Image.save(filename, format) # Saves the image under the given filename and format.\n",
    "Image.resize((width, height)) # Resizes the image to the specified width and height.\n",
    "Image.crop((left, top, right, bottom)) # Crops the image using the given coordinates.\n",
    "Image.rotate(angle) # Rotates the image by the given angle.\n",
    "Image.convert(mode) # Converts the image to the specified mode (e.g., \"RGB\", \"L\").\n",
    "Image.filter(filter) # Applies a specified filter to the image (e.g., ImageFilter.BLUR).\n",
    "Image.transpose(method) # Transposes the image (e.g., flipping)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6565be77",
   "metadata": {},
   "source": [
    "> opencv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273243f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import PIL \n",
    "\n",
    "# cv2 image shape (387, 620, 3) \n",
    "# torch tensor shape (3, 387, 620); channel in RGB\n",
    "# transposed_image = np.transpose(image, (1, 2, 0))     or img.permute(1,2,0)\n",
    "\n",
    "# PIL.Image.open(str(img))       to view an image           img = image path\n",
    "# plt.imshow(img)                to view an image            img = np array, expects RGB not BGR\n",
    "# cv2.imread(str(img))           to read an image            img = image path, output = np array, channel format in BGR\n",
    "# T.ToTensor()                   to transform an image       expects an PIL Image or ndarray \n",
    "\n",
    "\n",
    "img = np.zeros(shape=(480, 640)) \n",
    "\n",
    "# Core Operations\n",
    "\n",
    "    img = cv2.imread(img, flag) # Reading images (flag: cv2.IMREAD_COLOR or 1, cv2.IMREAD_GRAYSCALE or 0, cv2.IMREAD_UNCHANGED or -1)\n",
    "        img.shape   # returns a tuple of rows, columns, and channels\n",
    "        img.size    # returns the total number of pixels (row*col*channels)\n",
    "        img.copy()  # copy an image into a new variable. or use (np.copy(img))\n",
    "        np.copy(img)\n",
    "        img.dtype   # returns the image datatype \n",
    "    cv2.imshow(window_name, img)  # Showing Images\n",
    "    cropped_img = img[100:300, 100:300] # Image Cropping\n",
    "    cv2.imwrite(filename, img) # saving an image\n",
    "    cv2.waitKey(0) & 0xFF  # Wait for a key press  \n",
    "    cv2.destroyAllWindows() / cv2.destroyWindow() # Close all OpenCV windows \n",
    "    gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)  # Convert Color Spaces - Convert to grayscale\n",
    "    resized_img = cv2.resize(img, (width, height))  # Resize to a specific size\n",
    "    cv2.namedWindow('image')    #set the window to be 'image'\n",
    "    b, g, r = cv2.split(img)\n",
    "    b, g, r = img[y, x, 0], img[y, x, 1], img[y, x, 2]\n",
    "    img = cv2.merge((b,g,r)) \n",
    "    cv2.inRange(image, lower_bound, upper_bound)    # used for color segmentation. It filters an image to include only pixels within a specified color range, creating a binary mask\n",
    "    cv2.createTrackbar('trackbar_name', 'window_name', value, count, onChange)  # Create Trackbar\n",
    "    pos = cv2.getTrackbarPos('trackbar_name', 'window_name')    # Get Trackbar Position\n",
    "    hist = cv2.calcHist([gray_image], [0], None, [256], [0, 256])   # calculate histogram for a gray-scale image\n",
    "    hist_blue = cv2.calcHist([color_image], [0], None, [256], [0, 256])     # calculate histogram for the blue channel of a colored image\n",
    "        plt.plot(hist_blue)     # plot the histogram\n",
    "    np.interp(brightness_scale, [0, 100], [1, 4])       # scales  values in range [0-100] into [1-4]\n",
    "    np.clip(a, a_min, a_max, out=None, **kwargs)        # Clip (limit) the values \"a\" in an array into (a_min, a_max).\n",
    "    np.transpose(img, axes=(0,1,2))     # Returns an array with axes transposed (useful for converting from cv2 to pytorch style)\n",
    "\n",
    "# Working with Images\n",
    "    \n",
    "    # Drawing Shapes and Text on Images\n",
    "\n",
    "        cv2.line(img, (start_coordinates), (end_coordinates), (color_in_bgr), line_thickness)                     # Draw Line\n",
    "        cv2.rectangle(img, (top-left corner coordinates), (bottom-right corner coordinates), color, thickness)    # Draw Rectangle\n",
    "        cv2.circle(img, (center_coordinates), (circle_radius), (color_in_bgr), stroke_thickness)     # Draw Circle\n",
    "        cv2.polylines(img, [pts], isClosed, color, thickness)         # Draw Polygon\n",
    "        cv2.putText(img, text, orgin_coordinate, font, font_scale, (color, thickness, line_type))         # Write Text\n",
    "        cvzone.putTextRect(img, text, pos, scale=3, thickness=3, colorT=(255, 255, 255), colorR=(255, 0, 255), font=1,)    #text with rectangle background\n",
    "        cv2.arrowedLine(img, (start_coordinates), (end_coordinates), (color_in_bgr), line_thickness)      # arrowed line \n",
    "                            # thickness = any digit or use [cv2.FILLED or -1] to fill the shape\n",
    "        cv2.fillPoly(img, [np.array([pts])], color=(200, 245, 0)) # pts is a numpy list of array with all the x,y points in the shape ~ pts.reshape((-1, 1, 2))\n",
    "        cv2.fillConvexPoly(mask, points, color)     # Fill Concave polygon using convex hull algorithm\n",
    "        # draw polygon - https://roboflow.github.io/polygonzone/ \n",
    "\n",
    "    # Arithmetic Operations on Images\n",
    "\n",
    "        cv2.add(image1, image2) # Image Addition\n",
    "        cv2.addWeighted(image1, weight1, image2, weight2, gammaValue)    #Image Alpha Blending\n",
    "        cv2.subtract(image1, image2)    #Image Subtraction\n",
    "        cv2.bitwise_and(image1, image2, destination, mask)   # Bitwise And\n",
    "        cv2.bitwise_or(image1, image2, destination, mask)   # Bitwise Or\n",
    "        cv2.bitwise_not(image, destination, mask)   # Bitwise Not\n",
    "        cv2.bitwise_xor(image1, image2, destination, mask)  # Bitwise Xor\n",
    "        \n",
    "    # Morphological Operations on Images:   (Manipulates image shape/structure using kernels; includes erosion, dilation, opening, and closing)\n",
    "\n",
    "        cv2.erode(img, kernel, iterations=1)  # Erosion:      Shrinks bright regions and enlarges dark regions by removing pixels at boundaries.\n",
    "        cv2.dilate(img, kernel, iterations=1) # Dilation:     Expands bright areas and shrinks dark regions by adding pixels to boundaries.\n",
    "        cv2.morphologyEx(img, cv2.MORPH_OPEN, kernel, iterations=1)   #Opening:       Removes small bright spots (noise) by erosion followed by dilation\n",
    "        cv2.morphologyEx(img, cv2.MORPH_CLOSE, kernel, iterations=1)   # Closing:      Fills small dark spots and small holes by dilation followed by erosion.\n",
    "        cv2.morphologyEx(img, cv2.MORPH_GRADIENT, kernel) #Morphological Gradient:    Highlights edges and boundaries by subtracting an eroded image from a dilated image\n",
    "        cv2.morphologyEx(img, cv2.MORPH_TOPHAT, kernel)   # Top Hat:      Isolates small elements and details brighter than their surroundings.\n",
    "        cv2.morphologyEx(img, cv2.MORPH_BLACKHAT, kernel) # Black Hat:    Isolates dark elements and details in bright surroundings.\n",
    "\n",
    "    # Smoothing Images: (Reduces noise and details by applying filters, like Gaussian blur or median blur, to soften images.)\n",
    "\n",
    "        cv2.filter2D(img, depth, kernel) # Convolve an Image:                                 Applies a custom kernel for convolution, allowing for diverse linear filtering effects.     \n",
    "        cv2.blur(img, shapeOfTheKernel)   # Avera­ging Filtering:                              Smoothens image using a simple average of neighboring pixels within the kernel.\n",
    "        cv2.getGaussianKernel(ksize, sigma[, ktype])    # Create Gaussian Kernel:               Generates a Gaussian kernel, used for more advanced blurring techniques.\n",
    "        cv2.GaussianBlur(img, shapeOfTheKernel, sigmaX )  # Gaussian Blur:                    Reduces noise using a Gaussian filter, effective for Gaussian noise.\n",
    "        cv2.medianBlur(img, kernel size)  # Median Blur:                                      useful for dealing with salt and pepper noise). Removes salt-and-pepper noise, replacing each pixel with the median of neighboring pixels\n",
    "        cv2.bilateralFilter(img, diameter, sigmaColor, sigmaSpace)    # Bilateral Blur:       Preserves edges while reducing noise, using a non-linear, edge-preserving approach.\n",
    "\n",
    "    # Geometric Transformations on Image:  \n",
    "\n",
    "        res = cv2.resize(img,(2width, 2height), interpolation)  # Scaling (scaling types: cv2.INTER_AREA, cv2.IN­TER­_CUBIC, cv2.INTER_LINEAR)\n",
    "        cv2.warpAffine(img, M, (width, height))         # affine transformation to an image (where M is the transformation matrix)\n",
    "                M = np.float32([[1, 0, new_width], [0, 1, new_height]])     #  Translation\n",
    "                M = cv2.getRotationMatrix2D(center, angle, scale)   # Rotation\n",
    "                M = cv2.getAffineTransform(pts1, pts2)      # Affine Transformation\n",
    "                M = cv2.getPerspectiveTransform(src, dst)      # Perspective Transformation\n",
    "        cv2.warpPerspective(img, M, dsize)\n",
    "        \n",
    "    # Image Thresholding:  (apply to GRAYSCALE) (Converts images to binary using a set threshold, useful for separating foreground from background)\n",
    "\n",
    "        retval, thresholded_image = cv2.threshold(img, thresh, maxvalue, thresholdingTechnique)    # Simple Threshold\n",
    "        retval, thresholded_image = cv2.adaptiveThreshold(img, maxvalue, adaptivemethod, thresholdingTechnique, blocksize, constant)   # Adaptive Threshold\n",
    "        retval, bw_image = cv2.threshold(img, thresh, maxvalue, thresholdingTechnique)    # Otsu Thresholding\n",
    "        \n",
    "            # Thresholding technique\n",
    "            cv2.THRESH_BINARY   # If pixel intensity is greater than the set threshold, the value is set to 255, else set to 0\n",
    "            cv2.THRESH_BINARY_INV   # Inverted or Opposite case of cv2.THRESH_BINARY\n",
    "            cv2.THRESH_TRUNC        # If the pixel intensity value > threshold, it is truncated to the threshold. set pixel values == threshold\n",
    "            cv2.THRESH_TOZERO       # Pixel intensity is set to 0, for all the pixels’ intensity, less than the threshold value\n",
    "            cv2.THRESH_TOZERO_INV   # Inverted or Opposite case of cv2.THRESH_TOZERO\n",
    "            cv2.THRESH_OTSU\n",
    "            cv2.THRESH_TRIANGLE \n",
    "            \n",
    "            # Adaptive Threshold Methods\n",
    "            cv2.ADAPTIVE_THRESH_MEAN_C      # Calculates the threshold as the mean of neighboring area minus a constant. Useful for varying lighting conditions.\n",
    "            cv2.ADAPTIVE_THRESH_GAUSSIAN_C  # Uses a Gaussian-weighted sum of the neighborhood values for thresholding, ideal for finer, localized changes.\n",
    "                                                    \n",
    "    # Edge/Line and Object Detection (Features):   (use GRAYSCALE - Identifies sharp changes in intensity to detect object boundaries and lines in images.)\n",
    "\n",
    "        cv2.Canny(img, thresh_lower, thresh_upper, aperture_size, L2Gradient)   # Canny Edge Detection \n",
    "        cv2.HoughLines(img, rho, theta, threshold)    # Houghline Method for Line Detection using the standard Hough transform   (rho: Distance resolution in pixels., theta: Angle resolution in radians., threshold: Minimum votes to consider a line)\n",
    "        cv2.HoughLinesP(img, rho, theta, threshold, ..)    # Finds line segments in a binary image using the probabilistic Hough transform\n",
    "        cv2.HoughCircles(img, cv2.HOUGH_GRADIENT, 1, 20, param1 = 50, param2 = 30, minRadius = 1, maxRadius = 40) #Houghline Method for Circle Detection\n",
    "        cv2.cornerHarris(img, blockSize, kSize, k, borderType)    # Harris Corner Method for Corner Detection\n",
    "        cv2.goodFeaturesToTrack(img, max_corner, quality_level, min_distance)   # Shi-Tomasi Method for Corner Detection\n",
    "        cv2.drawKeypoints(img, key_points, output_image, colour, flag)  # Keypoints Detection\n",
    "        \n",
    "        # Image gradients:      Computes image gradients to emphasize texture and edges\n",
    "        cv2.Sobel(img, ddepth, dx, dy, dst=None, ksize=None, scale=None)       # Sobel Operator, useful for edge detection in both X and Y directions.         (ddepth: Depth of the destination image. dx and dy: Order of the derivative x and y)\n",
    "        cv2.Laplacian(img, ddepth=-1, dst=None, ksize=None)          # Calculates the Laplacian of the image, highlighting regions of rapid intensity change\n",
    "        cv2.Scharr(img, ddepth=-1, dx, dy)    # A variation of Sobel, more sensitive to edges than the standard Sobel operator.\n",
    "\n",
    "        #  Contour Detection:           Used to detect and extract contours from binary images. Essential for shape analysis, object detection, and recognition tasks.\n",
    "        contours, hierarchy = cv2.findContours(thresh, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)  #  Finds contours in a binary image.    Parameters: source image, contour retrieval mode, contour approximation method.\n",
    "        contours, Area, BoundingBox, Center = cvzone.Utils.findContours(img, imgPre, minArea=1000, maxArea=inf,)    # Finds Contours in an image.\n",
    "        cv2.drawContours(img, contours, contourIdx, color, thickness) # Draw contour      contourIdx = -1\n",
    "        area = cv2.contourArea(contours) # contour area\n",
    "        x, y, w, h = cv2.boundingRect(contours)  # Bounding Rectangle: \n",
    "        length = cv2.arcLength(contours, True)   # Contour Perimeter:\n",
    "        approx = cv2.approxPolyDP(contours, epsilon, True)   # Approximating Contours\n",
    "        \n",
    "        # Template Matching:        used for finding the location of a template image within a larger image. It's mainly used in applications where you need to find specific objects or features in an image\n",
    "        result = cv2.matchTemplate(img, template, method)     # Perform Template Matching:    \n",
    "        h, w = template.shape \n",
    "        min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(result)  # locate the match \n",
    "        if method in [cv2.TM_SQDIFF, cv2.TM_SQDIFF_NORMED]: \n",
    "            top_left = min_loc \n",
    "        else: \n",
    "            top_left = max_loc\n",
    "        bottom_right = (top_left[0] + w, top_left[1] + h)\n",
    "        cv2.rectangle(img, top_left, bottom_right, color, thickness)  # draw a rectangle around the match \n",
    "\n",
    "        \n",
    "    # Image Pyramids:   (Creates a multi-scale representation of an image, useful for scaling images up or down)\n",
    "\n",
    "        cv2.pyrDown(layer)  # Lower Gaussian Pyramid \n",
    "        cv2.pyrUp(layer)    # Higher Gaussian Pyramid\n",
    "        \n",
    "    # Changing the Colorspace of Images\n",
    "\n",
    "        cv2.cvtColor(img, cv2.COLOR_BGR2RGB) # BGR to RGB: - often used when switching from cv2 to pytorch, PIL or Sklearn.\n",
    "        cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) # BGR to Grayscale: \n",
    "        cv2.cvtColor(img, cv2.COLOR_RGB2GRAY) # RGB to Grayscale: \n",
    "        cv2.cvtColor(img, cv2.COLOR_BGR2HSV)  # BGR to HSV (H-Hue , S-Saturation, V-Value represents intensity)\n",
    "        cv2.cvtColor(img, cv2.COLOR_BGR2LAB)  # BGR to Lab (L-Lightness. A-color from Green to Magenta. B colors from Blue to Yellow) \n",
    "        cv2.cvtColor(img, cv2.COLOR_BGR2YCrCb) # BGR to YCrCb Color (Y-Luminance or Luma component, Cb and Cr are Chroma components)\n",
    "        hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)    # Track Blue (color) Object\n",
    "            lower_blue = np.array([110,50,50])\n",
    "            upper_blue = np.array([130,255,255])\n",
    "            cv2.inRange(hsv, lower_blue, upper_blue)                                \n",
    "                                        \n",
    "\n",
    "# Working With Videos\n",
    "\n",
    "    cv2.VideoCapture('file_name.mp4')       # Playing a Video \n",
    "    PIL.Image.open(filename, mode)  # Create a Video from Multiple Images\n",
    "    cap = cv2.VideoCapture(File_path)     # Extracting Images from Video\n",
    "        cap.read()\n",
    "        cap.imwrite('filename.png', img)    # write the image to a file \n",
    "\n",
    "\n",
    "    cap = cv2.VideoCapture(\"file_name.mp4\")  # Replace with your video file path\n",
    "    cap = cv2.VideoCapture(0)  # '0' is the default camera. Use '1', '2', etc. for other cameras\n",
    "        ret, frame = cap.read()  # Read Frames from the Video - 'ret' is a boolean indicating success, 'frame' is the current frame\n",
    "        cv2.flip(frame, 1)  # Flip the frame horizontally (1), vertical (0), both (-1) \n",
    "        cv2.imshow('Frame Title', frame)  # Display the current frame\n",
    "        cap.release()  # Release the video file or capturing device\n",
    "        if cap.isOpened():  # Check if VideoCapture Object is Opened\n",
    "        width = cap.get(cv2.CAP_PROP_FRAME_WIDTH)   # Get Video Properties - width\n",
    "        height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT) # Get Video Properties - height\n",
    "        fps = cap.get(cv2.CAP_PROP_FPS)             # Get Video Properties - fps\n",
    "        cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)      # set Video Properties\n",
    "        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)     # set Video Properties\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'XVID')  # Define the codec (like XVID, MP4V, etc.)\n",
    "        out = cv2.VideoWriter('output.avi', fourcc, 20.0, (640, 480))  # Filename, codec, FPS, resolution\n",
    "            out.write(frame)  # Write a frame to the output video\n",
    "            out.release()  # Release the VideoWriter object\n",
    "    cv2.namedWindow('image')    #set the window to be 'image'\n",
    "\n",
    "            # Video Properties\n",
    "            3 - cv2.CAP_PROP_FRAME_WIDTH    #  Set the width of the video frames\n",
    "            4 - cv2.CAP_PROP_FRAME_HEIGHT   #  Set the height of the video frames\n",
    "            5 - cv2.CAP_PROP_FPS            # Set the frame rate of the video capture.\n",
    "            10 - cv2.CAP_PROP_BRIGHTNESS    # Adjust the brightness of the video (if the camera supports this setting).\n",
    "            11 - cv2.CAP_PROP_CONTRAST      # Adjust the contrast of the video (if the camera supports this setting).\n",
    "            12 - cv2.CAP_PROP_SATURATION    # Adjust the saturation of the video (if the camera supports this setting).\n",
    "            15 - cv2.CAP_PROP_EXPOSURE      # Adjust the exposure of the camera (if the camera supports this setting).\n",
    "            39 - cv2.CAP_PROP_AUTOFOCUS     # Enable or disable autofocus, if supported (0 or 1).\n",
    "            \n",
    "            # Mouse Events\n",
    "            cv2.EVENT_LBUTTONDOWN   # Triggered when the left mouse button is pressed\n",
    "            cv2.EVENT_LBUTTONUP     # Occurs when the left mouse button is released. Often used in conjunction with EVENT_LBUTTONDOWN for actions like drag-and-drop.\n",
    "            cv2.EVENT_RBUTTONDOWN   # Triggered when the right mouse button is pressed\n",
    "            cv2.EVENT_MOUSEMOVE     # Occurs when the mouse is moved over the window. This is frequently used for tracking mouse movement, real-time drawing, or interactive applications\n",
    "            cv2.EVENT_LBUTTONDBLCLK # Triggered on a double-click of the left mouse button. Commonly used for more complex interactions like object selection or opening properties\n",
    "            cv2.EVENT_MOUSEMOVE and flags == cv2.EVENT_FLAG_LBUTTON     #if the mouse is moved while the left button is pressed down.\n",
    "            \n",
    "# Machine Learning and Deep Learning with OpenCV\n",
    "\n",
    "    net = cv2.dnn.readNet(model, config, framework) \n",
    "    net.setInput(blob)\n",
    "    output = net.forward()\n",
    "\n",
    "    knn = cv2.ml.KNearest_create()\n",
    "    knn.train(trainData, responses)\n",
    "\n",
    "    svm = cv2.ml.SVM_create()\n",
    "    svm.train(data, cv2.ml.ROW_SAMPLE, labels)\n",
    "\n",
    "# Camera Calibration and 3D Reconstruction\n",
    "    ret, corners = cv2.findChessboardCorners(gray, (width, height)) # Finding Chessboard Corners:\n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, gray.shape[::-1], None, None)  # Calibrate Camera:\n",
    "\n",
    "\n",
    "# Object Detection and Tracking\n",
    "    face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')     # Face Detection: Using Haar Cascades. download from opencv github \n",
    "    faces = face_cascade.detectMultiScale(image, scaleFactor, minNeighbors)\n",
    "\n",
    "    bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)       # Feature matching \n",
    "    matches = bf.match(descriptors1, descriptors2)\n",
    "    \n",
    "    sift = cv2.SIFT_create()            # Advanced feature detection \n",
    "    kp, des = sift.detectAndCompute(img, None)\n",
    "  \n",
    "    \n",
    "    \n",
    "# Others \n",
    "    cv2.setMouseCallback('image', mouse_callback)   # Mouse Callback Function: For capturing mouse events\n",
    "            def mouse_callback(event, x, y, flags, param):\n",
    "                    \"\"\"\n",
    "                    Mouse event callback.\n",
    "                    Parameters: event (int), x (int), y (int), flags (int), param (int)\n",
    "                    \"\"\"\n",
    "                    # Left mouse button down event\n",
    "                    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "                        # Draw a blue rectangle around the mouse click position\n",
    "                        cv2.rectangle(img, (x, y), (x + 20, y + 20), (255, 0, 0), cv2.FILLED)\n",
    "                        cv2.imshow('image', img)\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8834b568",
   "metadata": {},
   "source": [
    "> CVZone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4cf0f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install cvzone\n",
    "pip install mediapipe\n",
    "\n",
    "import cvzone \n",
    "\n",
    "# Others:\n",
    "    cvzone.cornerRect(img, bbox, l=30, t=5, rt=1, colorR=(255, 0, 255), colorC=(0, 255, 0))\n",
    "    cvzone.downloadImageFromUrl(url, keepTransparency=True)         # download image from url \n",
    "    cvzone.findContours(img, imgPre, minArea=1000, maxArea=inf,)    # Finds Contours in an image.\n",
    "    cvzone.overlayPNG(img, imgPNG, pos=[-30, 50])                   # overlay image\n",
    "    cvzone.putTextRect(img, text, pos, scale=3, thickness=3, colorT=(255, 255, 255), colorR=(255, 0, 255), font=1,)    #text with rectangle background\n",
    "    cvzone.rotateImage(img, angle, scale=1, keepSize=False)         # rotate an image 60 deg.\n",
    "    cvzone.stackImages(imgList, cols, scale)                        # Stack Images together to display in a single window\n",
    "    \n",
    "# Face Detection: Easily detect faces in an image or video stream.\n",
    "    from cvzone.FaceDetectionModule import FaceDetector\n",
    "    detector = FaceDetector(minDetectionCon=0.5, modelSelection=0)\n",
    "            img, bboxs = detector.findFaces(img, draw=False)        # # bbox contains 'id', 'bbox', 'score', 'center'\n",
    "\n",
    "# Hand Tracking: Track hand landmarks in real-time.\n",
    "    from cvzone.HandTrackingModule import HandDetector\n",
    "    detector = HandDetector(detectionCon=0.8, maxHands=2)\n",
    "            hands, img = detector.findHands(img, draw = False)      # Finds hands in a BGR image    (hand1[\"lmList\"]  # List of 21 landmarks for the first hand)\n",
    "            length, info, img = detector.findDistance()         # Find the distance between two landmarks input should be (x1,y1) (x2,y2)\n",
    "            fingers = fingersUp()   # Finds how many fingers are open and returns in a list \n",
    "\n",
    "# Pose Estimation: Identify human body positions.\n",
    "    from cvzone.PoseModule import PoseDetector\n",
    "    detector = PoseDetector(staticMode=False, modelComplexity=1, smoothLandmarks=True, enableSegmentation=False, smoothSegmentation=True,\n",
    "                        detectionCon=0.5,\n",
    "                        trackCon=0.5)\n",
    "            img = detector.findPose(img)            # Find the human pose in the frame\n",
    "            lmList, bboxInfo = detector.findPosition(img, draw=True, bboxWithHands=False)   # Find the landmarks, bounding box, and center of the body in the frame\n",
    "            length, img, info = detector.findDistance(lmList[11][0:2], lmList[15][0:2], img, color, scale)     # Calculate the distance between landmarks\n",
    "            angle, img = detector.findAngle(lmList[11][0:2], lmList[13][0:2], lmList[15][0:2], img, color, scale)   # Calculate the angle between landmarks\n",
    "            isCloseAngle50 = detector.angleCheck(myAngle=angle, targetAngle=50, offset=10)      # Check if the angle is close to 50 degrees with an offset of 10\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f67b9b",
   "metadata": {},
   "source": [
    "> Image Annotation on Colab and Jupyter Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78801ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function that loads an image before adding it to the widget\n",
    "\n",
    "import base64\n",
    "\n",
    "def encode_image(filepath):\n",
    "    with open(filepath, 'rb') as f:\n",
    "        image_bytes = f.read()\n",
    "    encoded = str(base64.b64encode(image_bytes), 'utf-8')\n",
    "    return \"data:image/jpg;base64,\"+encoded\n",
    "     \n",
    "\n",
    "file_image = r\"C:\\Users\\pault\\Documents\\5. Projects\\1. Bird Species Classification\\data\\train\\ABYSSINIAN GROUND HORNBILL\\014.jpg\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8afffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "IS_COLAB = False\n",
    "\n",
    "if IS_COLAB:\n",
    "    from google.colab import output\n",
    "    output.enable_custom_widget_manager()\n",
    "\n",
    "from jupyter_bbox_widget import BBoxWidget\n",
    "\n",
    "widget = BBoxWidget()\n",
    "widget.image = encode_image(file_image)\n",
    "widget\n",
    "     \n",
    "\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d925aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "widget.bboxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PyTorch Tips"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8335f04b",
   "metadata": {},
   "source": [
    "> Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn             # neural networks\n",
    "import torch.optim as optim       # optimizers e.g. gradient descent, ADAM, etc.\n",
    "import torch.nn.functional as F   # layers, activations and more\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms   # composable transforms\n",
    "from torchvision import datasets, models, transforms     # vision datasets,\n",
    "                                                         # architectures &\n",
    "                                                         # transforms\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## torch\n",
    "  # **Tensor Creation**\n",
    "    torch.zeros # Tensor filled with zeros.\n",
    "    torch.ones # Tensor filled with ones.\n",
    "    torch.randn #Tensor with random numbers from a normal distribution.   torch.Tensor` - Basic tensor object.\n",
    "    torch.arange # Tensor containing a sequence of numbers.\n",
    "    torch.tensor # Create tensor from data.\n",
    "    \n",
    "  # **Operations**\n",
    "    torch.matmul # Matrix multiplication.\n",
    "    torch.cat # Concatenates tensors along a specified dimension.\n",
    "    torch.stack # Stacks tensors in a new dimension.\n",
    "    torch.split # Splits a tensor into chunks.\n",
    "    \n",
    "  # **Conversion**\n",
    "    torch.from_numpy # Convert numpy array to tensor.\n",
    "    torch.Tensor.numpy # Convert tensor to numpy array.\n",
    "    \n",
    "  # Device Management**   torch.device` - Device interface (CPU/GPU).\n",
    "    torch.cuda.is_available # Check if CUDA is available.\n",
    "    tensor.to('cuda') # Move tensor to GPU.\n",
    "\n",
    "## torch.nn\n",
    "  # Layers**\n",
    "    nn.Linear(m,n) # Fully connected layer from m to n units\n",
    "    nn.Conv2d # 2D convolutional layer.\n",
    "    nn.MaxPool2d # 2D max pooling layer.\n",
    "    \n",
    "  # Activation Functions**\n",
    "    nn.ReLU # Rectified Linear Unit activation function.\n",
    "    nn.Sigmoid  # Sigmoid activation function.    nn.Tanh` - Hyperbolic tangent activation function.\n",
    "      # others: ELU, SELU, PReLU, LeakyReLU, RReLu, CELU, GELU, Threshold, Hardshrink, HardTanh, LogSigmoid, Softplus, Tanh, Softmin, \n",
    "      \n",
    "  # Loss Functions**\n",
    "    nn.CrossEntropyLoss # Loss function for classification.\n",
    "    nn.MSELoss  # Mean Squared Error loss for regression.\n",
    "    nn.BCELoss  # Binary Cross-Entropy Loss.\n",
    "      # others: L1Loss, MSELoss, CrossEntropyLoss, CTCLoss, NLLLoss, PoissonNLLLoss, KLDivLoss, BCELoss, BCEWithLogitsLoss etc.\n",
    "      \n",
    "  # Utilities**\n",
    "    nn.Module # Base class for all neural network modules.\n",
    "\n",
    "## torch.optim\n",
    "  # Optimizers**\n",
    "    optim.SGD # Stochastic Gradient Descent optimizer.\n",
    "    optim.Adam  # Adam optimizer.\n",
    "    optim.Adagrad # Adagrad optimizer.\n",
    "    optim.RMSprop # RMSprop optimizer.\n",
    "    optimizer.step() # update weights\n",
    "\n",
    "## Learning Rate Scheduling\n",
    "    scheduler = optim.X(optimizer,...)      # create lr scheduler\n",
    "    scheduler.step()                        # update lr after optimizer updates weights\n",
    "    optim.lr_scheduler.X                    # where X is LambdaLR, MultiplicativeLR,\n",
    "                                            # StepLR, MultiStepLR, ExponentialLR,\n",
    "                                            # CosineAnnealingLR, ReduceLROnPlateau, CyclicLR,\n",
    "                                            # OneCycleLR, CosineAnnealingWarmRestarts,\n",
    "\n",
    "## Datasets and Data Utilities \n",
    "    torch.utils.data.DataLoader(data, batch_size, shuffle, drop_last)  # loads data batches agnostic of structure of individual data points\n",
    "    torch.utils.data.TensorDataset(X, y)    # labelled dataset in the form of tensors\n",
    "    torch.utils.data.DatasetFolder()\n",
    "    torch.utils.data.Dataset()    # abstract class representing dataset\n",
    "    torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "    \n",
    "## torch.nn.functional\n",
    "  # Activation Functions**\n",
    "    F.relu  # Rectified Linear Unit activation function.\n",
    "    F.sigmoid # Sigmoid activation function.\n",
    "    F.tanh  # Hyperbolic tangent activation function.\n",
    "    \n",
    "  # Loss Functions**\n",
    "    F.cross_entropy # Loss function for classification.\n",
    "    F.mse_loss  # Mean Squared Error loss for regression.\n",
    "    F.binary_cross_entropy  # Binary Cross-Entropy Loss.\n",
    "    \n",
    "  # Convolutional Operations**\n",
    "    F.conv2d  # Apply a 2D convolution.\n",
    "    F.max_pool2d  # Apply 2D max pooling.\n",
    "\n",
    "\n",
    "\n",
    "## torchvision\n",
    "  # Datasets**\n",
    "    torchvision.datasets.MNIST  # Dataset of handwritten digits.\n",
    "    torchvision.datasets.CIFAR10  # Dataset of 32x32 images in 10 classes.\n",
    "    torchvision.datasets.ImageFolder  # Generic data loader where images are arranged in a specific format.\n",
    "  # Models**\n",
    "    torchvision.models.resnet50 # Pretrained ResNet-50 model.\n",
    "    torchvision.models.vgg16  # Pretrained VGG-16 model.\n",
    "    torchvision.models.alexnet  # Pretrained AlexNet model.\n",
    "  # Transforms**\n",
    "    torchvision.transforms.Resize # Resize an image.\n",
    "    torchvision.transforms.CenterCrop # Crop the image at the center.\n",
    "    torchvision.transforms.ToTensor # Convert image to tensor.\n",
    "    transforms.ToPILImage # Convert tensor to PIL image.\n",
    "\n",
    "## torchvision.transforms\n",
    "  # Common Transforms**\n",
    "    transforms.Compose  # Compose several transforms together.\n",
    "    transforms.ToTensor  # Convert PIL image or numpy array to tensor.\n",
    "    transforms.Normalize  # Normalize a tensor image with mean and standard deviation.\n",
    "    transforms.RandomCrop # Crop the image randomly.\n",
    "    transforms.RandomHorizontalFlip # Horizontally flip the image randomly.\n",
    "\n",
    "## torchvision.ops\n",
    "  # Operations**\n",
    "    torchvision.ops.boxes # Operations on bounding boxes.\n",
    "    torchvision.ops.nms  # Non-maximum suppression. removes overlapping bounding boxes.\n",
    "    torchvision.ops.batched_nms # Performs NMS on a batch of boxes from different images, grouped by image ids.\n",
    "    torchvision.ops.roi_pool  # Region of Interest pooling, used to extract fixed-size features from variable-sized RoIs.\n",
    "    torchvision.ops.roi_align  # Region of Interest alignment, more accurate than RoI pooling\n",
    "    torchvision.ops.box_iou  # Compute intersection over union of two sets of boxes\n",
    "    torchvision.ops.sigmoid_focal_loss  # Sigmoid focal loss for dense object detection.\n",
    "    torchvision.ops.box_area  # Compute the area of a set of boxes.\n",
    "    torchvision.ops.box_convert  # Convert boxes between different formats.\n",
    "    torchvision.ops.generalized_box_iou # Compute generalized intersection over union of two sets of boxes.\n",
    "    torchvision.ops.clip_boxes_to_image # Clip boxes to an image with a specific size.\n",
    "    torchvision.ops.remove_small_boxes  # Remove boxes that are smaller than a specified size. \n",
    "    torchvision.ops.masks_to_boxes  # Convert masks to bounding boxes.\n",
    "    \n",
    "## torchvision.utils\n",
    "  # Utilities**\n",
    "    torchvision.utils.make_grid  # Make a grid of images.\n",
    "    torchvision.utils.save_image  # Save a tensor image to disk.\n",
    "    torchvision.utils.draw_bounding_boxes  # Draw bounding boxes on an image.\n",
    "    torchvision.utils.draw_segmentation_masks # Draw segmentation masks on an image.\n",
    "    torchvision.utils.draw_keypoints # Draw keypoints on an image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f91a04",
   "metadata": {},
   "source": [
    "> Pytorch Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b54ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Classification Data\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "import PIL\n",
    "import torchvision.transforms as T\n",
    "import torch\n",
    "\n",
    "class Dataset (torch.utils.data.Dataset):\n",
    "    def __init__(self, image_path, transforms):\n",
    "        self.image_path = image_path\n",
    "        self.transforms = transforms\n",
    "\n",
    "        self.data_classes = []\n",
    "        self.data_images = []\n",
    "        self.data_labels = []\n",
    "        for dirpath, subdir, filenames in os.walk(image_path):\n",
    "            for file_dir in subdir:\n",
    "                self.data_classes.append(file_dir)\n",
    "            for img in filenames:\n",
    "                # print(img)\n",
    "                image_path = os.path.join(dirpath, img)\n",
    "                self.data_images.append(image_path)\n",
    "                label_class = dirpath.split(os.sep)[-1]\n",
    "                self.data_labels.append(self.data_classes.index(label_class))\n",
    "               \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data_images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.data_images[idx]\n",
    "        image = PIL.Image.open(image_path).convert('RGB') \n",
    "        label = self.data_labels[idx]\n",
    "        \n",
    "        if self.transforms:\n",
    "            image = self.transforms(image)\n",
    "        else:\n",
    "            image = T.ToTensor()(image)\n",
    "            \n",
    "        return image, label\n",
    "\n",
    "\n",
    "# Load Object Detection data\n",
    "\n",
    "class ObjectDetectionDataset(Dataset):\n",
    "    def __init__(self, root_dir, split='train', transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir (string): Directory with all the images and labels.\n",
    "            split (string): One of 'train', 'test', or 'valid' to specify the dataset split.\n",
    "            transform (callable, optional): Optional transform to be applied on a sample.\n",
    "        \"\"\"\n",
    "        self.root_dir = os.path.join(root_dir, split)\n",
    "        self.transform = transform\n",
    "        self.images_dir = os.path.join(self.root_dir, 'images')\n",
    "        self.labels_dir = os.path.join(self.root_dir, 'labels')\n",
    "        self.image_files = [f for f in os.listdir(self.images_dir) if os.path.isfile(os.path.join(self.images_dir, f))]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.images_dir, self.image_files[idx])\n",
    "        image = Image.open(img_name).convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        label_name = os.path.splitext(self.image_files[idx])[0] + '.txt'\n",
    "        label_path = os.path.join(self.labels_dir, label_name)\n",
    "        boxes = self.parse_labels(label_path)\n",
    "\n",
    "        sample = {'image': image, 'boxes': boxes} \n",
    "\n",
    "        return sample\n",
    "\n",
    "    def parse_labels(self, label_path):\n",
    "        \"\"\"\n",
    "        Parse the label file and return the target format expected by the model.\n",
    "        The label file contains lines in the format: class x_center y_center width height.\n",
    "        \"\"\"\n",
    "        boxes = []\n",
    "        with open(label_path, 'r') as file:\n",
    "            for line in file:\n",
    "                class_label, x_center, y_center, width, height = map(float, line.split())\n",
    "                boxes.append([class_label, x_center, y_center, width, height])\n",
    "        return torch.tensor(boxes)\n",
    "\n",
    "# Usage example\n",
    "dataset = ObjectDetectionDataset(root_dir='/path/to/your/data', split='train')\n",
    "sample = dataset[0]  # Get the first sample\n",
    "print(sample)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d246134b",
   "metadata": {},
   "source": [
    "> Pytorch Image Models (TIMM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e569b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "from timm.scheduler import CosineLRScheduler\n",
    "from timm.utils import model_parameters\n",
    "\n",
    "# List all available models\n",
    "all_models = timm.list_models()\n",
    "\n",
    "# List models pre-trained on ImageNet\n",
    "pretrained_models = timm.list_models(pretrained=True)\n",
    "all_densenet_models = timm.list_models('*densenet*')    # search for model architectures using Wildcard. this will list all densenet models\n",
    "\n",
    "# Create a model with pretrained weights\n",
    "model = timm.create_model('resnet50', pretrained=True)\n",
    "\n",
    "# Create a model with a specific number of output classes (e.g., 10)\n",
    "model = timm.create_model('resnet50', pretrained=True, num_classes=10)\n",
    "model.eval()\n",
    "\n",
    "lr_scheduler = CosineLRScheduler(optimizer, t_initial=len(train_loader)*num_epochs)\n",
    "\n",
    "# Counting the number of parameters\n",
    "num_params = model_parameters(model, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b572ca46",
   "metadata": {},
   "source": [
    "> Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e497328",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Core CV tasks in Hugging Face:\n",
    "    # Image classification\n",
    "    # Image segmentation\n",
    "    # (Zero-shot) object detection\n",
    "    # Video classification\n",
    "    # Depth estimation\n",
    "    # Image-to-image synthesis\n",
    "    # Unconditional image generation\n",
    "    # Zero-shot image classification\n",
    "    \n",
    "# Tasks that lie at the intersection of vision and language:\n",
    "    # Image-to-text (image captioning, OCR)\n",
    "    # Text-to-image\n",
    "    # Document question-answering\n",
    "    # Visual question-answering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44b68c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a pipeline as a high-level helper\n",
    "from transformers import pipeline, AutoImageProcessor, AutoModelForObjectDetection, DetrImageProcessor, DetrForObjectDetection\n",
    "\n",
    "pipe = pipeline(\"object-detection\", model=\"facebook/detr-resnet-50\") \n",
    "output = pipe(\"http://images.cocodataset.org/val2017/000000039769.jpg\")\n",
    "\n",
    "processor = AutoImageProcessor.from_pretrained(\"facebook/detr-resnet-50\")\n",
    "model = AutoModelForObjectDetection.from_pretrained(\"facebook/detr-resnet-50\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a1d109",
   "metadata": {},
   "source": [
    "> Supervision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d941c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://supervision.roboflow.com/             # reusable code for computer vision \n",
    "import supervision as sv\n",
    "\n",
    "# Model Detection and Classification\n",
    "    detr = sv.Detections     # class for getting detections from model. params are: bbox (xyxy), confidence scores, labels(class_id).\n",
    "        # attributes\n",
    "        detr.class_id   # Identifier for the detected object class.\n",
    "        detr.confidence # Confidence score for the detection.\n",
    "        detr.box_area   # The area of the detection bounding box.\n",
    "        detr.mask       # The mask of the detected object, if available.\n",
    "        detr.tracker_id     # The ID assigned to the detected object by a tracker.\n",
    "        detr.area           # Alias for box_area.\n",
    "        detr.get_anchors_coordinates # Retrieve anchor coordinates for detections.\n",
    "        detr.with_nms       # Apply Non-Maximum Suppression (NMS) to filter detections\n",
    "        # initialization and conversion\n",
    "            results = model(image)[0]\n",
    "            detections = sv.Detections.from_ultralytics(results)\n",
    "        detr.from_detectron2        # Initialize from Detectron2 library output.\n",
    "        detr.from_ultralytics       # Initialize from Ultralytics output.\n",
    "        detr.from_deepsparse        # Initialize from DeepSparse output.\n",
    "        detr.from_roboflow          # Initialize from Roboflow detection output.\n",
    "        detr.from_sam               # Initialize from Segment Anything Model.\n",
    "        detr.from_transformers      # Initialize from Hugging Face's transformers output.\n",
    "        \n",
    "    clasf = sv.Classifications # function for getting classifications from model.\n",
    "        # attributes\n",
    "        clasf.confidence    # Confidence score for the classification.\n",
    "        clasf.from_clip    # Initialize from OpenAI's CLIP model output.\n",
    "        clasf.from_timm   # Initialize from PyTorch Image Models (timm) output.\n",
    "        clasf.rom_ultralytics   # Initialize from Ultralytics output.\n",
    "        clasf.get_top_k   # Get the top k classifications.\n",
    "\n",
    "# Datasets and annotators\n",
    "    sv.BaseDataset                              # Base class for creating custom datasets.\n",
    "    sv.ClassificationDataset                    # For classification tasks.\n",
    "    sv.DetectionDataset                         # For object detection tasks.\n",
    "    sv.BoundingBoxAnnotator, sv.BoxAnnotator, sv.BoxCornerAnnotator,      # Annotate bounding boxes.\n",
    "    sv.CircleAnnotator, sv.LabelAnnotator, sv.PolygonAnnotator, sv.TraceAnnotator,  # Annotate circles, labels, polygons, and traces.\n",
    "    \n",
    "# Drawing Functions\n",
    "    sv.draw_image | sv.draw_line | sv.draw_polygon | sv.draw_rectangle | sv.draw_text   # Functions to draw various shapes and text on images.\n",
    "    sv.draw_filled_rectangle                                                            # Draw filled rectangles.\n",
    "    sv.plot_image, sv.plot_images_grid                                                  # Plot single or grid of images.\n",
    "\n",
    "# Metrics and Evaluation\n",
    "    sv.metrics # Metrics for evaluation.\n",
    "    sv.ConfusionMatrix,       # Generate a confusion matrix.\n",
    "    sv.MeanAveragePrecision     # Calculate mean average precision for detection tasks.\n",
    "\n",
    "# Geometry and Tracking\n",
    "    sv.Point, sv.Position, sv.Rect       # Basic geometric entities.\n",
    "    sv.ByteTrack                         # Tracking algorithm implementation.\n",
    "    sv.LineZone, sv.PolygonZone          # Define zones as lines or polygons.\n",
    "    \n",
    "# Annotators (More detailed)\n",
    "    sv.BlurAnnotator                         # Apply blur effect to annotations.\n",
    "    sv.BoundingBoxAnnotator, sv.BoxAnnotator, sv.BoxCornerAnnotator     # Annotate bounding boxes.\n",
    "    sv.CircleAnnotator                                      # Annotate circles.\n",
    "    sv.ColorAnnotator                                       # Apply color to annotations.\n",
    "    sv.DotAnnotator                                         # Annotate single points.\n",
    "    sv.EllipseAnnotator                                     # Annotate ellipses.\n",
    "    sv.LabelAnnotator                                       # Add labels to annotations.\n",
    "    sv.LineZoneAnnotator                                    # Annotate line zones.\n",
    "    sv.MaskAnnotator                                        # Annotate with masks.\n",
    "    sv.PixelateAnnotator                                    # Pixelate certain areas.\n",
    "    sv.PolygonAnnotator                                     # Annotate polygons.\n",
    "    sv.PolygonZoneAnnotator                                 # Annotate polygon zones.\n",
    "    sv.TraceAnnotator                                       # Trace annotations.\n",
    "    sv.TriangleAnnotator                                    # Annotate triangles.\n",
    "    \n",
    "# Utilities\n",
    "    sv.Color, sv.ColorLookup, sv.ColorPalette       # Utilities for handling colors.\n",
    "    sv.FPSMonitor      # Monitor frames per second in video processing.\n",
    "    sv.ImageSink, sv.VideoSink      # save an image or video in a target directory.\n",
    "    sv.InferenceSlicer      # Slice images for inference.\n",
    "    \n",
    "    # code for videos\n",
    "    sv.VideoInfo        # Retrieve video information. \n",
    "    sv.process_video        # Process video files.\n",
    "    sv.get_video_frames_generator    # Utility function to get video frames as a generator.\n",
    "\n",
    "    sv.box_iou_batch        # Calculate Intersection over Union (IoU) for batches of boxes.\n",
    "    sv.calculate_dynamic_line_thickness, sv.calculate_dynamic_text_scale        # Calculate dynamic sizes based on image dimensions.\n",
    "    sv.calculate_masks_centroids       # Calculate centroids of masks.\n",
    "    sv.list_files_with_extensions       # List files in a directory with specific extensions.\n",
    "    sv.polygon_to_mask, sv.polygon_to_xyxy      # Convert polygons to masks or bounding box coordinates.\n",
    "     \n",
    "# Data Manipulation and Processing\n",
    "    sv.crop_image       # Crop images.\n",
    "    sv.filter_polygons_by_area      # Filter polygons based on area.\n",
    "    sv.get_polygon_center, sv.get_video_frames_generator        # Utility functions for polygons and video frame processing.\n",
    "    sv.mask_to_polygons, sv.mask_to_xyxy        # Convert masks to polygons or bounding box coordinates.\n",
    "    sv.move_boxes, sv.non_max_suppression, sv.scale_boxes       # Manipulate bounding boxes.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc252ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examples:\n",
    "\n",
    "import supervision as sv\n",
    "\n",
    "# initiate polygon zone\n",
    "polygon = np.array([\n",
    "    [540,  985],\n",
    "    [1620, 985],\n",
    "    [2160, 1920],\n",
    "    [1620, 2855],\n",
    "    [540,  2855],\n",
    "    [0,    1920]\n",
    "])\n",
    "\n",
    "video_info = sv.VideoInfo.from_video_path(MALL_VIDEO_PATH)   # Get video information from a specific video file path.\n",
    "zone = sv.PolygonZone(polygon=polygon, frame_resolution_wh=video_info.resolution_wh)\n",
    "box_annotator = sv.BoxAnnotator(thickness=4, text_thickness=4, text_scale=2)\n",
    "zone_annotator = sv.PolygonZoneAnnotator(zone=zone, color=sv.Color.white(), thickness=6, text_thickness=6, text_scale=4)\n",
    "\n",
    "\n",
    "# extract video frame\n",
    "generator = sv.get_video_frames_generator(MALL_VIDEO_PATH)\n",
    "iterator = iter(generator)\n",
    "frame = next(iterator)\n",
    "\n",
    "# detect\n",
    "results = model(frame, imgsz=1280)[0]\n",
    "detections = sv.Detections(\n",
    "    xyxy=results[\"instances\"].pred_boxes.tensor.cpu().numpy(),\n",
    "    confidence=results[\"instances\"].scores.cpu().numpy(),\n",
    "    class_id=results[\"instances\"].pred_classes.cpu().numpy().astype(int)\n",
    ")\n",
    "mask = zone.trigger(detections=detections)\n",
    "\n",
    "# annotate\n",
    "box_annotator = sv.BoxAnnotator(thickness=4, text_thickness=4, text_scale=2)\n",
    "labels = [f\"{model.names[class_id]} {confidence:0.2f}\" for _, confidence, class_id, _ in detections]\n",
    "frame = box_annotator.annotate(scene=frame, detections=detections, labels=labels)\n",
    "frame = zone_annotator.annotate(scene=frame)\n",
    "\n",
    "\n",
    "def process_frame(frame: np.ndarray, _) -> np.ndarray:\n",
    "    # detect\n",
    "    results = model(frame, imgsz=1280)[0]\n",
    "    detections = sv.Detections.from_yolov8(results)\n",
    "    detections = detections[detections.class_id == 0]\n",
    "    zone.trigger(detections=detections)\n",
    "\n",
    "    # annotate\n",
    "    box_annotator = sv.BoxAnnotator(thickness=4, text_thickness=4, text_scale=2)\n",
    "    labels = [f\"{model.names[class_id]} {confidence:0.2f}\" for _, confidence, class_id, _ in detections]\n",
    "    frame = box_annotator.annotate(scene=frame, detections=detections, labels=labels)\n",
    "    frame = zone_annotator.annotate(scene=frame)\n",
    "\n",
    "    return frame\n",
    "\n",
    "sv.process_video(source_path=MALL_VIDEO_PATH, target_path=f\"{HOME}/mall-result.mp4\", callback=process_frame)\n",
    "\n",
    "\n",
    "%matplotlib inline  \n",
    "sv.show_frame_in_notebook(frame, (16, 16))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47a2773",
   "metadata": {},
   "source": [
    "> Detectron2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d58f952",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/facebookresearch/detectron2 \n",
    "\n",
    "import cv2  \n",
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "# Import necessary modules\n",
    "from detectron2 import model_zoo                    # to access all the models available \n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer, ColorMode \n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "\n",
    "\n",
    "######################################################################################################################################\n",
    "# Step 1: Register the dataset with Detectron2 \n",
    "######################################################################################################################################\n",
    "\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "\n",
    "# Step 1: Define the dataset format and paths (do for train, val, and test datasets)\n",
    "dataset_name = \"fruit_dataset\"\n",
    "json_file = \"/path/to/your/annotations/train.json\"  # Update this path\n",
    "image_root = \"/path/to/your/fruit_images\"  # Update this path\n",
    "\n",
    "# Step 2: Register the dataset\n",
    "# This function registers the dataset in COCO format with Detectron2 and makes it accessible via the DatasetCatalog and MetadataCatalog.\n",
    "register_coco_instances(name = dataset_name, \n",
    "                        metadata={}, \n",
    "                        json_file=json_file, \n",
    "                        image_root=image_root)                        # train dataset\n",
    "register_coco_instances(\"dataset_val_name\", {}, \"/path/to/your/annotations/val.json\", \"/path/to/your/fruit_images\")  # val dataset \n",
    "register_coco_instances(\"dataset_test_name\", {}, \"/path/to/your/annotations/test.json\", \"/path/to/your/fruit_images\")  # test dataset \n",
    "\n",
    "# Optional: Verify dataset registration and metadata (e.g., class names)\n",
    "fruit_metadata = MetadataCatalog.get(dataset_name)\n",
    "print(f\"Registered dataset with metadata: {fruit_metadata}\")\n",
    "# or\n",
    "[ data_set for data_set in MetadataCatalog.list() if data_set.startswith(DATA_SET_NAME) ]\n",
    "\n",
    "\n",
    "MetadataCatalog.get(dataset_name).set(thing_classes=[\"apple\", \"orange\", \"banana\"])    # class names\n",
    "DatasetCatalog.register(dataset_name, MetadataCatalog.get(dataset_name))              # dataset metadata\n",
    "\n",
    "######################################################################################################################################\n",
    "# Step 2: Load the model configuration and pre-trained model\n",
    "######################################################################################################################################\n",
    "\n",
    "# The following code snippet loads a pre-trained object detection model from Detectron2's model zoo. The specific model used here is \"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\", which is pre-trained on the COCO dataset. You can change the model configuration and pre-trained weights based on your specific use case and requirements.\n",
    "\n",
    "setup_logger() # Set up Detectron2 logger\n",
    "\n",
    "def load_model(model_name, *args, **kwargs):\n",
    "        # Load model configuration and pre-trained model from the model zoo\n",
    "        cfg = get_cfg()\n",
    "        # finetune from a pretrained model\n",
    "\n",
    "        cfg.SOLVER.IMS_PER_BATCH = 2\n",
    "        cfg.SOLVER.BASE_LR = 0.0025\n",
    "        cfg.SOLVER.MAX_ITER = 1000\n",
    "        cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128\n",
    "        cfg.MODEL.DEVICE = 'cuda'   #cpu or cuda \n",
    "        \n",
    "        # Dataset & DataLoader settings\n",
    "        cfg.DATASETS.TRAIN = (\"dataset_train\",)\n",
    "        cfg.DATASETS.TEST = (\"dataset_val\",)\n",
    "        cfg.DATALOADER.NUM_WORKERS = 4  # Number of data loading workers\n",
    "\n",
    "        # Solver (Optimization) settings\n",
    "        cfg.SOLVER.IMS_PER_BATCH = 16  # Images per batch\n",
    "        cfg.SOLVER.BASE_LR = 0.001  # Base Learning Rate\n",
    "        cfg.SOLVER.MAX_ITER = 10000  # Number of iterations (updates to the model)\n",
    "        cfg.SOLVER.STEPS = (7000, 9000)  # Points to decay the learning rate\n",
    "        cfg.SOLVER.GAMMA = 0.1  # Learning rate decay multiplier\n",
    "        cfg.SOLVER.WARMUP_ITERS = 1000  # Warm-up iterations before learning rate scheduler starts\n",
    "        cfg.SOLVER.WARMUP_FACTOR = 1.0 / 1000  # Starting factor for learning rate\n",
    "        cfg.SOLVER.WARMUP_METHOD = \"linear\"  # Method for learning rate warm-up\n",
    "\n",
    "        # Model settings\n",
    "        cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = 128  # Number of proposals to sample for training\n",
    "        cfg.MODEL.ROI_HEADS.NUM_CLASSES = 20  # Number of classes in your dataset\n",
    "        cfg.MODEL.BACKBONE.FREEZE_AT = 2  # Freeze the first k stages of the backbone\n",
    "        cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5  # Confidence threshold for predictions during testing\n",
    "\n",
    "        # Output directory\n",
    "        cfg.OUTPUT_DIR = \"./output\"\n",
    "\n",
    "        # Checkpoint settings\n",
    "        cfg.SOLVER.CHECKPOINT_PERIOD = 1000  # Save a checkpoint after every N iterations\n",
    "        \n",
    "        # Load a pre-defined config from Detectron2's model zoo\n",
    "        cfg.merge_from_file(model_zoo.get_config_file(model_name))\n",
    "        cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(model_name)\n",
    "        predictor = DefaultPredictor(cfg)  # Create a predictor from a config file. It requires the model weights to be available on the machine.\n",
    "        return predictor, cfg \n",
    "\n",
    "                # model_zoo.get_config_file(\"COCO-Detection/faster_rcnn_R_50_FPN_3x.yaml\")        # object detection-COCO dataset\n",
    "                # model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")  # instance segmentation-COCO dataset\n",
    "                # model_zoo.get_config_file(\"COCO-PanopticSegmentation/panoptic_fpn_R_50_3x.yaml\")  # panoptic segmentation-COCO dataset\n",
    "                # model_zoo.get_config_file(\"COCO-Keypoints/keypoint_rcnn_R_50_FPN_3x.yaml\")        # keypoint detection-COCO dataset\n",
    "\n",
    "predictor, cfg = load_model(model_name, *args, **kwargs)\n",
    "\n",
    "######################################################################################################################################\n",
    "# Step 3: Train the Detectron2 model\n",
    "######################################################################################################################################\n",
    "import logging\n",
    "from collections import OrderedDict\n",
    "from detectron2.engine import DefaultTrainer, DEFAULT_TIMEOUT, default_argument_parser, default_setup, hooks, launch\n",
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.data import build_detection_test_loader \n",
    "from detectron2.evaluation import (\n",
    "    DatasetEvaluator,\n",
    "    DatasetEvaluators,\n",
    "    inference_on_dataset,\n",
    "    print_csv_format,\n",
    ")\n",
    "from detectron2.config import CfgNode\n",
    "from detectron2.utils import comm\n",
    "import os \n",
    "from typing import List, Optional, Union\n",
    "from densepose.modeling.cse import Embedder\n",
    "\n",
    "\n",
    "# Extend the DefaultTrainer to use a custom evaluator\n",
    "class Trainer(DefaultTrainer):\n",
    "    @classmethod\n",
    "    def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n",
    "        if output_folder is None:\n",
    "            os.makedirs(cfg.OUTPUT_DIR + \"/coco_eval\", exist_ok=True)\n",
    "            output_folder = cfg.OUTPUT_DIR + \"/coco_eval\"\n",
    "        return COCOEvaluator(dataset_name, cfg, False, output_folder)\n",
    "\n",
    "# or \n",
    "class Trainer(DefaultTrainer):\n",
    "    @classmethod\n",
    "    def extract_embedder_from_model(cls, model: nn.Module) -> Optional[Embedder]:\n",
    "        if isinstance(model, nn.parallel.DistributedDataParallel):\n",
    "            model = model.module\n",
    "        if hasattr(model, \"roi_heads\") and hasattr(model.roi_heads, \"embedder\"):\n",
    "            return model.roi_heads.embedder\n",
    "        return None\n",
    "\n",
    "    # TODO: the only reason to copy the base class code here is to pass the embedder from\n",
    "    # the model to the evaluator; that should be refactored to avoid unnecessary copy-pasting\n",
    "    @classmethod\n",
    "    def test(\n",
    "        cls,\n",
    "        cfg: CfgNode,\n",
    "        model: nn.Module,\n",
    "        evaluators: Optional[Union[DatasetEvaluator, List[DatasetEvaluator]]] = None,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            cfg (CfgNode):\n",
    "            model (nn.Module):\n",
    "            evaluators (DatasetEvaluator, list[DatasetEvaluator] or None): if None, will call\n",
    "                :meth:`build_evaluator`. Otherwise, must have the same length as\n",
    "                ``cfg.DATASETS.TEST``.\n",
    "\n",
    "        Returns:\n",
    "            dict: a dict of result metrics\n",
    "        \"\"\"\n",
    "        logger = logging.getLogger(__name__)\n",
    "        if isinstance(evaluators, DatasetEvaluator):\n",
    "            evaluators = [evaluators]\n",
    "        if evaluators is not None:\n",
    "            assert len(cfg.DATASETS.TEST) == len(evaluators), \"{} != {}\".format(\n",
    "                len(cfg.DATASETS.TEST), len(evaluators)\n",
    "            )\n",
    "\n",
    "        results = OrderedDict()\n",
    "        for idx, dataset_name in enumerate(cfg.DATASETS.TEST):\n",
    "            data_loader = cls.build_test_loader(cfg, dataset_name)\n",
    "            # When evaluators are passed in as arguments,\n",
    "            # implicitly assume that evaluators can be created before data_loader.\n",
    "            if evaluators is not None:\n",
    "                evaluator = evaluators[idx]\n",
    "            else:\n",
    "                try:\n",
    "                    embedder = cls.extract_embedder_from_model(model)\n",
    "                    evaluator = cls.build_evaluator(cfg, dataset_name, embedder=embedder)\n",
    "                except NotImplementedError:\n",
    "                    logger.warn(\n",
    "                        \"No evaluator found. Use `DefaultTrainer.test(evaluators=)`, \"\n",
    "                        \"or implement its `build_evaluator` method.\"\n",
    "                    )\n",
    "                    results[dataset_name] = {}\n",
    "                    continue\n",
    "            if cfg.DENSEPOSE_EVALUATION.DISTRIBUTED_INFERENCE or comm.is_main_process():\n",
    "                results_i = inference_on_dataset(model, data_loader, evaluator)\n",
    "            else:\n",
    "                results_i = {}\n",
    "            results[dataset_name] = results_i\n",
    "            if comm.is_main_process():\n",
    "                assert isinstance(\n",
    "                    results_i, dict\n",
    "                ), \"Evaluator must return a dict on the main process. Got {} instead.\".format(\n",
    "                    results_i\n",
    "                )\n",
    "                logger.info(\"Evaluation results for {} in csv format:\".format(dataset_name))\n",
    "                print_csv_format(results_i)\n",
    "\n",
    "        if len(results) == 1:\n",
    "            results = list(results.values())[0]\n",
    "        return results\n",
    "    \n",
    "# either write the trainer class or use the default trainer below\n",
    "\n",
    "# Initialize the trainer and start training\n",
    "trainer = Trainer(cfg)\n",
    "trainer.resume_or_load(resume=False)\n",
    "if cfg.TEST.AUG.ENABLED:\n",
    "    trainer.register_hooks(\n",
    "        [hooks.EvalHook(0, lambda: trainer.test_with_TTA(cfg, trainer.model))]\n",
    "    )\n",
    "trainer.train()\n",
    "\n",
    "\n",
    "######################################################################################################################################\n",
    "# Step 4: Make Predictions an image/video\n",
    "######################################################################################################################################\n",
    "\n",
    "# Load an image for object detection\n",
    "image_path = \"path/to/object_detection_image.jpg\"\n",
    "im = cv2.imread(image_path)\n",
    "\n",
    "metadata = MetadataCatalog.get(TRAIN_DATA_SET_NAME)     # get the metadata for the dataset used during training (should be the same as in step 1)\n",
    "dataset_train = DatasetCatalog.get(TRAIN_DATA_SET_NAME)\n",
    "\n",
    "# OBJECT DETECTION\n",
    "# Make object detection prediction\n",
    "outputs = predictor(im)\n",
    "# Visualize object detection predictions\n",
    "v = Visualizer(im[:, :, ::-1], metadata= MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=1.2, \n",
    "               instance_mode=ColorMode.IMAGE_BW) \n",
    "                    # ColorMode.IMAGE \n",
    "                    # ColorMode.IMAGE_BW\n",
    "                    # ColorMode.SEGMENTATION\n",
    "v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "cv2.imshow(\"Object Detection\", v.get_image()[:, :, ::-1])\n",
    "cv2.waitKey(0)\n",
    "\n",
    "\n",
    "\n",
    "# INSTANCE SEGMENTATION                - change the predictor to a segmentation model \n",
    "# Make image segmentation prediction\n",
    "outputs = predictor(im)\n",
    "# Visualize image segmentation predictions\n",
    "v = Visualizer(im[:, :, ::-1], metadata= MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=1.2, \n",
    "               instance_mode=ColorMode.IMAGE_BW)\n",
    "v = v.draw_sem_seg(outputs[\"sem_seg\"].argmax(dim=0).to(\"cpu\"))\n",
    "cv2.imshow(\"Image Segmentation\", v.get_image()[:, :, ::-1])\n",
    "cv2.waitKey(0)\n",
    "\n",
    "        # Visualizer.draw_instance_predictions()\n",
    "        # Visualizer.draw_panoptic_seg()\n",
    "        # Visualizer.draw_panoptic_seg_predictions()\n",
    "        # Visualizer.draw_sem_seg() \n",
    "        \n",
    "\n",
    "\n",
    "######################################################################################################################################\n",
    "# Structure of your dataset should look like this:\n",
    "######################################################################################################################################\n",
    "\n",
    "'''\n",
    "dataset-directory/\n",
    "├─ README.dataset.txt\n",
    "├─ README.roboflow.txt\n",
    "├─ train\n",
    "│  ├─ train-image-1.jpg\n",
    "│  ├─ train-image-1.jpg\n",
    "│  ├─ ...\n",
    "│  └─ _annotations.coco.json\n",
    "├─ test\n",
    "│  ├─ test-image-1.jpg\n",
    "│  ├─ test-image-1.jpg\n",
    "│  ├─ ...\n",
    "│  └─ _annotations.coco.json\n",
    "└─ valid\n",
    "   ├─ valid-image-1.jpg\n",
    "   ├─ valid-image-1.jpg\n",
    "   ├─ ...\n",
    "   └─ _annotations.coco.json\n",
    "\n",
    "\n",
    "\n",
    "annotations.coco.json\n",
    "{\n",
    "    \"info\":{\n",
    "        \"year\":\"2024\",\n",
    "        \"version\":\"5\",\n",
    "        \"description\":\"Exported from roboflow.com\",\n",
    "        \"contributor\":\"\",\n",
    "        \"url\":\"https://public.roboflow.com/object-detection/undefined\",\n",
    "        \"date_created\":\"2024-02-06T02:29:57+00:00\"},\n",
    "        \"licenses\":[{\"id\":1,\"url\":\"https://creativecommons.org/licenses/by/4.0/\",\"name\":\"CC BY 4.0\"}],\n",
    "    \"categories\":[\n",
    "        {\"id\":0,\"name\":\"Comodities\",\"supercategory\":\"none\"},\n",
    "        {\"id\":1,\"name\":\"agriculture\",\"supercategory\":\"Comodities\"},\n",
    "        {\"id\":2,\"name\":\"building\",\"supercategory\":\"Comodities\"},\n",
    "        {\"id\":3,\"name\":\"cloud\",\"supercategory\":\"Comodities\"},\n",
    "        {\"id\":4,\"name\":\"forest\",\"supercategory\":\"Comodities\"}],\n",
    "    \"images\":[\n",
    "        {\"id\":0,\"license\":1,\"file_name\":\"PAN_4e82d531-6f00-4f9e-9201-09903f2d0ab2_png.rf.2df4e8b1a5ebcb9eda1b690d6eeef51f.jpg\",\"height\":256,\"width\":256,\"date_captured\":\"2024-02-06T02:29:57+00:00\"},\n",
    "        {\"id\":1,\"license\":1,\"file_name\":\"PAN_3d1811f6-ef40-4899-a745-67978477fc8b_png.rf.430b9a64ae7949049d6511b755928f17.jpg\",\"height\":256,\"width\":256,\"date_captured\":\"2024-02-06T02:29:57+00:00\"},\n",
    "        {\"id\":2,\"license\":1,\"file_name\":\"PAN_13a6b3b2-73e9-4442-a7c3-b7810de0d389_png.rf.76ff23e585fc7cb319e01f42d4e4d728.jpg\",\"height\":256,\"width\":256,\"date_captured\":\"2024-02-06T02:29:57+00:00\"},\n",
    "        {\"id\":3,\"license\":1,\"file_name\":\"PAN_1a45bec3-98b0-4fdd-ac68-a8b7943b792e_png.rf.46993983202dc374d5fd2d596b3e8c1a.jpg\",\"height\":256,\"width\":256,\"date_captured\":\"2024-02-06T02:29:57+00:00\"}],\n",
    "    \"annotations\":[\n",
    "        {\"id\":0,\"image_id\":0,\"category_id\":4,\"bbox\":[0,0,256,255.93],\"area\":65518.08,\"segmentation\":[[0,-0.005,256,-0.005,256,255.925,0,255.925]],\"iscrowd\":0},\n",
    "        {\"id\":1,\"image_id\":0,\"category_id\":7,\"bbox\":[73,0,116.25,49.25],\"area\":5725.313,\"segmentation\":[[96.5,49.25,106.25,49,137.75,33,151.25,32.5,166.25,25,180.75,25,189,14.75,188.5,4.75,184.444,0,72.75,0,84.5,36.75,92,48.25]],\"iscrowd\":0},{\"id\":2,\"image_id\":0,\"category_id\":7,\"bbox\":[0,0,187.778,256],\"area\":48071.117,\"segmentation\":[[187.778,256,164.25,247,158.75,250.5,149.5,230.25,139.5,224.75,131.25,206.5,116.5,230.75,113,230.75,123.5,208.25,116.5,200.25,124,199.75,113,196.75,124,195.25,117,193.75,116.5,183.25,108.5,174.75,107,163.25,97.5,158.25,98.75,152.5,94.25,152,93.25,156,92.25,152,87.5,152.75,90.25,159.5,95.5,160.25,88.75,167.5,60.5,167.25,60,160.75,56,159.25,60,152.25,55.5,150.75,55.5,144.75,59.75,144,60,151.75,64.75,153,73.75,151.5,73.5,144.75,68.75,140,67.75,144,61.5,142.25,59.5,120.25,62.5,119.25,58.25,119,54.75,112,49.75,115,38.25,111,40.5,108.75,35.5,107.25,34.75,99.5,28.25,99.5,25,107.25,27,98.75,32,96.25,30.25,91.5,25,95.25,25,89.75,31.5,88.75,23.75,88,20.5,79.25,27.5,40.25,10.5,14.75,10,3.75,0,0,0,256]],\"iscrowd\":0},\n",
    "        {\"id\":3,\"image_id\":1,\"category_id\":4,\"bbox\":[0,0,256,256],\"area\":65536,\"segmentation\":[[0,0,256,0,256,256,0,256]],\"iscrowd\":0}]\n",
    "}\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f7bf61",
   "metadata": {},
   "source": [
    "> YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363a1ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "# ================================\n",
    "# DIFFERENT WAYS TO BUILD A MODEL\n",
    "# ================================\n",
    "\n",
    "model = YOLO('yolov8n.pt', task='detect')  # load a pretrained object detection model (start with this if you are training)\n",
    "    # model = YOLO('yolov8n-cls.pt')  # load a pretrained YOLOv8n classification model\n",
    "    # model = YOLO('yolov8n-s.yaml')  # build a YOLOv8n segmentation model from YAML\n",
    "    # model = YOLO('yolov8n-pose.pt')  # load a pretrained YOLOv8n pose model\n",
    "    # model = YOLO('yolov8n.yaml', task='detect')  # build a YOLOv8n detection model from YAML\n",
    "model = YOLO('yolov8n.yaml').load('yolov8n.pt') # build from YAML and transfer weights from a pretrained model\n",
    "\n",
    "# task: detect # (str) YOLO task, i.e. detect, segment, classify, pose\n",
    "# mode: train # (str) YOLO mode, i.e. train, val, predict, export, track, benchmark\n",
    "\n",
    "# Important model functions \n",
    "results = model.train(data='coco128.yaml', epochs=100, imgsz=640, device=[0, 1]) # train a YOLOv8n model for 100 epochs on 640x640 images in two GPUs\n",
    "model.predict(source='bus.jpg', stream = False, save=True, imgsz=320, conf=0.5, show_boxes=True) # predict on an image\n",
    "    # results = model(\"https://ultralytics.com/images/bus.jpg\")  # predict on an image\n",
    "    # if stream = True, it treats the input source as a continuous video stream for predictions\n",
    "model.val()     # evaluate model performance on the validation set\n",
    "model.export(format = \"onnx\")  # Export a YOLOv8 model to any supported format (other formar: torchscript, paddle, openvino, coreml, tflite, savedmodel, etc.)\n",
    "model.track(source=\"https://youtu.be/LNwODJXcvt4\", tracker=\"bytetrack.yaml\", stream = False, persist=True, conf=0.3, iou=0.5, show=True)   # track objects in a video\n",
    "model.benchmark()   # benchmark the model's speed and accuracy\n",
    "\n",
    "\n",
    "results = model.train(resume=True)  # resume training after interrrupted session\n",
    "\n",
    "# Use the model\n",
    "model.train(data=\"coco128.yaml\", epochs=3)  # train the model\n",
    "metrics = model.val()  # evaluate model performance on the validation set\n",
    "results = model(\"https://ultralytics.com/images/bus.jpg\")  # predict on an image\n",
    "    # results[0].plot()\n",
    "    # results[0].boxes()\n",
    "    # results[0].names\n",
    "    # results[0].masks()\n",
    "    # results[0].xyxy[0]\n",
    "    \n",
    "path = model.export(format=\"onnx\")  # export the model to ONNX format\n",
    "\n",
    "# Validate the model\n",
    "metrics = model.val()  # no arguments needed, dataset and settings remembered\n",
    "metrics.box.map    # map50-95\n",
    "metrics.box.map50  # map50\n",
    "metrics.box.map75  # map75\n",
    "metrics.box.maps   # a list contains map50-95 of each category\n",
    "\n",
    "# using YOLO on video file or webcam\n",
    "model = YOLO('yolov8n.pt')\n",
    "\n",
    "video_path = \"path/to/your/video/file.mp4\"\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Loop through the video frames\n",
    "while cap.isOpened():\n",
    "    # Read a frame from the video\n",
    "    success, frame = cap.read()\n",
    "\n",
    "    if success:\n",
    "        # Run YOLOv8 inference on the frame\n",
    "        results = model(frame)\n",
    "\n",
    "        # Visualize the results on the frame\n",
    "        annotated_frame = results[0].plot()\n",
    "\n",
    "        # Display the annotated frame\n",
    "        cv2.imshow(\"YOLOv8 Inference\", annotated_frame)\n",
    "\n",
    "        # Break the loop if 'q' is pressed\n",
    "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "            break\n",
    "    else:\n",
    "        # Break the loop if the end of the video is reached\n",
    "        break\n",
    "\n",
    "# Release the video capture object and close the display window\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "# other functions\n",
    "model.MODE(ARGS)    # Run MODE mode using the custom arguments ARGS \n",
    "\n",
    "\n",
    "# Using CLI\n",
    "!yolo task=detect mode=train model=yolov8s.pt data=data/data.yaml epochs=25 imgsz=800 plots=True\n",
    "!yolo task=segment mode=predict model=yolov8x-seg.pt source='input/video_3.mp4' show=True\n",
    "!yolo task=pose mode=predict source=bus.jpg show = True \n",
    "!yolo task=detect mode=track source=video.mp4 output=output.avi conf=cfg/yolov5s.yaml weights=yolov5s.pt\n",
    "!yolo task=benchmark model=yolov8n.pt data='coco8.yaml' imgsz=640 half=False device=0\n",
    "\n",
    "\n",
    "----------------------------------------------------------------\n",
    "# Move the trained runs into colab folder \n",
    "import shutil\n",
    "\n",
    "# Define the source and destination paths\n",
    "source_path = '/content/runs'\n",
    "destination_path = '/content/gdrive/MyDrive/Colab Notebooks/Licence-plate/runs'\n",
    "\n",
    "shutil.move(source_path, destination_path)  # Move the folder from source to destination path \n",
    "----------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "# YOLO data.yaml format  for training\n",
    "path: \"C:\\Users\\pault\\Documents\\5b. Datasets\\traffic signs detection\"\n",
    "train: data/train/images   # Path to the training images (relative to this file).\n",
    "val: data/valid/images    # Path to the validation images (relative to this file).\n",
    "test: ../test/images    # Path to the test images (relative to this file).\n",
    "nc: 5   # Number of classes\n",
    "names: ['Green Light', 'Red Light', 'Speed Limit 10', 'Speed Limit 100', 'Speed Limit 110']   # Class names. NB: # index must match the order of the class names here.\n",
    "# or\n",
    "names:\n",
    "- '0'\n",
    "- '1'\n",
    "- '2'\n",
    "- '3'\n",
    "- A\n",
    "- B\n",
    "- C\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409e25d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ultralytics YOLO 🚀, AGPL-3.0 license\n",
    "# Default training settings and hyperparameters for medium-augmentation COCO training\n",
    "\n",
    "task: detect # (str) YOLO task, i.e. detect, segment, classify, pose\n",
    "mode: train # (str) YOLO mode, i.e. train, val, predict, export, track, benchmark\n",
    "\n",
    "# Train settings -------------------------------------------------------------------------------------------------------\n",
    "model: # (str, optional) path to model file, i.e. yolov8n.pt, yolov8n.yaml\n",
    "data: # (str, optional) path to data file, i.e. coco128.yaml\n",
    "epochs: 100 # (int) number of epochs to train for\n",
    "time: # (float, optional) number of hours to train for, overrides epochs if supplied\n",
    "patience: 50 # (int) epochs to wait for no observable improvement for early stopping of training\n",
    "batch: 16 # (int) number of images per batch (-1 for AutoBatch)\n",
    "imgsz: 640 # (int | list) input images size as int for train and val modes, or list[w,h] for predict and export modes\n",
    "save: True # (bool) save train checkpoints and predict results\n",
    "save_period: -1 # (int) Save checkpoint every x epochs (disabled if < 1)\n",
    "cache: False # (bool) True/ram, disk or False. Use cache for data loading\n",
    "device: # (int | str | list, optional) device to run on, i.e. cuda device=0 or device=0,1,2,3 or device=cpu\n",
    "workers: 8 # (int) number of worker threads for data loading (per RANK if DDP)\n",
    "project: # (str, optional) project name\n",
    "name: # (str, optional) experiment name, results saved to 'project/name' directory\n",
    "exist_ok: False # (bool) whether to overwrite existing experiment\n",
    "pretrained: True # (bool | str) whether to use a pretrained model (bool) or a model to load weights from (str)\n",
    "optimizer: auto # (str) optimizer to use, choices=[SGD, Adam, Adamax, AdamW, NAdam, RAdam, RMSProp, auto]\n",
    "verbose: True # (bool) whether to print verbose output\n",
    "seed: 0 # (int) random seed for reproducibility\n",
    "deterministic: True # (bool) whether to enable deterministic mode\n",
    "single_cls: False # (bool) train multi-class data as single-class\n",
    "rect: False # (bool) rectangular training if mode='train' or rectangular validation if mode='val'\n",
    "cos_lr: False # (bool) use cosine learning rate scheduler\n",
    "close_mosaic: 10 # (int) disable mosaic augmentation for final epochs (0 to disable)\n",
    "resume: False # (bool) resume training from last checkpoint\n",
    "amp: True # (bool) Automatic Mixed Precision (AMP) training, choices=[True, False], True runs AMP check\n",
    "fraction: 1.0 # (float) dataset fraction to train on (default is 1.0, all images in train set)\n",
    "profile: False # (bool) profile ONNX and TensorRT speeds during training for loggers\n",
    "freeze: None # (int | list, optional) freeze first n layers, or freeze list of layer indices during training\n",
    "multi_scale: False # (bool) Whether to use multi-scale during training\n",
    "# Segmentation\n",
    "overlap_mask: True # (bool) masks should overlap during training (segment train only)\n",
    "mask_ratio: 4 # (int) mask downsample ratio (segment train only)\n",
    "# Classification\n",
    "dropout: 0.0 # (float) use dropout regularization (classify train only)\n",
    "\n",
    "# Val/Test settings ----------------------------------------------------------------------------------------------------\n",
    "val: True # (bool) validate/test during training\n",
    "split: val # (str) dataset split to use for validation, i.e. 'val', 'test' or 'train'\n",
    "save_json: False # (bool) save results to JSON file\n",
    "save_hybrid: False # (bool) save hybrid version of labels (labels + additional predictions)\n",
    "conf: # (float, optional) object confidence threshold for detection (default 0.25 predict, 0.001 val)\n",
    "iou: 0.7 # (float) intersection over union (IoU) threshold for NMS\n",
    "max_det: 300 # (int) maximum number of detections per image\n",
    "half: False # (bool) use half precision (FP16)\n",
    "dnn: False # (bool) use OpenCV DNN for ONNX inference\n",
    "plots: True # (bool) save plots and images during train/val\n",
    "\n",
    "# Predict settings -----------------------------------------------------------------------------------------------------\n",
    "source: # (str, optional) source directory for images or videos\n",
    "vid_stride: 1 # (int) video frame-rate stride\n",
    "stream_buffer: False # (bool) buffer all streaming frames (True) or return the most recent frame (False)\n",
    "visualize: False # (bool) visualize model features\n",
    "augment: False # (bool) apply image augmentation to prediction sources\n",
    "agnostic_nms: False # (bool) class-agnostic NMS\n",
    "classes: # (int | list[int], optional) filter results by class, i.e. classes=0, or classes=[0,2,3]\n",
    "retina_masks: False # (bool) use high-resolution segmentation masks\n",
    "embed: # (list[int], optional) return feature vectors/embeddings from given layers\n",
    "\n",
    "# Visualize settings ---------------------------------------------------------------------------------------------------\n",
    "show: False # (bool) show predicted images and videos if environment allows\n",
    "save_frames: False # (bool) save predicted individual video frames\n",
    "save_txt: False # (bool) save results as .txt file\n",
    "save_conf: False # (bool) save results with confidence scores\n",
    "save_crop: False # (bool) save cropped images with results\n",
    "show_labels: True # (bool) show prediction labels, i.e. 'person'\n",
    "show_conf: True # (bool) show prediction confidence, i.e. '0.99'\n",
    "show_boxes: True # (bool) show prediction boxes\n",
    "line_width: # (int, optional) line width of the bounding boxes. Scaled to image size if None.\n",
    "\n",
    "# Export settings ------------------------------------------------------------------------------------------------------\n",
    "format: torchscript # (str) format to export to, choices at https://docs.ultralytics.com/modes/export/#export-formats\n",
    "keras: False # (bool) use Kera=s\n",
    "optimize: False # (bool) TorchScript: optimize for mobile\n",
    "int8: False # (bool) CoreML/TF INT8 quantization\n",
    "dynamic: False # (bool) ONNX/TF/TensorRT: dynamic axes\n",
    "simplify: False # (bool) ONNX: simplify model\n",
    "opset: # (int, optional) ONNX: opset version\n",
    "workspace: 4 # (int) TensorRT: workspace size (GB)\n",
    "nms: False # (bool) CoreML: add NMS\n",
    "\n",
    "# Hyperparameters ------------------------------------------------------------------------------------------------------\n",
    "lr0: 0.01 # (float) initial learning rate (i.e. SGD=1E-2, Adam=1E-3)\n",
    "lrf: 0.01 # (float) final learning rate (lr0 * lrf)\n",
    "momentum: 0.937 # (float) SGD momentum/Adam beta1\n",
    "weight_decay: 0.0005 # (float) optimizer weight decay 5e-4\n",
    "warmup_epochs: 3.0 # (float) warmup epochs (fractions ok)\n",
    "warmup_momentum: 0.8 # (float) warmup initial momentum\n",
    "warmup_bias_lr: 0.1 # (float) warmup initial bias lr\n",
    "box: 7.5 # (float) box loss gain\n",
    "cls: 0.5 # (float) cls loss gain (scale with pixels)\n",
    "dfl: 1.5 # (float) dfl loss gain\n",
    "pose: 12.0 # (float) pose loss gain\n",
    "kobj: 1.0 # (float) keypoint obj loss gain\n",
    "label_smoothing: 0.0 # (float) label smoothing (fraction)\n",
    "nbs: 64 # (int) nominal batch size\n",
    "hsv_h: 0.015 # (float) image HSV-Hue augmentation (fraction)\n",
    "hsv_s: 0.7 # (float) image HSV-Saturation augmentation (fraction)\n",
    "hsv_v: 0.4 # (float) image HSV-Value augmentation (fraction)\n",
    "degrees: 0.0 # (float) image rotation (+/- deg)\n",
    "translate: 0.1 # (float) image translation (+/- fraction)\n",
    "scale: 0.5 # (float) image scale (+/- gain)\n",
    "shear: 0.0 # (float) image shear (+/- deg)\n",
    "perspective: 0.0 # (float) image perspective (+/- fraction), range 0-0.001\n",
    "flipud: 0.0 # (float) image flip up-down (probability)\n",
    "fliplr: 0.5 # (float) image flip left-right (probability)\n",
    "mosaic: 1.0 # (float) image mosaic (probability)\n",
    "mixup: 0.0 # (float) image mixup (probability)\n",
    "copy_paste: 0.0 # (float) segment copy-paste (probability)\n",
    "auto_augment: randaugment # (str) auto augmentation policy for classification (randaugment, autoaugment, augmix)\n",
    "erasing: 0.4 # (float) probability of random erasing during classification training (0-1)\n",
    "crop_fraction: 1.0 # (float) image crop fraction for classification evaluation/inference (0-1)\n",
    "\n",
    "# Custom config.yaml ---------------------------------------------------------------------------------------------------\n",
    "cfg: # (str, optional) for overriding defaults.yaml\n",
    "\n",
    "# Tracker settings ------------------------------------------------------------------------------------------------------\n",
    "tracker: botsort.yaml # (str) tracker type, choices=[botsort.yaml, bytetrack.yaml]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45679954",
   "metadata": {},
   "source": [
    "> DeepSORT Object Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c2d39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single Object Trackers:\n",
    "    # we only track a single object, no matter how many objects are present in the frame. e.g. CSRT, KCF, MOSSE, etc.\n",
    "\n",
    "# Multi Object Trackers:\n",
    "    # if there is more than one person in the frame, we track all of them separately. e.g. SORT, DeepSORT, JDE, CenterTrack etc.\n",
    "\n",
    "\n",
    "# Simple Online Realtime Tracking (SORT):\n",
    "    # SORT is a simple and real-time tracker for multiple objects. It is based on the idea of minimizing a cost function that consists of both the distance between the predicted object location and the new detection, and the size of the predicted object bounding box and the new detection.\n",
    "\n",
    "# https://github.com/nwojke/deep_sort   # clone DeepSORT repository\n",
    "# or use the one by computervisionengineer  https://github.com/computervisioneng/deep_sort \n",
    "\n",
    "##################################################################################\n",
    "# Create a custom tracker \"tracker.py\" file for the tracker settings  you want to use     #\n",
    "# You can copy and modify this template or create a new file from scratch        #\n",
    "##################################################################################\n",
    "\n",
    "from deep_sort.deep_sort.tracker import Tracker as DeepSortTracker\n",
    "from deep_sort.tools import generate_detections as gdet\n",
    "from deep_sort.deep_sort import nn_matching\n",
    "from deep_sort.deep_sort.detection import Detection\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class Tracker:\n",
    "    tracker = None\n",
    "    encoder = None\n",
    "    tracks = None\n",
    "\n",
    "    def __init__(self):\n",
    "        max_cosine_distance = 0.4\n",
    "        nn_budget = None\n",
    "\n",
    "        encoder_model_filename = 'model_data/mars-small128.pb'\n",
    "\n",
    "        metric = nn_matching.NearestNeighborDistanceMetric(\"cosine\", max_cosine_distance, nn_budget)\n",
    "        self.tracker = DeepSortTracker(metric)\n",
    "        self.encoder = gdet.create_box_encoder(encoder_model_filename, batch_size=1)\n",
    "\n",
    "    def update(self, frame, detections):\n",
    "\n",
    "        if len(detections) == 0:\n",
    "            self.tracker.predict()\n",
    "            self.tracker.update([])  \n",
    "            self.update_tracks()\n",
    "            return\n",
    "\n",
    "        bboxes = np.asarray([d[:-1] for d in detections])\n",
    "        bboxes[:, 2:] = bboxes[:, 2:] - bboxes[:, 0:2]\n",
    "        scores = [d[-1] for d in detections]\n",
    "\n",
    "        features = self.encoder(frame, bboxes)\n",
    "\n",
    "        dets = []\n",
    "        for bbox_id, bbox in enumerate(bboxes):\n",
    "            dets.append(Detection(bbox, scores[bbox_id], features[bbox_id]))\n",
    "\n",
    "        self.tracker.predict()\n",
    "        self.tracker.update(dets)\n",
    "        self.update_tracks()\n",
    "\n",
    "    def update_tracks(self):\n",
    "        tracks = []\n",
    "        for track in self.tracker.tracks:\n",
    "            if not track.is_confirmed() or track.time_since_update > 1:\n",
    "                continue\n",
    "            bbox = track.to_tlbr()\n",
    "\n",
    "            id = track.track_id\n",
    "\n",
    "            tracks.append(Track(id, bbox))\n",
    "\n",
    "        self.tracks = tracks\n",
    "\n",
    "\n",
    "class Track:\n",
    "    track_id = None\n",
    "    bbox = None\n",
    "\n",
    "    def __init__(self, id, bbox):\n",
    "        self.track_id = id\n",
    "        self.bbox = bbox\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "########################################################################################\n",
    "# You can then use the custom tracker in the YOLO model by setting the tracker argument # to an instance of your own Tracker class.###############################################\n",
    "########################################################################################\n",
    "#                              EVALUATION CODE                                          #\n",
    "########################################################################################\n",
    "    \n",
    "# Example usage:\n",
    "from tracker import Tracker\n",
    "import cv2\n",
    "\n",
    "def main():\n",
    "    # Create a tracker instance\n",
    "    tracker = Tracker()\n",
    "\n",
    "    colors = [(random.randint(0, 255), random.randint(0, 255), random.randint(0, 255)) for j in range(10)] # create a list of random colors for the bounding boxes\n",
    "    # Create an evaluator instance\n",
    "    # evaluator = TrackerEvaluator(tracker)           # create an instance of the TrackerEvaluator class (This is not important, only use the Tracker class)\n",
    "\n",
    "    # Load the video\n",
    "    cap = cv2.VideoCapture('video.mp4')\n",
    "\n",
    "    detection_threshold = 0.5\n",
    "    \n",
    "    # Loop through the video frames\n",
    "    while cap.isOpened():\n",
    "        # Read a frame from the video\n",
    "        success, frame = cap.read()\n",
    "\n",
    "        if success:\n",
    "            # Run object detection on the frame\n",
    "            results = model(frame)\n",
    "        \n",
    "            # Update the tracking system with the current\n",
    "            for result in results:\n",
    "                detections = []\n",
    "                for r in result.boxes.data.tolist():\n",
    "                    x1, y1, x2, y2, score, class_id = r\n",
    "                    x1 = int(x1)\n",
    "                    x2 = int(x2)\n",
    "                    y1 = int(y1)\n",
    "                    y2 = int(y2)\n",
    "                    class_id = int(class_id)\n",
    "                    if score > detection_threshold:\n",
    "                        detections.append([x1, y1, x2, y2, score])\n",
    "\n",
    "                tracker.update(frame, detections)\n",
    "\n",
    "                for track in tracker.tracks:\n",
    "                    bbox = track.bbox\n",
    "                    x1, y1, x2, y2 = bbox\n",
    "                    track_id = track.track_id\n",
    "\n",
    "                    cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (colors[track_id % len(colors)]), 3)\n",
    "\n",
    "            # Break the loop if 'q' is pressed\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "        else:\n",
    "            # Break the loop if the end of the video is reached\n",
    "            break\n",
    "\n",
    "    # Release the video capture object and close the display window\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d489a2",
   "metadata": {},
   "source": [
    "> Argparse Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de0345c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import sys \n",
    "\n",
    "parser = argparse.ArgumentParser(description='SORT demo')   # create a parser object to store the command line arguments\n",
    "parser.add_argument('--display', dest='display', help='Display online tracker output (slow) [False]', action='store_true')\n",
    "parser.add_argument('--task', type=str, choices=['detect', 'classify', 'segment', 'pose'], default='detect', help='Task to perform.')\n",
    "parser.add_argument(\"--seq_path\", help=\"Path to detections.\", required=False, type=str, default='data')\n",
    "args = parser.parse_args()  # parse the command line arguments and store them in the args object\n",
    "\n",
    "python main.py --display --task classify --seq_path /your/custom/seq_path\n",
    "\n",
    "\n",
    "# Here's a brief explanation of some of the common parameters:\n",
    "name or flags   # The name of the command-line argument (e.g., '--myoption'). For positional arguments, only the name is specified (e.g., 'myargument').\n",
    "action  # Defines the action to be taken when the argument is encountered. Some common values include:\n",
    "    'store' # Just stores the argument’s value (default action).\n",
    "    'store_true'/'store_false'  # Stores True/False when the argument is present/absent.\n",
    "    'append'    # Stores a list, appending each argument value to the list.\n",
    "    'count' # Counts the number of times a keyword argument occurs.\n",
    "nargs   # Indicates the number of command-line arguments that should be consumed. Can be an integer or special characters like '+', '*', or '?'.\n",
    "const   # A constant value required by some action and nargs selections.\n",
    "default # The value produced if the command-line argument is absent from the command line.\n",
    "type    # The type to which the command-line argument should be converted. This can be a Python type like int, float, str, or a function that takes a single string argument and returns the converted value.\n",
    "choices # A container of the allowable values for the argument. If the command-line argument is outside this container, the program will raise an error.\n",
    "required    # Whether or not the command-line option may be omitted (optionals only).\n",
    "help    # A brief description of what the argument does, which is displayed in the help message.\n",
    "metavar # A name for the argument in usage messages.\n",
    "dest    # The name of the attribute to be added to the object returned by parse_args(). By default, argparse derives the value from the command-line argument, removing the initial -- prefix and replacing - with _.\n",
    "\n",
    "\n",
    "# main.py file structure\n",
    "\n",
    "def parse_args():\n",
    "    \"\"\"Parse input arguments.\"\"\"\n",
    "    parser = argparse.ArgumentParser(description='Model training and inference script')\n",
    "    parser.add_argument('--display', dest='display', help='Display online tracker output (slow) [False]', action='store_true')\n",
    "    parser.add_argument(\"--seq_path\", help=\"Path to detections.\", type=str, default='data')\n",
    "    parser.add_argument('--task', type=str, choices=['detect', 'classify', 'segment', 'pose'], default='detect', help='Task to perform.')\n",
    "    parser.add_argument('--mode', type=str, choices=['train', 'test', 'predict'], default='train', help='Mode of operation.')\n",
    "    parser.add_argument('--data', type=str, required=True, help='Path to the data file.')\n",
    "    parser.add_argument(\"--iou_threshold\", help=\"Minimum IOU for match.\", type=float, default=0.3)\n",
    "    parser.add_argument(\"--epochs\", help=\"Number of training epochs.\", type=int, default=10)\n",
    "    args = parser.parse_args()\n",
    "    return args\n",
    "\n",
    "args = parse_args()\n",
    "# print(f\"Task: {args.task}\")\n",
    "# print(f\"Mode: {args.mode}\")\n",
    "# print(f\"Data Path: {args.data}\")\n",
    "# print(f\"IOU Threshold: {args.iou_threshold}\")\n",
    "# print(f\"Epochs: {args.epochs}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "\n",
    "# use this to run the script\n",
    "python main.py --task recognition --mode train --data \"path/to/data/file\" --epochs 25\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64892f41",
   "metadata": {},
   "source": [
    "> Neptune AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de93c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install neptune\n",
    "\n",
    "# Step 1: Sign Up and Create a project\n",
    "    # Go to the Neptune app,\n",
    "    # Sign up for an account if you haven’t already,\n",
    "    # Click on New project button on the left,\n",
    "    # Give it a name,\n",
    "    # Decide whether you want it to be public or private,\n",
    "    # Done.\n",
    "    \n",
    "# Step 2: Get your API token: You will need a Neptune API token (your personal key) to connect the scripts you run with Neptune.\n",
    "    # Click on your user logo on the right side of the screen,\n",
    "    # Click on Get Your API token ,\n",
    "    # Copy your API token,\n",
    "    # Paste it to the environment variable, config file, or directly to your script.\n",
    "\n",
    "# Step 3: Install Neptune client library:\n",
    "pip install neptune\n",
    "\n",
    "# Step 4: Initialize and Configuring Neptune Run\n",
    "import neptune\n",
    "run = neptune.init_run(\n",
    "  project=\"workspace/project-name\",\n",
    "  api_token=\"your-api-token\",\n",
    ")\n",
    "\n",
    "##################################################################\n",
    "# You can also register and track ML models\n",
    "##################################################################\n",
    "import neptune\n",
    "model = neptune.init_model(\n",
    "    name=\"Prediction model\",\n",
    "    key=\"MOD\", \n",
    "    project=\"gra-research/cytovance-research\", \n",
    "    api_token=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiIxMTM4MWQyYS00ZTgxLTQ5M2EtOTVkOC1mNGMyMjQxOTg0ZTAifQ==\", # your credentials\n",
    ")\n",
    "\n",
    "########################################################################################################\n",
    "# You can also store project level metadata like datasets, models, python notebooks, images etc.\n",
    "########################################################################################################\n",
    "import neptune\n",
    "project = neptune.init_project(project=\"gra-research/cytovance-research\", \n",
    "                               api_token=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiIxMTM4MWQyYS00ZTgxLTQ5M2EtOTVkOC1mNGMyMjQxOTg0ZTAifQ==\")\n",
    "\n",
    "project[\"general/brief\"] = URL_TO_PROJECT_BRIEF\n",
    "project[\"general/data_analysis\"].upload(\"data_analysis.ipynb\")\n",
    "project[\"dataset/v0.1\"].track_files(\"s3://datasets/images\")\n",
    "project[\"dataset/latest\"] = project[\"dataset/v0.1\"].fetch() # fetch the latest version of the dataset\n",
    "########################################################################################################\n",
    "\n",
    "\n",
    "# Logging Metadata to Neptune\n",
    "\n",
    "# Log Parameters\n",
    "params = {\n",
    "    \"activation\": \"ReLU\", \n",
    "    \"datasetRandomState\": randomState, \n",
    "    \"lr\": learningRate,\n",
    "    \"trainingEpochs\": trainingEpochs,\n",
    "    \"trainingBatchSize\": 128,\n",
    "    \"inputSize\": 224 * 224 * 3,\n",
    "    \"randomSeed\": randomState,\n",
    "    \"numberOfClasses\": 2,\n",
    "}\n",
    "run[\"model/parameters\"] = params\n",
    "\n",
    "\n",
    "# Log Metrics\n",
    "for epoch in num_epochs:\n",
    "    run[\"train/loss\"].append(epoch, loss)       \n",
    "    run[\"train/accuracy\"].log(epoch, accuracy)\n",
    "    run['training/accuracy'] = 0.95\n",
    "    run[\"sys/tags\"].add([\"colab\", \"simple\"]) # Adds tags or other categorical metadata to the experiment\n",
    "    run[\"validation/accuracy\"].log(epoch, accuracy)\n",
    "    # run[\"validation/accuracy\"].append(validationAccuracy) # appending the loss and accuracy values to the list 'metrics' under 'losses' and 'accuracy'.\n",
    "\n",
    "# track files\n",
    "run[\"data_versions/train\"].track_files(\"sample.csv\")\n",
    "\n",
    "# Log model architecture and summary \n",
    "from neptune.utils import stringify_unsupported\n",
    "run[\"model/model_summary\"] = model.summary()  # model.summary() is the summary of the model architecture\n",
    "run[\"model/archicture\"] = stringify_unsupported(model)\n",
    "run[\"model/checkpoints\"].upload('path/to/your_checkpoint.pth')\n",
    "\n",
    "# Log Images (e.g., heatmaps, images etc.)\n",
    "run[\"validation/heatmap\"].upload(heatmap)\n",
    "\n",
    "# Log text or just anything using the '=' operator\n",
    "run['summary'] = 'This experiment explores the effect of learning rate on accuracy.'\n",
    "run['training/accuracy'] = 0.95\n",
    "\n",
    "# Log Artifacts\n",
    "run[\"model/checkpoints\"].upload(\"path/to/your/model.pth\")\n",
    "run['visualizations'].upload('path/to/your_plot.png')\n",
    "\n",
    "# Log tags\n",
    "run[\"tags\"].add(\"experiment-1\", 'another_tag')\n",
    "\n",
    "# Log Dataframes or track files\n",
    "run['data/sample'].upload(neptune.types.File.as_html(your_dataframe))\n",
    "run[\"validation/metrics\"].upload('path/to/your_metrics.csv')\n",
    "run[\"data_versions/train\"].track_files(\"sample.csv\")\n",
    "\n",
    "# Querying and retriving data from Neptune\n",
    "metrics = run[\"validation/metrics\"].get()   # get the metrics from the run\n",
    "params = run['parameters'].fetch()          # Retrieve Logged Data:\n",
    "losses = run['train/loss'].fetch_values()   # Retrieve Logged Data:\n",
    "run['model/checkpoints'].download('destination/path/checkpoint.pth')    # Downloading Artifacts\n",
    "\n",
    "# Close the run when you are done with it to free up resources\n",
    "run.stop()\n",
    "\n",
    "# Download all runs as a pandas DataFrame\n",
    "project = neptune.init_project(\n",
    "    project=\"YOUR-WORKSPACE/tutorial\",\n",
    "    mode=\"read-only\",\n",
    "        )\n",
    "\n",
    "runs_table_df = project.fetch_runs_table().to_pandas()\n",
    "\n",
    "\n",
    "# helpful tips\n",
    "log     # Usage: run['some/metric'].log(value)\n",
    "        # Purpose: Logs a single data point for a given metric or parameter. It's commonly used inside training loops to log metrics \n",
    "        # like loss or accuracy at each iteration or epoch.\n",
    "    \n",
    "append  # Usage: run[\"train/loss\"].append(1, 0.5)  # Append data point (epoch 1, loss 0.5)\n",
    "        # Purpose: The append method is typically used when you want to track the progression of a metric or parameter over time. \n",
    "        # Each time you call append with new data, Neptune will store that data point along with its associated timestamp.\n",
    "\n",
    "add     # Usage: run['sys/tags'].add(['tag1', 'tag2'])\n",
    "        # Purpose: Adds tags or other categorical metadata to the experiment. Tags help in categorizing, filtering, and organizing \n",
    "        # experiments in Neptune.\n",
    "\n",
    "assign  # Usage: run['parameters'].assign({'lr': 0.01, 'batch_size': 32})\n",
    "        # Purpose: Assigns a dictionary of parameters to the experiment. Useful for logging hyperparameters and other parameters \n",
    "        # at the beginning of an experiment.\n",
    "                        \n",
    "fetch   # Usage: run['some/metric'].fetch() returns a pandas Series object containing all logged values for this metric.\n",
    "\n",
    "fetch_values # Usage: run['train/loss'].fetch_values()\n",
    "             # To retrieve all logged values for a metric. Returns a pandas Series object containing all logged values for this metric.\n",
    "             \n",
    "upload  # Usage: run['artifacts/my_model'].upload('path/to/model')\n",
    "        # Purpose: Uploads files or artifacts like model checkpoints, plots, or data files to Neptune. Useful for versioning and \n",
    "        # sharing artifacts.\n",
    "        \n",
    "download # Usage: run['artifacts/my_model'].download('destination/path')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "##################################################################################################\n",
    "\n",
    "# The project tab is for storing project-level metadata. It can be used to store datasets as artifacts,\n",
    "project = neptune.init_project(\n",
    "  name = \"your_project\",\n",
    "  api_token = \"your_api_token\"\n",
    ")\n",
    "\n",
    "# to store datasets or link to them\n",
    "project['general'] = {\n",
    "        'data_link':'link_to_data', \n",
    "    }\n",
    "# or \n",
    "project[\"datasets/raw\"].upload(\"path/to/your/dataset\")\n",
    "\n",
    "\n",
    "# to save models and create many versions of models\n",
    "model = neptune.init_model(\n",
    "    name=\"Prediction model\",\n",
    "    key=\"MOD\", \n",
    "    project=\"your_project\", \n",
    "    api_token=\"your_api_token\", # your credentials\n",
    ")\n",
    "\n",
    "# after the model is created, to create a version of the model\n",
    "model_version = neptune.init_model_version(\n",
    "        model = 'NEP-MOD',\n",
    "        project = 'your_project',\n",
    "        name = 'first',\n",
    "        api_token=\"your_api_token\",\n",
    ")\n",
    "\n",
    "model_version['model'].upload('model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab847088",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9901f74a",
   "metadata": {},
   "source": [
    "### Computer Vision Frameworks and Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88be2b9",
   "metadata": {},
   "source": [
    "| Framework/Tool | Description | Models/Applications | Common Usage | Performance | Data Format |\n",
    "|----------------|-------------|---------------------|--------------|-------------|-------------|\n",
    "| YOLO           | Real-time object detection system | Various versions (v1-v5) for improved accuracy and speed | Object detection in images/videos | High performance in real-time applications | Requires specific formatting for annotations, often in a separate `.txt` file for each image, and a `.yaml` file for dataset configuration |\n",
    "| Detectron2     | Facebook AI's library for object detection and segmentation | Models like Faster R-CNN, Mask R-CNN for detection and segmentation | Object detection, instance and panoptic segmentation | High accuracy, suitable for research and production | Uses JSON for annotations, often in COCO format, with details on bounding boxes, segmentation masks, etc. |\n",
    "| DeepSORT       | Tracking algorithm | Used in conjunction with detection models like YOLO for tracking objects | Object tracking in video sequences | Good for applications where object tracking over time is crucial | Depends on the detection model used for initial object identification |\n",
    "| TIMM           | PyTorch Image Models | A collection of SOTA deep learning models for image classification and more | Image classification, transfer learning | Offers a wide range of models with various performance levels | Standard image datasets in formats like ImageNet, with labels typically in `.txt` files or within dataset folders |\n",
    "| PaddleOCR      | PaddlePaddle's OCR tool | Lightweight models for text detection and recognition | Text detection and recognition in images | High accuracy with relatively fast inference | Images as input, annotations can vary but often include coordinates in `.txt` files or JSON format |\n",
    "| MediaPipe      | Framework for building multimodal applied ML pipelines | Face, hand, pose detection, holistic tracking | Real-time, interactive applications | Optimized for mobile and edge devices | Uses internal data formats, often processing raw video frames directly |\n",
    "| CVZone         | Simplified computer vision modules | Modules for face detection, color tracking, etc. | Rapid prototyping of CV applications | Designed for ease of use over cutting-edge performance | Works with standard image and video formats, annotations are not typically required |\n",
    "| Supervision (Roboflow) | Platform for creating and managing computer vision datasets | Provides tools for dataset creation, annotation, and preprocessing. Integrates with ML models for detection and segmentation. | Used for building, annotating, and exporting datasets for computer vision models. | Performance depends on the models and frameworks used. | Datasets are managed within the platform, with export options in various formats for compatibility with different models and frameworks. |\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a960dde1",
   "metadata": {},
   "source": [
    "| Task                                          | SOTA Models                                                   |\n",
    "|-----------------------------------------------|--------------------------------------------------------------|\n",
    "| Image Classification                         | EfficientNet, ViT (Vision Transformer), ResNet, DenseNet, RegNet |\n",
    "| Facial Recognition and Analysis               | ArcFace, FaceNet, VGGFace, DeepFace                           |\n",
    "| Optical Character Recognition (OCR)           | Tesseract OCR, Paddle OCR, Google Cloud Vision OCR, OCRopus, Rosoka |\n",
    "| Object Detection                              | YOLOvx, SSD, Faster R-CNN, Mask R-CNN, Detectron2                          |\n",
    "| Deep Segmentation                             | U-Net, SegNet, DeeplabV3, Mask R-CNN                           |\n",
    "| Segment Anything Model (SAM)                  | SAM                                                          |\n",
    "| Body Pose Estimation                          | OpenPose, HRNet, PoseNet                                      |\n",
    "| Tracking with DeepSORT                        | DeepSORT (Deep Simple Online and Realtime Tracking)          |\n",
    "| Deep Fakes                                    | DeepFakeDetection, XceptionNet, MesoNet                       |\n",
    "| Vision Transformers (VIT)                     | Vision Transformers (VIT)                                    |\n",
    "| Depth Estimation                              | Monodepth2, MiDaS, DeepDepth                                  |\n",
    "| Image Similarity using Metric learning         | SimCLR, Triplet Loss                                          |\n",
    "| Image Captioning                              | Show, Attend, and Tell (SAT), Transformer-based captioning models |\n",
    "| Video Classification (CNN+RNN, Transformers)  | CNN + RNN architectures, Transformer-based video models       |\n",
    "| Point Cloud Classification and Segmentation   | PointNet, PointNet++, KPConv                                  |\n",
    "| Neural Radiance Fields (NeRFs)                | NeRF, PlenOctrees                                             |\n",
    "| 3D Vision and Lidar                           | Volumetric CNNs, RangeNet++, SqueezeSegV2                      |\n",
    "| 3D Reconstruction and Scene Reconstruction    | MVSNet, COLMAP, Bundle Fusion                                 |\n",
    "|     --                                          |                                                               |\n",
    "|Frameworks                                     | Detectron2, YOLO, Pytorch, Opencv, cvzone, DeepSort, Supervision            |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655dc4b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9a47f414",
   "metadata": {},
   "source": [
    "### ML Deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba828607",
   "metadata": {},
   "source": [
    "> Gradio Tips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65bb0cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import joblib # for loading the model\n",
    "\n",
    "\n",
    "# Steps to create a Gradio App\n",
    "    # 1. Define the input and output components.\n",
    "    # 2. Load the model.\n",
    "    # 3. Define the function to make predictions.\n",
    "    # 4. Create the Gradio interface.\n",
    "    # 5. Launch the interface.\n",
    "\n",
    "\n",
    "# Components\n",
    "    # Input Components\n",
    "        gr.Textbox(lines=2, placeholder=\"Enter text here\", label=\"Your Text\")                                 # Text\n",
    "        gr.Number(label=\"Your Number\", default=0, step=1)                                                     # Number\n",
    "        gr.Slider(minimum=0, maximum=100, step=1, label=\"Your Slider\")                                        # Slider\n",
    "        gr.Checkbox(label=\"Check if True\", default=False)                                                     # Checkbox\n",
    "        gr.Radio(choices=[\"Option 1\", \"Option 2\"], label=\"Select One\", default=\"Option 1\")                    # Radio\n",
    "        gr.Dropdown(choices=[\"Option 1\", \"Option 2\"], label=\"Select One\", default=\"Option 1\")                 # Dropdown\n",
    "        gr.Image(tool=\"select\", shape=(224, 224), label=\"Upload Image\")                                       # Image\n",
    "        gr.File(label=\"Upload File\", type=[\".pdf\", \".docx\"])                                                  # File\n",
    "        gr.Dataframe(headers=[\"Column 1\", \"Column 2\"], value = [] ,datatype=[\"str\", \"number\"], label=\"Your Dataframe\")    # Dataframe\n",
    "        gr.Audio(label=\"Upload Audio\", type=\"file\", source=\"upload\")                                          # Audio\n",
    "        gr.Video(label=\"Upload Video\")                                                                        # Video\n",
    "        gr.Series(gr.Number(), label=\"Number Series\")                                                         # Series: for inputting a series of numbers.\n",
    "        \n",
    "    # Output Components\n",
    "        gr.Label(label=\"Output Label\")   # Label\n",
    "        gr.Textbox(label=\"Output Text\")   # Text\n",
    "        gr.Image(label=\"Output Image\")   # Image\n",
    "        gr.Plot(label=\"Output Plot\")  # Plot\n",
    "        gr.Dataframe(label=\"Output Dataframe\")   # Dataframe\n",
    "        gr.Audio(label=\"Output Audio\")   # Audio\n",
    "        gr.Video(label=\"Output Video\")   # Video\n",
    "        gr.JSON(label=\"Output JSON\")  # JSON\n",
    "\n",
    "# setting the input and output variables\n",
    "input1 = gr.Textbox(label=\"Input 1\")\n",
    "input2 = gr.Dropdown(choices=[\"Male\", \"Female\"], label='Gender')\n",
    "output = gr.Number(label=\"Prediction\")\n",
    "\n",
    "# Interface Functions\n",
    "model = joblib.load('file path of model')  # Load your model here\n",
    "\n",
    "def predict(var1, var2, var3, var4, var5, var6, var7, var8):\n",
    "    inputs = [var1, var2, var3, var4, var5, var6, var7, var8] \n",
    "    prediction = model.predict([inputs])[0]  # Make prediction (adjust according to your model's prediction method)\n",
    "    \"\"\"Return the prediction (you might want to format or round the prediction)\"\"\"\n",
    "    return prediction  # Return the prediction (you might want to format or round the prediction)\n",
    "\n",
    "# Building the Interface\n",
    "interface = gr.Interface(\n",
    "    fn=predict,\n",
    "    inputs = [input1, input2],\n",
    "    outputs=output,\n",
    "    examples = [['example_1', data], ['example_2' data]]    # Example inputs to show in the interface\n",
    "    title=\"Model Prediction App\",\n",
    "    description=\"Enter the values for the 8 variables to get the numeric prediction from the model.\",\n",
    "    theme=\"abidlabs/pakistan\",  # You can choose from various themes like 'default', 'huggingface', 'dark', 'grass', 'peach', etc.\n",
    "                    # 'ParityError/LimeFace', 'abidlabs/pakistan', 'HaleyCH/HaleyCH_Theme', 'freddyaboulton/dracula_revamped'\n",
    "                    # https://huggingface.co/spaces/gradio/theme-gallery for more themes\n",
    "    css=\"\"\"\n",
    "        body { font-family: Arial, sans-serif; }\n",
    "        .gr-interface { max-width: 800px; margin: auto; }\n",
    "        .gr-title, .gr-description { text-align: center; }\n",
    "        .gr-inputs, .gr-output { border-radius: 10px; }\n",
    "        .gr-group { margin-bottom: 20px; }\n",
    "        .gr-output-label { margin-top: 20px; }\n",
    "    \"\"\",\n",
    "    live=True, # Set to False to disable live updates and use a submit button for triggering predictions,\n",
    "    share = True, # Share the interface on social media sites like Twitter and LinkedIn\n",
    ")\n",
    "\n",
    "# Starting the Server (blocking call)\n",
    "interface.launch(share=True, auth=(\"username\", \"password\"), # Share the interface and set authentication (auth is optional)\n",
    "                 debug = True,   # Set debug to True to see error messages in the console when things go wrong\n",
    "                 inline = False # Set inline to True to display the interface in the Jupyter notebook instead of opening a new browser window\n",
    "                 )        \n",
    "\n",
    "\n",
    "\n",
    "# Function Decorators\n",
    "@gr.update                                                                  # Dynamically update component values based on other inputs.\n",
    "@gr.capture                                                                 # Capture and log inputs and outputs for debugging.\n",
    "\n",
    "# Advanced Components\n",
    "gr.Series(gr.Number(), label=\"Number Series\")                               # Series: for inputting a series of numbers.\n",
    "gr.JSON(label=\"Your JSON\")                                                  # JSON: for complex data structures.\n",
    "gr.Plot(plot_type=\"matplotlib\")                                             # Interactive Plots: for interactive Matplotlib or Plotly plots.\n",
    "\n",
    "# State and Session Management\n",
    "gr.State()                                                                  # Stateful Components: to maintain state across interactions.\n",
    "gr.session_state                                                            # Session State: to store and manage session-specific data\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56985cd8",
   "metadata": {},
   "source": [
    "> Streamlit App Tips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f93f9e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "622723c6",
   "metadata": {},
   "source": [
    "> Flask App Tips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851709ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f3e5b188",
   "metadata": {},
   "source": [
    "> Amazon Sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2859f95a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fc2492d8",
   "metadata": {},
   "source": [
    "> Heroku"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a7e46b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c662fabb",
   "metadata": {},
   "source": [
    "### OU Supercomputer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c39e60",
   "metadata": {},
   "source": [
    "> Supercomputer intro with code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce972f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working with a Supercomputer\n",
    "\n",
    "# Accessing the Supercomputer\n",
    "    # Access is typically granted through SSH (Secure Shell), using a command like:\n",
    "        ssh username@schooner.oscer.ou.edu\n",
    "    # Windows users might need an SSH client like PuTTY or Git Bash to use SSH.\n",
    "\n",
    "# File Transfer\n",
    "    # Downloading files: Use the scp command to securely copy files from the supercomputer to your local machine.\n",
    "        scp username@dtn2.oscer.ou.edu:/path/to/remote/file /path/to/local/destination\n",
    "    # Uploading files: Reverse the scp command to upload files, or use Git to clone and pull your repository on the supercomputer.\n",
    "\n",
    "# Running Code\n",
    "    # Bash Scripts: You typically run code on a supercomputer by writing a bash script with a .sh extension that specifies the resources needed and the commands to execute.\n",
    "        #!/bin/bash\n",
    "        #SBATCH --job-name=test_job\n",
    "        #SBATCH --output=result.txt\n",
    "        #SBATCH --time=01:00:00\n",
    "        #SBATCH --ntasks=1\n",
    "        #SBATCH --mem=4GB\n",
    "\n",
    "        module load python3\n",
    "        python3 my_script.py\n",
    "    # Submit the job using:\n",
    "        sbatch your_script.sh.\n",
    "    # Slurm: Supercomputers often use Slurm for job scheduling. Slurm commands include \n",
    "        # sbatch to submit jobs, \n",
    "        # squeue to view job status, and \n",
    "        # scancel to cancel jobs.\n",
    "\n",
    "# Monitoring Jobs\n",
    "    # Use squeue to check job status and top or htop on the assigned node to monitor resource usage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b918880",
   "metadata": {},
   "source": [
    "> VScode on OSCER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607dffd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caution with VS Code on OSCER:\n",
    "    # Important: Do not use VS Code's Remote SSH feature to connect to Schooner, as it may consume a significant amount of RAM \n",
    "    # and potentially crash the login nodes.\n",
    "    \n",
    "\n",
    "# Setting Up VS Code for Supercomputing:\n",
    "    # Downloading VS Code\n",
    "    # Installing Remote Tunnels Extension: (Search for \"Remote - Tunnels\" and install the extension.)\n",
    "    # Creating a Github Account\n",
    "    # Logging into Schooner:\n",
    "        # Use SSH to log into Schooner. The command format is \n",
    "        ssh username@schooner.oscer.ou.edu\n",
    "    # Setting Up VS Code CLI on Schooner: Depending on the VS Code version, \n",
    "        # download the compatible CLI version using curl and extract it. You'll end up with an executable named \"code\".\n",
    "        curl -Lk 'URL' --output vscode_cli.tar.gz\n",
    "        tar -xf vscode_cli.tar.gz\n",
    "        rm vscode_cli.tar.gz\n",
    "    # Preparing VS Code Server Batch Script: Create a batch script to run VS Code Server on Schooner\n",
    "        #!/bin/bash\n",
    "        #SBATCH --partition=partition_name\n",
    "        #SBATCH --output=vscode_%J_stdout.txt\n",
    "        #SBATCH --error=vscode_%J_stderr.txt\n",
    "        #SBATCH --ntasks=1\n",
    "        #SBATCH --mem=2G\n",
    "        #SBATCH --time=1:00:00\n",
    "\n",
    "        module load Python/3.10.8-GCCcore-12.2.0\n",
    "        # Load other modules or activate environments as needed\n",
    "        $HOME/code tunnel --accept-server-license-terms --name=$HOSTNAME\n",
    "\n",
    "    # Submitting the Batch Job:\n",
    "        sbatch your_script_name.sbatch\n",
    "        tail -f vscode_jobID_stdout.txt # to monitor the job's output\n",
    "    # Monitoring Job Output: Use \n",
    "        tail -f job_output_file_name # to monitor the job's output\n",
    "    # Connecting to the Tunnel in VS Code:  In VS Code, use the command palette (Ctrl+Shift+P) to connect to the tunnel created by the job on Schooner.\n",
    "    # Camcel a batch job:\n",
    "        scancel job_ID\n",
    "\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe59642",
   "metadata": {},
   "source": [
    "> Helpful step-by-step guide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62665d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logging into Schooner:\n",
    "    # Using Bash: Open your terminal and log in to the supercomputer using SSH (Secure Shell). \n",
    "    # Replace your_username with your actual username on Schooner:\n",
    "    ssh your_username@schooner.oscer.ou.edu\n",
    "    # Enter Password: You'll be prompted to enter your password. Type it in to establish the connection.\n",
    "\n",
    "# Activating or Starting a Job:\n",
    "    # SLURM Job Scheduler: Schooner utilizes SLURM for job management. You'll interact with SLURM to submit, monitor, and manage your jobs.\n",
    "\n",
    "# Compress Your Project Directory (if you need to)\n",
    "    # tar -czvf project.tar.gz /path/to/your/project\n",
    "    # tar -czvf ChestXRay.tar.gz \"data/Chest XRay\"      #this compresses the Chest XRay dataset into the .tar.gz\n",
    "\n",
    "# Transferring Files:\n",
    "    # Use SCP (Secure Copy Protocol) to transfer files between your local machine and Schooner. Use Bash to run the command:\n",
    "    scp \"data/Chest XRay.zip\" obinopaul@schooner.oscer.ou.edu:~/Healthcare-Project/ \n",
    "    scp ChestXRay.tar.gz obinopaul@schooner.oscer.ou.edu:~/Healthcare-Project/\n",
    "\n",
    "\n",
    "# or Load only one Script:\n",
    "    # Transfer Script: Use scp (Secure Copy Protocol) to transfer your Python scripts or entire project directory from your local \n",
    "    # machine to Schooner.\n",
    "    scp your_script.py your_username@schooner.oscer.ou.edu:~/path_to_your_directory/\n",
    "\n",
    "# Decompress Your Project Directory once logged in: \n",
    "    ssh obinopaul@schooner.oscer.ou.edu\n",
    "    cd ~/Healthcare-Project\n",
    "    tar -xzvf ChestXRay.tar.gz\n",
    "\n",
    "    rm ChestXRay.tar.gz # remove the compressed file after decompressing it\n",
    "\n",
    "\n",
    "## If you are running multiple scripts, you can use the following command to run them in the background:\n",
    "    nohup python script1.py & nohup python script2.py & nohup python script3.py \n",
    "    \n",
    "# Set Up Your Environment\n",
    "    module load Python/3.11.3-GCCcore-12.3.0    # Load the Python environment\n",
    "    module load cuDNN/8.6.0.163-CUDA-11.8.0     # Load CUDA\n",
    "\n",
    "    source /home/obinopaul/Healthcare-Project/yolo/bin/activate # activate the YOLO environment\n",
    "\n",
    "# Running a Job:\n",
    "    # Prepare Job Script: Create a job script (your_job_script.sbatch) specifying resource requests and commands to run your script. \n",
    "    # Here's an example for a non-parallel job:\n",
    "    \n",
    "    #!/bin/bash\n",
    "    #SBATCH --partition=normal\n",
    "    #SBATCH --ntasks=1\n",
    "    #SBATCH --mem=10G\n",
    "    #SBATCH --time=01:00:00\n",
    "    #SBATCH --job-name=ml_job\n",
    "    #SBATCH --output=output_%j.txt\n",
    "\n",
    "    module load python3\n",
    "    source activate your_env\n",
    "    cd ~/desired_destination/project_name/\n",
    "    python main.py\n",
    "    \n",
    "    # Save this as run_project.sh and submit it:\n",
    "\n",
    "# Submit Job: Use sbatch to submit your job script to SLURM.\n",
    "    sbatch your_job_script.sbatch   # Submit batch jobs\n",
    "\n",
    "# Monitoring Jobs: Use squeue to check the status of your job. You can filter jobs by your username:\n",
    "    squeue -u your_username         # to check the status of your job(s) (add -t at the end to check all pending/running jobs)\n",
    "    tail -f job_output_file_name    # to monitor the job's output\n",
    "\n",
    "# Cancelling Jobs: If needed, cancel a job using scancel followed by the job ID.\n",
    "    scancel job_id\n",
    "    scancel <job number>                    # cancels the specified job\n",
    "    scancel -u <username>                   # cancels all jobs for the specified user\n",
    "    scancel -t PENDING -u <username>        # cancels all pending jobs for the specified user\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "###################### LOADING A MODULE ON SCHOONER ############################\n",
    "    \n",
    "    module avail    # This will list all the available modules on Schooner\n",
    "    module list         # This will list all the modules that are currently loaded in your environment\n",
    "    module load Python      # Load the default Python module\n",
    "    module load <application name>  # Load a specific module\n",
    "    module unload <application name>    # Unload a module from your environment\n",
    "    module purge                        # Unload all modules from your environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e454351",
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir -p ~/Healthcare-Project   #create a proejct directory \n",
    "module load Python/3.11.3-GCCcore-12.3.0    # set up your python environment\n",
    "python -m venv ~/Healthcare-Project/yolo # create a virtual environment\n",
    "source ~/Healthcare-Project/yolo/bin/activate   # activate the environment\n",
    "\n",
    "# Install cuda\n",
    "module avail cuda   # check the CUDA available \n",
    "module load cuDNN/8.6.0.163-CUDA-11.8.0\n",
    "module load CUDA/12.3.0\n",
    "\n",
    "\n",
    "# Install Libraries \n",
    "scp path/to/requirements.txt obinopaul@schooner.oscer.ou.edu:~/Healthcare-Project/  #transfer the requirements.txt file to the supercomputer\n",
    "pip install -r ~/Healthcare-Project/requirements.txt    # load the requiremennts.txt file\n",
    "\n",
    "# Transfer additional files from your PC to the Supercomputer \n",
    "scp ChestXRay.tar.gz obinopaul@schooner.oscer.ou.edu:~/Healthcare-Project/\n",
    "\n",
    "# Installing Pytorch\n",
    "\n",
    "pip install wheel   # For the latest pytorch built with CUDA 11.8, first, you need to install wheel package:\n",
    "pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118 #Then, according to the official pytorch installation instruction, type:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "########################### NOTE ############################\n",
    "deactivate  # deactivate a virtual environment\n",
    "rm -rf ~/Healthcare-Project/yolo    # delete a virtual environment\n",
    "du -h --max-depth=1 ~/Healthcare-Project/   # check the contents and size of a directory\n",
    "du -ah /home/obinopaul/Healthcare-Project/ | sort -rh | head -20    # or this \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e41911",
   "metadata": {},
   "source": [
    "> OnDemand App (An interactive app for OSCER SCHOONER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b52d75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open OnDemand provides a user-friendly web interface for accessing and managing jobs on OSCER's Schooner supercomputer. \n",
    "# Here's a concise guide to get started:\n",
    "\n",
    "\n",
    "# Logging into OSCER via Open OnDemand:\n",
    "    # Account Requirement: Ensure you have an OSCER account. If not, request one at the OSCER account request page.\n",
    "    # Accessing Open OnDemand: Navigate to the Open OnDemand portal at https://ondemand.oscer.ou.edu and log in using your OSCER credentials.\n",
    "\n",
    "# Basic Features of Open OnDemand:\n",
    "    # Dashboard: Upon logging in, you'll encounter the Dashboard, which gives you access to various functionalities through pulldown menus.\n",
    "\n",
    "# Key Functionalities:\n",
    "    # Files Menu: \n",
    "        # Access and manage your files directly through a File Explorer-like interface. You can upload, download, edit, move, or \n",
    "        # rename files between your local device and Schooner.\n",
    "    # Jobs Menu:\n",
    "        # Active Jobs: View the status of your queued, running, or recently completed jobs. You can see detailed information or \n",
    "            # sort jobs based on different criteria.\n",
    "        # Job Composer: Create, edit, and submit Slurm batch job scripts to run applications on Schooner. Templates for various job types \n",
    "            # and applications will be provided for easy editing.\n",
    "    # Clusters Menu: \n",
    "        # Currently featuring Schooner, this menu offers \"Schooner Shell Access\" for command-line interaction via Secure Shell \n",
    "        # within the web interface. It's crucial to avoid running compute- or data-intensive applications through this shell.\n",
    "    # Interactive Apps:\n",
    "        # GUIs: Launch interactive sessions with applications like MATLAB, VMD, and ANSYS Workbench. These sessions provide \n",
    "            # interactive front ends for the respective software.\n",
    "        # Servers: Initiate Jupyter Notebook sessions interactively. You'll need to set some job parameters before launching, \n",
    "            # which can be adjusted as per your requirement or left to default.\n",
    "    # My Interactive Sessions: Manage and interact with your active sessions initiated through the \"Interactive Apps\" menu.\n",
    "\n",
    "# Ending Your Session:\n",
    "    # Logging Out: Ensure to log out after completing your tasks to secure your session and free up resources.\n",
    "\n",
    "# Additional Notes:\n",
    "    # Open OnDemand is an evolving platform, and feedback or requests for additional features are encouraged. \n",
    "    # If you need more resources or have suggestions, contact OSCER support.\n",
    "    \n",
    "    # For comprehensive details, refer to the official SLURM documentation or use the man command on Schooner (e.g., man sbatch) \n",
    "    # to learn more about specific commands.\n",
    "    \n",
    "# This guide provides an overview of starting and managing your machine learning tasks on Schooner using Open OnDemand, emphasizing user-friendly access and management of computational jobs and resources."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b6e30715",
   "metadata": {},
   "source": [
    "### Data Analytics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0f8fa02d",
   "metadata": {},
   "source": [
    "#### Documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd06f218",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data Preprocessing\n",
    "    importing the required libraries\n",
    "    importing the dataset\n",
    "    handling missing data\n",
    "    encoding the categoical data\n",
    "    feature engineering\n",
    "    spliting the dataset into test set and training set\n",
    "    feature scaling \n",
    "    *webscraping with beautifulsoup\n",
    "    \n",
    "Machine Learning\n",
    "    Simple linear regression\n",
    "    multiple linear regression\n",
    "    logistic regression\n",
    "    K nearest neighbours\n",
    "    support vector machines\n",
    "    Naive Bayes Classifier\n",
    "    Decision trees\n",
    "    random forest\n",
    "    neural networks\n",
    "    k-means clustering\n",
    "    Hierarchical Clustering\n",
    "\n",
    "Deep Learning\n",
    "    \n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0a303da5",
   "metadata": {},
   "source": [
    "#### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b460abc",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from pyforest import * #automatically imports all the necessary libraries for data science/analytics\n",
    "\n",
    "# Data Analysis\n",
    "import pandas as pd          # data analysis library for handling structured data\n",
    "from typing import List\n",
    "from pandas import DataFrame \n",
    "import numpy as np           # mathematical library for working with numerical data\n",
    "from pandas.plotting import parallel_coordinates \n",
    "from pivottablejs import pivot_ui\n",
    "import statsmodels.api as sm # library for performing statistical analysis\n",
    "import scipy.stats as stats\n",
    "import pandas_profiling\n",
    "\n",
    "\n",
    "import os       # import the os module for accessing operating system functionalities\n",
    "import sqlite3  # import the sqlite3 module for working with SQLite databases\n",
    "import math     # import the math module for mathematical operations and functions\n",
    "from collections import Counter  # import the Counter class from the collections module for counting items in an iterable\n",
    "from pathlib import Path  # import the Path class from the pathlib module for working with file paths and directories\n",
    "from tqdm import tqdm  # import the tqdm module for displaying progress bars during loops and iterations\n",
    "\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt     # data visualization library for creating graphs and charts\n",
    "%matplotlib inline\n",
    "import seaborn as sns        # data visualization library based on matplotlib for creating more attractive visualizations\n",
    "import plotly\n",
    "import plotly.io as pio\n",
    "import plotly.express as px   # interactive data visualization library\n",
    "import plotly.graph_objects as go   # library for creating interactive graphs and charts\n",
    "from plotly.subplots import make_subplots\n",
    "import missingno as msno \n",
    "import kaleido \n",
    "\n",
    "# Machine Learning \n",
    "from scipy.stats import skew, norm\n",
    "import yellowbrick\n",
    "import sklearn # machine learning library containing many algorithms for building models\n",
    "from sklearn.decomposition import PCA \n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.manifold import TSNE \n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score, classification_report \n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") \n",
    "\n",
    "pd.set_option('display.max_rows', 15)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5bb1e655",
   "metadata": {},
   "source": [
    "#### Preprocessing Structured Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e8446dd7",
   "metadata": {},
   "source": [
    "##### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f69cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('fileName.csv', sheet_name = \"Sheet 1\", parse_dates=True, columns=['product', 'price'], skiprows = [2], header = None,  )\n",
    "pd.read_html(\"https://developers.turing.com/dashboard/turing_test\")\n",
    "pd.read_excel\n",
    "pd.read_spss\n",
    "import pyreadstat\n",
    "pyreadstat.read_spss(\"filename.sav\", ) \n",
    "1. # parse_dates=True or [\"Date\", \"DOB\"] - if you want dates to be recognized as dates, add this argument:\n",
    "    #infer_datetime_format = True (used for only csv and others, but not excel)\n",
    "2. #columns=['product', 'price'] - if you want to include the names of the columns\n",
    "3. #sheet_name = \"Sheet 1\" - to reat sheet 1 only. You could also just write \"Sheet 1\" instead of \"sheet_name\"\n",
    "4. #skiprows = [2] - if you want to skip three rows\n",
    "5. #usecols = [2, 5] - if you want to import only columns three and 6\n",
    "6. #header = None/1/2 - if there are no headers in the dataset (None), or use header 2\n",
    "7. #skip_blank_lines=True - Skip blank lines in the dataset. \n",
    "8. #names = [\"Age\", \"DOB\"] - names of the hearders assuming they were not provided\n",
    "9. #nrows = 2 - number of rows to import\n",
    "10 #na_values = [\"not available\", \"n.a\", -1] - identify n.a values and assign them as n.a\n",
    "   #na_values = {\"eps\" = [\"not available\", \"n.a\", -1],\n",
    "    #            \"DOB\" = [\"not available\", 0.5]\n",
    "11. #index_col = False/\"Date\" - False for no index column, or use any column of choice.\n",
    "12. #dtype = { \"DOB\" : float, - used to specify the datatype of the columns while reading the file. To change the datatype, use .astype function. \n",
    " #           \"Name\" : int}\n",
    "\n",
    "#Read from SQL Query\n",
    "from sqlalchemy import create_engine\n",
    "engine = create_engine('sqlite:///:memory:')\n",
    "pd.read_sql(\"SELECT * FROM my_table;\", engine)\n",
    "pd.read_sql_table('my_table', engine)\n",
    "pd.read_sql_query(\"SELECT * FROM my_table;\", engine)\n",
    "\n",
    "#import a .tsv file from a url\n",
    "chipo = pd.read_csv(\"https://raw.githubusercontent.com/justmarkham/DAT8/master/data/chipotle.tsv\", sep = '\\t')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3bcdffa4",
   "metadata": {},
   "source": [
    "##### Export Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef04b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel('dir/myDataFrame.xlsx',  sheet_name='Sheet2', index = False) #write to excel\n",
    "df.to_sql('myDf', engine) #write to sql\n",
    "\n",
    "with pd.ExcelWriter (\"courses.xlsx\") as writer: #writing to multiple sheets\n",
    "    df1.to_excel (writer, sheet_name = \"sheet_1\")\n",
    "    df2.to_excel (writer, sheet_name = \"sheet_2\")\n",
    "    \n",
    "with pd.ExcelWriter (\"courses.xlsx\", mode = \"a\") as writer: #writing to multiple sheets\n",
    "    df.to_excel (writer, sheet_name = \"sheet_1\") "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "61829839",
   "metadata": {},
   "source": [
    "##### DataFrame Manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ec3c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('max_colwidth',800) #column width\n",
    "pd.set_option(\"display.max_columns\",200) #Number of columns:\n",
    "bp_data.iloc[:, 1:10] #inner slicing\n",
    "bp_data.loc[:, \"Year\": \"Home Runs\"] #outer slicing \n",
    "df.iloc[np.r_[0:5, -5:0]] #selects the first 5 and last 5 rows. very important. \n",
    "numeric_cols = smart_home.select_dtypes(include=[\"float64\", \"int64\"]) # Select only numeric columns\n",
    "\n",
    "#duplicate detection\n",
    "df.groupby('item_name').item_name.nunique() #Find duplicates #count unique values of one column:\n",
    "pd.concat(i for _, i in df.groupby('my_user_id') if len(i) > 1)  #Find duplicates #Show duplicate values for one column:\n",
    "df = df.drop_duplicates(subset='my_user_id', keep=False)    #Remove duplicates\n",
    "df['n'].replace({'a': 'x', 'b': 'y', 'c': 'w', 'd': 'z'}) #replace the values in a column\n",
    "df['n'].rename(columns = ['a', 'b']) #rename columns\n",
    "df[df.duplicated(subset = \"patient_id\", keep = False)].sort_values(\"patient_id\")#A. To isolate duplicate values and view the results.\n",
    "repeat_patients = df.groupby(by = \"patient_id\").size().sort_values(ascending = False)#B Dsiplat all duplicate values in order\n",
    "\n",
    "#other basic data manipulation\n",
    "df = df.drop(['col1', 'col2'], axis=1)  #Drop one or more column(s): axis = 1 (column) or axis=0 (row)\n",
    "del df['COL1'] #remove columns\n",
    "df_train.rename(columns={\"trans_date_trans_time\":\"transaction_time\", \"cc_num\":\"credit_card_number\"},\n",
    "                inplace=True) #rename columns\n",
    "df.sort_values(by = ['COL1', 'COL2'], ascending = (0, 1)) # sorting\n",
    "df[(df['colCOL11'] >= 1) & (df['COL2'] <=1 )] #filter multiple conditions \"and\"\n",
    "df[(df['colCOL11'] >= 1) | (df['COL2'] <=1 )] #filter multiple conditions \"or\"\n",
    "df = pd.merge(df1, df2, how = 'left', left_on = ['my_user_id'], right_index = True) #combine dataframe\n",
    "df = pd.concat([df1, df2], axis = 0) #combine dataframe #concatenate\n",
    "df_train.credit_card_number = df_train.credit_card_number.astype('category') # Change dtypes\n",
    "df_train.credit_card_number = df_train.credit_card_number.astype('object') # Change dtypes (other dtypes = float64, int64)\n",
    "df.info() #check basic information of dataframe\n",
    "df.unique() #check unique variables of a dataframe\n",
    "df.describe() #describe basic details like count, mean, sd, percentile etc.\n",
    "np.round(df_train.describe(),2) #round up to the nearest 2 significant figures\n",
    "df.columns.value_counts().sum() or chipo.shape[1] #count number of columns in a dataset\n",
    "\n",
    "#check datatypes of features\n",
    "sns.set(style=\"ticks\", context=\"talk\",font_scale = 1)\n",
    "plt.style.use(\"dark_background\")\n",
    "plt.figure(figsize = (8,6))\n",
    "ax = df_train.dtypes.value_counts().plot(kind='bar',grid = False,fontsize=20,color='grey')\n",
    "for p in ax.patches:\n",
    "    height = p.get_height()\n",
    "    ax.text(p.get_x()+ p.get_width() / 2., height + 0.2, height, ha = 'center', size = 25)\n",
    "sns.despine()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "26ef4c5e",
   "metadata": {},
   "source": [
    "##### Data Wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a35aa1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#23 datascience techniques you should know (https://ai.plainenglish.io/23-data-science-techniques-you-should-know-61bc2c9d1b3a)\n",
    "\n",
    "#Data profiling - very usedul for statistical analysis\n",
    "import pandas_profiling\n",
    "df.profile_report() \n",
    "\n",
    "#Pivottables - Smart tables\n",
    "from pivottablejs import pivot_ui \t#for smart tables in Jupyter notebook\n",
    "pivot_ui(df)\n",
    "\n",
    "#or (use for google colab)\n",
    "from google.colab import data_table\t\t#for smart tables in Google Colab\n",
    "data_table.enable_datafrane_formatter()\n",
    "\n",
    "#filtering data\n",
    "weather_per_day = weather_data.resample('D') #filters out the daily data from a dataframe with time as index\n",
    "weather_per_month = weather_data.resample('M') #filters out monthly data from a dataframe with time as index\n",
    "weather_per_hour = weather_data.resample('H') #filters out hourly data from a dataframe with time as index\n",
    "weather_data = smart_home.filter(items=['temperature',\n",
    "                                      'humidity', 'visibility', ])    #filters out the following columns from the dataframe\n",
    "africa_deaths_cause = df_deaths_cause[df_deaths_cause[\"Code\"].isin(Africa[\"Three_Letter_Country_Code\"])]\n",
    "                                                                #filters the rows in df_deaths_cause for Africa['three_letter_country_code..']\n",
    "numeric_cols = smart_home.select_dtypes(include=[\"float64\", \"int64\"]) # Select only numeric columns\n",
    "\n",
    "\n",
    "\n",
    "#grouping variables in a dataset\n",
    "grouped = df.groupby(\"Year\", as_index=False, dropna=False) #as_index = True/False\n",
    "print(grouped.get_group(2010))\n",
    "    sales.groupby(\"store\", \"product_group\", as_index=False)[\"stock_qty\"].mean()  |  sales.groupby(\"store\")[[\"stock_qty\",\"price\"]].mean()  \n",
    "    sales.groupby(\"store\", as_index=False)[\"stock_qty\"].agg([\"mean\", \"max\", \"unique\"])\n",
    "    sales.groupby(\"store\", as_index=False)[\"last_week_sales\"].nlargest(2) #returns largest values for each column (or .nsmallest(4))\n",
    "    sales_sorted.groupby(\"store\", as_index=False).nth(4) #returns the nth value (or nth(-2) to return the second row from the end)\n",
    "    sales.groupby([\"store\",\"product_group\"], as_index=False).agg(avg_sales = (\"last_week_sales\", \"mean\"))    \n",
    "    sales.groupby(\"store\", as_index=False).agg(total_sales_in_thousands = (\"last_month_sales\", lambda x: round(x.sum() / 1000, 1))) #lambda function\n",
    "    daisy_pg1 = sales.groupby([\"store\", \"product_group\"], as_index=False).get_group((\"Daisy\",\"PG1\")) #multiple grouping, and getting multiple grouped output\n",
    "    sales.groupby(\"continent\").agg({\n",
    "                        \"sprit_servings\": \"mean\",\n",
    "                        \"beer_servings\": \"max\",\n",
    "                        \"wine_servings\": lambda x: x**3\n",
    "                        })\n",
    "\n",
    "#Multi-indexing\n",
    "        # if your indices are ['index1', 'index2'] and you want to select the row where index1 is 'value1' and index2 is 'value2', \n",
    "df.loc['value1']\n",
    "df.loc[('value1', 'value2')]\n",
    "df.loc['value1', 'column_label']\n",
    "df.xs('value2', level='index2') #cross-section method - very helpful\n",
    "df.loc[df.index.get_level_values('index2') == 'value2', ['col1', \"col2\"]]\n",
    "                                          \n",
    "#Merging                                                                           \n",
    "result = pd.merge(df1, df2, on='Product', how='inner')              \n",
    "result = pd.merge(df1, df2, on='Employee ID', how='left')\n",
    "result = pd.merge(df1, df2, on='Product', how='right')\n",
    "train = train.merge(riders, how = 'left', left_on='rider_id', right_on='Rider ID')\n",
    "test = test.merge(riders, how = 'left', left_on='rider_id', right_on='Rider ID')\n",
    "                                               \n",
    "If the column names in both DataFrames are the same, we can use the \"on\" parameter instead of \"left_on\" and \"right_on\".                                        \n",
    "\n",
    "\"left_on\"; \"right_on\":\n",
    "The resulting DataFrame result will contain only the rows where the values in the 'key1' column of df1 \n",
    "match the values in the 'key2' column of df2. In this case, the resulting DataFrame will contain two rows, \n",
    "where the values in the 'key1' column are 2 and 3.\n",
    "\n",
    "                                               \n",
    "\"left\": This performs a left join, \"keeping all the rows from the left\" (left_on) dataframe \n",
    "        and merging with the matching rows from the right (right_on) dataframe. \n",
    "        \"If there is no match, the result will have NaN values in the columns from the right dataframe\".\n",
    "\n",
    "\"right\": This performs a right join, \"keeping all the rows from the right\" (right_on) dataframe \n",
    "        and merging with the matching rows from the left (left_on) dataframe. \n",
    "        \"If there is no match, the result will have NaN values in the columns from the left dataframe\".\n",
    "\n",
    "\"outer\": This performs an outer join, \"keeping all the rows from both dataframes\". \n",
    "        If there is no match between the rows from the left and right dataframes, \n",
    "        \"the result will have NaN values in the columns from the non-matching dataframe\".\n",
    "\n",
    "\"inner\": This performs an inner join, \"keeping only the rows that have matching values\" \n",
    "        in both the left (left_on) and right (right_on) dataframes.                                 \n",
    "                                               \n",
    "                                               \n",
    "                                               \n",
    "#Pandas Apply and Map functions (use .apply() for multiple columns and .map() for single column)\n",
    "    df['colA'] = df['colA'].map(lambda x: x + 1)\n",
    "    df[['colA', 'colD']] = df[['colA', 'colD']].apply(lambda x: x + 1)\n",
    "    \n",
    "\n",
    "#Regular expression\n",
    "import re\n",
    "re.findall(pattern, text). #This function takes two arguments in the form of re.findall(pattern, string). \n",
    "              #Here, pattern represents the substring we want to find, and string represents the main string we want to find it in                               \n",
    "              #returns the matches as a list of strings or tuples    \n",
    "    match = re.findall(r\"From:.*\", fh)\n",
    "re.search(pattern, text) #matches the first instance of a pattern in a string, and returns it as a re match object.\n",
    "        match = re.search(r\"From:.*\", fh)\n",
    "re.split(pattern, text) \n",
    "        address = re.findall(r\"From:.*\", fh)\n",
    "        for item in address:\n",
    "            for line in re.findall(r\"\\w\\S*@.*\\w\", item):\n",
    "                username, domain_name = re.split(r\"@\", line)\n",
    "                print(\"{}, {}\".format(username, domain_name))\n",
    "re.sub(pattern, repl, text) #it substitutes parts of a string - this replaces the matched substring(s) with the ‘repl’ string.\n",
    "re.finditer(pattern, text) #returns the matches with extra functionality\n",
    "re.match(pattern, text) #returns the matches at the beginning of strings\n",
    "\n",
    "\n",
    "#get duplicated and non-duplicated values\n",
    "duplicated = df[df.duplicated(\"Roll_no\")]\n",
    "non_duplicated = df[~df.duplicated(\"Roll_no\")]\n",
    "\n",
    "transactions.rename(columns={'Quantity' :'Quant'}) #rename Column \"Quantity\" to \"Quant\"\n",
    "transactions.sort_values('TransactionID', ascending=False) #Sort rows by TransactionId decending\n",
    "transactions.sort_values(['Quantity','TransactionDate'],ascending=[True,False]) #Sort multiple rows\n",
    "transactions[pd.unique(['UserID'] + transactions.columns.values.tolist()).tolist()] # Make UserID the first column\n",
    "transactions[foo | (bar <0)] # Subset rows where foo is TRUE or bar is negative\n",
    "transactions[(transactions.Quantity >0) & (transactions.UserID == 2)] # Subset rows where Quantity > 1 and UserID = 2\n",
    "chipo.groupby([\"item_name\"]).max().sort_values(by=[\"quantity\"] , ascending= False) #group items and find the most sales\n",
    "\n",
    "#filter out (extract) data from a column in pandas (use regular expression)\n",
    "df['col1'] = df['original'].str.extract(r\"\\(([A-Za-z0-9 _]+)\\)\") #using regular expression (#The '.str.extract()' method extracts substrings from the Series that match a given regular expression.)\n",
    "emails_df[emails_df[\"sender_email\"].str.contains(\"epatra|spinfinder\")] #using regular expression\n",
    "df_most[\"price_float\"] = list(map((lambda x: (x[1:])), df_most[\"item_price\"])) #another method using lambda and map functions\n",
    "df[\"FName\"] = [i.split(\" \")[0].split(\",\")[-1].strip() for i in first_name] #to extract features from a dataset\n",
    "\n",
    "\n",
    "\n",
    "#How to add an empty column to DataFrame\n",
    "df[\"Blank_Column\"] = \" \"\n",
    "df[\"NaN_Column\"] = np.nan\n",
    "df[\"None_Column\"] = None\n",
    "df2 = df.assign(Blank_Column=\" \", NaN_Column = np.nan, None_Column=None) # Add an empty columns using the assign() method\n",
    "df2 = df.reindex(columns = df.columns.tolist() + [\"None_Column\", \"None_Column_2\"]) # Add multiple columns with NaN , uses columns param\n",
    "df2 = df.reindex(df.columns.tolist() + [\"None_Column\", \"None_Column_2\"],axis=1) # Add multiple columns with NaN, , uses axis param \n",
    "df2 = df.reindex(columns=[\"None_Column\", \"None_Column_2\"]+df.columns.tolist()) # Add multiple columns to the Beginning\n",
    "df2 = df.reindex(columns=[\"Courses\",\"None_Column\", \"None_Column_2\",\"Fee\"]) # Add multiple columns with NaN, , uses axis param \n",
    "df.insert(0,\"Blank_Column\", \" \") # Using insert(), add empty column at first position\n",
    "df[\"Blank_Column\"] = df.apply(lambda _: ' ', axis=1) # Using apply() & lambda function\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "38f66320",
   "metadata": {},
   "source": [
    "##### Speed up EDA in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2b0716",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas_profiling import ProfileReport\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv('my_data.csv')\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "#Pandas Profiling\n",
    "    \"\"\"a library for creating comprehensive reports on dataframes\n",
    "    \"\"\"\n",
    "from pandas_profiling import ProfileReport    \n",
    "profile = ProfileReport(df) # Create the report\n",
    "profile.to_file('my_data_report.html') # Save the report\n",
    "\n",
    "#SweetViz\n",
    "    \"\"\"a library for comparing datasets and generating report on the comparison\n",
    "    \"\"\"\n",
    "import sweetviz as sv\n",
    "my_report = sv.compare([train, 'Train'], [test, 'Test'], 'Survived') # Create the report\n",
    "my_report.show_html('my_report.html') # Save the report\n",
    "\n",
    "#AutoViz\n",
    "    \"\"\"a tool that automatically generates visualizations for a given dataset\n",
    "    \"\"\"\n",
    "from autoviz.AutoViz_Class import AutoViz_Class\n",
    "# Create the visualizations\n",
    "AV = AutoViz_Class()\n",
    "viz = AV.AutoViz('my_data.csv')\n",
    "viz.view_plots()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1174649d",
   "metadata": {},
   "source": [
    "##### WebScraping with ChatGPT Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc11d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use beta.openai.com/playground\n",
    "\n",
    "BeautifulSoup Prompts\n",
    "#Scrape this website: https://stackoverflow.com/questions/ with Python and BeautifulSoup\n",
    "#Locate the element with tag \"aa\" and class \"asa\". Scrape all the \"a\" elements inside.\n",
    "#Get the text attribute and print it.\n",
    "\n",
    "Selenium Prompts\n",
    "#Scrape this website: https://stackoverflow.com/questions/ with Python, Selenium and Chromedriver\n",
    "#Maximize the window, wait 5 seconds and locate all the elements with following xpath: \"span\" tag, \"class\" attribute name, and \"dsd\" attribute value\n",
    "#Get the text attribute and print them. \n",
    "\n",
    "NB:\n",
    "    tag --> attribute\n",
    "    wait 5 seconds or 15 seconds\n",
    "\n",
    "\n",
    "\n",
    "#Interate ChatGPT with python, and ineract on the command line.\n",
    "To run the code below on Windows, follow these steps:\n",
    "\n",
    "1. Open a text editor and paste the modified code into a new file.\n",
    "2. Save the file with the name HeyChatGPT.py in a directory of your choice.\n",
    "3. Open a command prompt or PowerShell window and navigate to the directory \n",
    "    where the HeyChatGPT.py file is located.\n",
    "4. Type set api_key=xxxxxxxxxx to set the value of the api_key environment variable \n",
    "    to your OpenAI API key. Replace xxxxxxxxxx with your actual API key.\n",
    "    #api_key=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 (my api_key)\n",
    "5. Type python HeyChatGPT.py \"How to reach Mars?\" to run the HeyChatGPT.py script and generate \n",
    "    a response to the prompt \"How to reach Mars?\". Replace the prompt text with any other \n",
    "    prompt you want to generate a response to.\n",
    "\n",
    "\n",
    "#!/usr/bin/env python3\n",
    "\n",
    "# Import openai, os, and sys modules\n",
    "import openai\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Set the prompt to the first command-line argument\n",
    "prompt = sys.argv[1]\n",
    "\n",
    "# Set the OpenAI API key to the value of the 'api_key' environment variable\n",
    "openai.api_key = os.environ['api_key']\n",
    "\n",
    "# Call the OpenAI API to generate a response to the prompt\n",
    "completions = openai.Completion.create(\n",
    "    engine=\"text-davinci-003\",\n",
    "    prompt=prompt,\n",
    "    max_tokens=1024,\n",
    "    n=1,\n",
    "    stop=None,\n",
    "    temperature=0.5,\n",
    ")\n",
    "\n",
    "# Extract the generated text from the API response\n",
    "message = completions.choices[0].text\n",
    "\n",
    "# Print the generated text to the console\n",
    "print(message)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "56dbd2a9",
   "metadata": {},
   "source": [
    "##### WebScraping - BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f899b22f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (3920982088.py, line 77)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[1], line 77\u001b[1;36m\u001b[0m\n\u001b[1;33m    for item1, item2, item3 in zip(company_name, skills, published_date) # Write the scraped data to the CSV file\u001b[0m\n\u001b[1;37m                                                                         ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import csv \n",
    "\n",
    "html_text = requests.get(\"https://www.sofascore.com/tournament/basketball/usa/nba/132\").text\n",
    "soup = BeautifulSoup(html_text, \"lxml\") #create an instance of beautifulsoup\n",
    "jobs = soup.find_all(\"li\", class_ = \"clearfix job-bx wh-shd-bx\" ) #\"li\" = tag, class = \"clearfix ....\" #Main tag\n",
    "#or\n",
    "jobs = soup.find(name = 'table', attrs = {'id' : 'per_game'}) # BeautifulSoup's .find() method searches for a tag and specified attributes, \n",
    "#or\n",
    "jobs = soup.find_all('tbody', {'class': 'Crom_body__UYOcU'})\n",
    "\n",
    "#having searched the main tag \"li\", next step would be to search and extract some particular information of choice\n",
    "# Creating a list of dictionaries to then convert into a Pandas Dataframe\n",
    "wiz_stats = []\n",
    "for row in wiz_per_game.find_all('tr')[1:]:  # Excluding the first 'tr', since that's the table's title head\n",
    "\n",
    "    player = {}\n",
    "    player['Name'] = row.find('a').text.strip()\n",
    "    player['Age'] = row.find('td', {'data-stat' : 'age'}).text\n",
    "    player['Min PG'] = row.find('td', {'data-stat' : 'mp_per_g'}).text\n",
    "    player['Field Goal %'] = row.find('td', {'data-stat' : 'fg_pct'}).text\n",
    "    player['Rebounds PG'] = row.find('td', {'data-stat' : 'trb_per_g'}).text\n",
    "    player['Assists PG'] = row.find('td', {'data-stat' : 'ast_per_g'}).text\n",
    "    player['Steals PG'] = row.find('td', {'data-stat' : 'stl_per_g'}).text\n",
    "    player['Blocks PG'] = row.find('td', {'data-stat' : 'blk_per_g'}).text\n",
    "    player['Turnovers PG'] = row.find('td', {'data-stat' : 'tov_per_g'}).text\n",
    "    player['Points PG'] = row.find('td', {'data-stat' : 'pts_per_g'}).text\n",
    "    wiz_stats.append(player)\n",
    "\n",
    "pd.DataFrame(wiz_stats)\n",
    "\n",
    "\n",
    "#OR\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "#specify the url\n",
    "url = 'https://www.nba.com/stats/alltime-leaders'\n",
    "\n",
    "#query the website and return the html to the variable 'page'\n",
    "page = requests.get(url)\n",
    "\n",
    "#parse the html using beautiful soup and store in variable 'soup'\n",
    "soup = BeautifulSoup(page.text, 'html.parser') #or use lxml to parse\n",
    "\n",
    "#find all elements with class \"Block_blockContent__6iJ_n\"\n",
    "divs = soup.find_all('tbody', {'class': 'Crom_body__UYOcU'})\n",
    "\n",
    "#loop through the elements and print the text inside\n",
    "for div in divs:\n",
    "    print(div.text)\n",
    "    \n",
    "    \n",
    "\n",
    "#A better way to write it\n",
    "html_text = requests.get(\"https://www.sofascore.com/tournament/basketball/usa/nba/132\").text\n",
    "soup = BeautifulSoup(html_text, \"lxml\") #create an instance of beautifulsoup\n",
    "jobs = soup.find_all(\"li\", class_ = \"clearfix job-bx wh-shd-bx\" ) #\"li\" = tag, class = \"clearfix ....\"\n",
    "\n",
    "#having searched the main tag \"li\", next step would be to search and extract some particular information of choice\n",
    "#some particular information include \"company name\", \"skills\", and whether the job was posted recently\n",
    "#\".find\" - would extract a single instance. \".find_all\" would extract all instances\n",
    "for job in enumerate(jobs): #you can remove the enumerate\n",
    "    published_date = job.find(\"span\", class_ = \"sim-posted\").text \n",
    "    if date in published_date: \n",
    "        company_name = job.find(\"h3\", class_ = \"job_list-comp\").text #add .replace(\" \", \"\") to remove whitespaces\n",
    "        skills = job.find(\"span\", class_ = \"srp-skills\").text #add .replace(\" \", \"\") to remove whitespaces\n",
    "        more_info = job.header.h2.a['href'] #used to extract the link for additional info.\n",
    "                                            #header is the first tag, h2 is second. \"a\" is the third indicating a link\n",
    "                                            #\"href\" is not a tag but a class name where the link is at.\n",
    "        \n",
    "#         print(f\"Company Name: {company_name.strip()} \\n\") #you can decide not to use \".strip() function\"\n",
    "#         print(f\"Skills: {skills.strip()} \\n\") \n",
    "#         print(f\"Date Posted: {published_date} \\n\")\n",
    "#         print (\" \") \n",
    "        \n",
    "#         with open('data.csv', 'w', newline='') as csv_file: #open a new csv file in write mode\n",
    "#             writer = csv.writer(csv_file) #create an instance of csv\n",
    "#             writer.writerow([\"Company Name\", \"Skills\", \"Date Posted\"])\n",
    "#             for item1, item2, item3 in zip(company_name, skills, published_date) # Write the scraped data to the CSV file\n",
    "#                 writer.writerow([item1, item2, item3])\n",
    "#             csv_file.close()\n",
    "\n",
    "with open('data.csv', 'w', newline='') as csv_file: #open a new csv file in write mode\n",
    "        writer = csv.writer(csv_file) #create an instance of csv\n",
    "        writer.writerow([\"Company Name\", \"Skills\", \"Date Posted\"])\n",
    "        for item1, item2, item3 in zip(company_name, skills, published_date) # Write the scraped data to the CSV file\n",
    "            writer.writerow([item1, item2, item3])\n",
    "csv_file.close() # Close the CSV file\n",
    "print(f\"Scraped data saved in {csv_file_name}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4fc8136f",
   "metadata": {},
   "source": [
    "##### WebScraping with Selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2416a1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bacff3c2",
   "metadata": {},
   "source": [
    "##### Git and Github Commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9c5da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting & Creating Projects\n",
    "git init #Initialize a local Git repository\n",
    "git clone ssh://git@github.com/[username]/[repository-name].git #Create a local copy of a remote repository\n",
    "\n",
    "#Basic Snapshotting\n",
    "git status #Check status\n",
    "git add [file-name.txt] #Add a file to the staging area\n",
    "git add -A #Add all new and changed files to the staging area\n",
    "git commit -m \"[commit message]\" #Commit changes\n",
    "git rm -r [file-name.txt] #Remove a file (or folder)\n",
    "\n",
    "#Branching & Merging\n",
    "git branch #List branches (the asterisk denotes the current branch)\n",
    "git branch -a #List all branches (local and remote)\n",
    "git branch [branch name] #Create a new branch\n",
    "git branch -d [branch name] #Delete a branch\n",
    "git push origin --delete [branch name] #Delete a remote branch\n",
    "git checkout -b [branch name] #Create a new branch and switch to it\n",
    "git checkout -b [branch name] origin/[branch name] #Clone a remote branch and switch to it\n",
    "git branch -m [old branch name] [new branch name] #Rename a local branch\n",
    "git checkout [branch name] #Switch to a branch\n",
    "git checkout - #Switch to the branch last checked out\n",
    "git checkout -- [file-name.txt] #Discard changes to a file\n",
    "git merge [branch name] #Merge a branch into the active branch\n",
    "git merge [source branch] [target branch] #Merge a branch into a target branch\n",
    "git stash #Stash changes in a dirty working directory\n",
    "git stash clear #Remove all stashed entries\n",
    "\n",
    "#Sharing & Updating Projects\n",
    "git push origin [branch name] #Push a branch to your remote repository\n",
    "git push -u origin [branch name] #Push changes to remote repository (and remember the branch)\n",
    "git push #Push changes to remote repository (remembered branch)\n",
    "git push origin --delete [branch name] #Delete a remote branch\n",
    "git pull #Update local repository to the newest commit\n",
    "git pull origin [branch name] #Pull changes from remote repository\n",
    "git remote add origin ssh://git@github.com/[username]/[repository-name].git #Add a remote repository\n",
    "git remote set-url origin ssh://git@github.com/[username]/[repository-name].git \n",
    "                                            #Set a repository's origin branch to SSH\n",
    "    \n",
    "#Inspection & Comparison\n",
    "git log #View changes\n",
    "git log --summary #View changes (detailed)\n",
    "git log --oneline #View changes (briefly)\n",
    "git diff [source branch] [target branch] #Preview changes before merging   \n",
    "\n",
    "#Git LFS \n",
    "cd my-sample-project\n",
    "git lfs install                       # initialize the Git LFS project\n",
    "git lfs track \"*.csv\"                 # select the file extensions that you want to treat as large files\n",
    "git add .                             # add the large file to the project (make sure that .gitattributes is tracked \"git add .gitattributes\")\n",
    "git commit -am \"Added Debian iso\"     # commit the file meta data\n",
    "git push origin main                  # sync the git repo and large file to the GitLab server\n",
    "\n",
    "#fast way to do it \n",
    "navigate to the directory\n",
    "run this \"git config --global core.autocrlf input\"\n",
    "then copy and paste the code from Github. shown below: \n",
    "    echo \"# Tackling-the-Health-Crises-in-Africa\" >> README.md\n",
    "    git init\n",
    "    git add README.md\n",
    "    git commit -m \"first commit\"\n",
    "    git branch -M main\n",
    "    git remote add origin https://github.com/obinopaul/Tackling-the-Health-Crises-in-Africa.git\n",
    "    git push -u origin main\n",
    "\n",
    "#or  \n",
    "#Creating a repository and pushing files\n",
    "Open the command line on your local machine.\n",
    "Navigate to the local directory where your code files are located.\n",
    "Initialize a new git repository by running the command \"git init\".\n",
    "Add your code files to the repository by running the command \"git add .\". (use git add . to add all files in the directory)\n",
    "    If a warning tells you that your files will be replaced by CRLF the newxt time git touchs it. use git \"config --global core.autocrlf input\"\n",
    "    use this \"git\"\n",
    "Commit your changes by running the command \"git commit -m 'Initial commit'\".\n",
    "create the main branch \"git branch -M main\"\n",
    "Connect your local repository to the remote repository by running the command \"git remote add origin https://github.com/[username]/[repository_name].git\"\n",
    "Push your code to the remote repository by running the command \"git push -u origin main\" \n",
    "You will be prompted to enter your Github username and password. \n",
    "Once the files are pushed, they should now appear on your Github repository.\n",
    "\n",
    "\n",
    "git status  #To check if a folder contains an existing Git repository\n",
    "Remove-Item -Recurse -Force -Path \".git\"    #remove the Git repository\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "406ef646",
   "metadata": {},
   "source": [
    "##### README (MarkDown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25fd07e7",
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "Here are some of the most common and useful markdown syntax to beautify your README file on GitHub:\n",
    "\n",
    "Headings: Use # to denote headings, with one # for the largest heading and six # for the smallest.\n",
    "Lists: Use - or * to create unordered lists, and 1. to create ordered lists.\n",
    "Bold & Italic: Use **bold text** or __bold text__ for bold and *italic text* or _italic text_ for italic.\n",
    "Code blocks: Use ``` to create code blocks, for example:\n",
    "        ```bash \n",
    "        ```\n",
    "        #or\n",
    "        ```python \n",
    "        ```\n",
    "        #or just ```\n",
    "Links: Use [Link text](URL) to create clickable links.\n",
    "Images: Use ![Alt text](image URL) to add images to your README.\n",
    "    #or use the code below to center the image \n",
    "    <p align=\"center\">\n",
    "        <img src=\"image_url\" alt=\"Alt text\" width=\"500\" height=\"300\">\n",
    "    </p>\n",
    "\n",
    "Tables: You can create tables using the following syntax:\n",
    "        | Column 1 | Column 2 |\n",
    "        |----------|----------|\n",
    "        | Row 1, Column 1 | Row 1, Column 2 |\n",
    "        | Row 2, Column 1 | Row 2, Column 2 |\n",
    "Emoji: You can add emoji to your README by using the colon symbol (:) followed by the name of the emoji. \n",
    "    For example, :smile: will show a smiling face emoji.\n",
    "Task lists: You can create a list of tasks that can be checked off using the following syntax:\n",
    "    - [x] Task 1\n",
    "    - [ ] Task 2\n",
    "Blockquotes: You can add quotes or highlight important text by using the > symbol\n",
    "    > Quote or highlighted text\n",
    "Horizontal lines: To separate sections in your README, you can use the following syntax:\n",
    "    ---\n",
    "Strikethrough: To strike through text, use the following syntax:\n",
    "    ~~Strikethrough text~~"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0e13bd6d",
   "metadata": {},
   "source": [
    "##### Requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e3f34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip freeze | findstr /i pandas >> requirements.txt #copy all the libraries one by one. It is case insensitive.\n",
    "\n",
    "#another way to do it\n",
    "Open a terminal or command prompt.\n",
    "Activate your virtual environment: Run the following command:\n",
    "        conda activate myenv\n",
    "Install the packages you need for your project: Run the following command for each package that your project requires:\n",
    "        pip install package_name\n",
    "Freeze the packages and versions: Run the following command:\n",
    "        pip freeze > requirements.txt\n",
    "Deactivate the virtual environment: Run the following command:\n",
    "        conda deactivate\n",
    "        conda deactivate envy #or\n",
    "        CALL conda.bat deactivate #or\n",
    "\n",
    "#Creating a new environment \n",
    "\tconda env export > environment.yml      (from a previous environment)\n",
    "\tconda env create -f environment.yml --name myenv\t(conda env create -f /path/to/environment.yml --name myenv)\n",
    "\tconda activate <environment_name>\n",
    "        conda env export > environment.yml (do this to export the environment after completing the project)\n",
    "\t#OR \t\n",
    "        conda create --name project1 --clone base\t(use this to clone the base environment with all its libraries into the new environment)\n",
    "\n",
    "        #if you wish to use the requiremnts.txt file instead of environment.yaml file\n",
    "        conda list -e | findstr /V \"^#\" > requirements.txt      (from a previous environment)\n",
    "        conda create --name myenv --file C:\\Users\\Cornel\\requirements.txt\t \n",
    "\n",
    "\n",
    "# Use the conda env update --file environment.yml command to update the new environment with the packages and dependencies \n",
    "# from the exported YAML file\n",
    "\n",
    "#Google Colab - Creating a new environment and installing libraries into it.\n",
    "        # Start by installing the virtualenv package using the !pip command:\n",
    "                !pip3 install virtualenv\n",
    "        # Create a new virtual environment by running the virtualenv command with the desired environment name:\n",
    "                !virtualenv myenv\n",
    "        # Activate the virtual environment using the source command:\n",
    "                !source /content/drive/MyDrive/colab_env/bin/activate; pip3 list \n",
    "        #if permission is denied, then run below\n",
    "                !chmod +x /content/drive/MyDrive/colab_env/bin/*\n",
    "\n",
    "        # Install the required libraries using !pip within the virtual environment:\n",
    "                !pip3 install library1 library2 library3\n",
    "                pip install -r requirements.txt\n",
    "\n",
    "# Having done this, to load the environment with its libraries:\n",
    "        # Mount Google Drive in your Colab notebook\n",
    "                from google.colab import drive\n",
    "                drive.mount('/content/drive')\n",
    "        # Navigate to the directory where your virtual environment is located on Google Drive\n",
    "                %cd /content/drive/MyDrive/myenv\n",
    "        # Activate the virtual environment using the source command:\n",
    "                !source bin/activate\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42465628",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install virtualenv\n",
    "!virtualenv theanoEnv\n",
    "\n",
    "!source /content/theanoEnv/bin/activate; pip3 install theano\n",
    "\n",
    "!source /content/theanoEnv/bin/activate; pip3 list\n",
    "\n",
    "!source /content/theanoEnv/bin/activate; pip3 install robotframework; pip3 list; python3 -m robot --help\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "eb197176",
   "metadata": {},
   "source": [
    "##### Basic Tips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed02e624",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Naina Chaturvedi on Medium for all courses on Data Science,ML, Deep learning, etc. (https://medium.com/@naina0412)\n",
    "\n",
    "# Object: used for text, numeric, and non-numeric values. If the given data does not fit any of the below dtype, then object type is assigned to it. It is both the blessing and curse in a package. There is a reason why objects are not the way to go for the performance-tuned codebases\n",
    "# int64: Integer numbers — covers both signed and unsigned integers along with the varying variable-length — 8, 16, 32 and 64\n",
    "# float64: Floating point numbers — covers the lengths 16, 32 and 64\n",
    "# bool: True and False values\n",
    "# datetime64: covers the date and time values\n",
    "# timedelta[ns]: used to capture the difference between two DateTime values. this dtype is helpful when the user is working with time-series data\n",
    "# category: used to cover a finite list of text values\n",
    "\n",
    "\n",
    "# In a correlation test, the results will include a correlation coefficient and a p-value.\n",
    "# The correlation coefficient is a number that tells us how strong the relationship is between the two things \n",
    "#we are testing. It can range from -1 to 1. A value of -1 means that there is a strong negative relationship \n",
    "#between the two things (when one thing increases, the other thing decreases). A value of 1 means that \n",
    "#there is a strong positive relationship between the two things (when one thing increases, the other thing increases). \n",
    "#A value of 0 means that there is no relationship between the two things.\n",
    "# The p-value is a number that tells us the probability that the relationship between the two things occurred by chance. \n",
    "#If the p-value is less than 0.05, we can say that the relationship is statistically significant, which means that \n",
    "#it is unlikely to have occurred by chance. If the p-value is greater than 0.05, we cannot say that the relationship \n",
    "#is statistically significant.\n",
    "# For example, let's say that we perform a correlation test and the results show a correlation coefficient of 0.6 \n",
    "#and a p-value of 0.01. This means that there is a moderate positive relationship between the two things we are testing \n",
    "#(the coefficient is close to 1) and that this relationship is statistically significant (the p-value is less than 0.05). \n",
    "#This means that we can be confident that the relationship between the two things is real and not just a coincidence.\n",
    "\n",
    "\n",
    "#Cookiecutter Data Science Project format (check https://drivendata.github.io/cookiecutter-data-science/)\n",
    "To clone a cookiecutter template \n",
    "$ cookiecutter cookiecutter https://github.com/drivendata/cookiecutter-data-science \n",
    "#or\n",
    "$ cookiecutter -c v1 https://github.com/drivendata/cookiecutter-data-science\n",
    "\n",
    "xcopy C:\\Users\\Cornel\\Documents\\5. Projects\\cookiecutter\\cookiecutter_main - what he used\\* C:\\backup /s /y\n",
    "This switch tells xcopy to overwrite files in the destination folder if they already exist.\n",
    "    \n",
    "├── LICENSE\n",
    "├── Makefile           <- Makefile with commands like `make data` or `make train`\n",
    "├── README.md          <- The top-level README for developers using this project.\n",
    "├── data\n",
    "│   ├── external       <- Data from third party sources.\n",
    "│   ├── interim        <- Intermediate data that has been transformed.\n",
    "│   ├── processed      <- The final, canonical data sets for modeling.\n",
    "│   └── raw            <- The original, immutable data dump.\n",
    "│\n",
    "├── docs               <- A default Sphinx project; see sphinx-doc.org for details\n",
    "│\n",
    "├── models             <- Trained and serialized models, model predictions, or model summaries\n",
    "│\n",
    "├── notebooks          <- Jupyter notebooks. Naming convention is a number (for ordering),\n",
    "│                         the creator's initials, and a short `-` delimited description, e.g.\n",
    "│                         `1.0-jqp-initial-data-exploration`.\n",
    "│\n",
    "├── references         <- Data dictionaries, manuals, and all other explanatory materials.\n",
    "│\n",
    "├── reports            <- Generated analysis as HTML, PDF, LaTeX, etc.\n",
    "│   └── figures        <- Generated graphics and figures to be used in reporting\n",
    "│\n",
    "├── requirements.txt   <- The requirements file for reproducing the analysis environment, e.g.\n",
    "│                         generated with `pip freeze > requirements.txt`\n",
    "│\n",
    "├── setup.py           <- Make this project pip installable with `pip install -e`\n",
    "├── src                <- Source code for use in this project.\n",
    "│   ├── __init__.py    <- Makes src a Python module\n",
    "│   │\n",
    "│   ├── data           <- Scripts to download or generate data\n",
    "│   │   └── make_dataset.py\n",
    "│   │\n",
    "│   ├── features       <- Scripts to turn raw data into features for modeling\n",
    "│   │   └── build_features.py\n",
    "│   │\n",
    "│   ├── models         <- Scripts to train models and then use trained models to make\n",
    "│   │   │                 predictions\n",
    "│   │   ├── predict_model.py\n",
    "│   │   └── train_model.py\n",
    "│   │\n",
    "│   └── visualization  <- Scripts to create exploratory and results oriented visualizations\n",
    "│       └── visualize.py\n",
    "│\n",
    "└── tox.ini            <- tox file with settings for running tox; see tox.readthedocs.io\n",
    "\n",
    "\n",
    "#Windows CMD\n",
    "dir: This command is used to display a list of files and folders in a directory.\n",
    "cd: This command is used to change the current working directory.\n",
    "copy: This command is used to copy files from one location to another.\n",
    "mkdir: This command is used to create a new directory.\n",
    "del: This command is used to delete files.\n",
    "ren: This command is used to rename files or directories.\n",
    "cls: This command is used to clear the command prompt screen.\n",
    "ipconfig: This command is used to display information about the network configuration of the computer.\n",
    "ping: This command is used to test the connectivity to a network.\n",
    "shutdown: This command is used to shut down the computer.\n",
    "type: This command is used to display the contents of a text file on the screen.\n",
    "xcopy: This command is used to copy entire directory trees, including subdirectories and files."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7462286d",
   "metadata": {},
   "source": [
    "##### Convert Pandas Categorical Data For Scikit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca04188",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(raw_data, columns = ['patient', 'obs', 'treatment', 'score']) #create dataframe\n",
    "le = preprocessing.LabelEncoder() # Create a label (category) encoder object\n",
    "le.fit(df['score']) # Fit the encoder to the pandas column\n",
    "list(le.classes_) # View the labels (if you want)\n",
    "le.transform(df['score']) # Apply the fitted encoder to the pandas column\n",
    "list(le.inverse_transform([2, 2, 1])) # Convert some integers into their category names"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4e13e72f",
   "metadata": {},
   "source": [
    "##### Handling Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dafc141e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fill Missing Values' Class With Most Frequent Class\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import Imputer\n",
    "imputer = Imputer(strategy='most_frequent', axis=0) # Create Imputer object\n",
    "imputer.fit_transform(X) # Fill missing values with most frequent class. assuming X = DataFrame variable\n",
    "\n",
    "#fill missing values \n",
    "df = pd.fillna({\"DOB\": 0, \"Age\": \"no-event\"}, method = \"ffill\", axis = 1) #method = \"ffil\" or \"bfill\" \n",
    "df.interpolate (method = \"linear\") #method = \"linear\", \"time\", \"index\", \"quadratic\" etc. \n",
    "  #fill missing values with average values\n",
    "    c = avg = 0 #compute average\n",
    "    for ele in df[\"Marks\"]:\n",
    "        if str(ele).isnumeric():\n",
    "            c += 1\n",
    "            avg += ele\n",
    "    avg /= c\n",
    "    #Replace missing values\n",
    "    df = df.replace(to_replace=\"NaN\", value = avg)\n",
    "    #Display data\n",
    "    df\n",
    "\n",
    "#percentage of missing valuess in dataset\n",
    "percent = (df_train.isnull().sum()/df_train.isnull().count()).sort_values(ascending=False)\n",
    "total = df_train.isnull().sum().sort_values(ascending=False)\n",
    "m_data = pd.concat([total, percent],axis=1 )\n",
    "m_data.head(10)\n",
    "    \n",
    "#Summary of missing values\n",
    "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      df.isnull().sum()\n",
    "df.shape #total number of rows and columns in the dataset. Then compare with the number of missing values.\n",
    "\n",
    "#visualize missing data\n",
    "import missingno as msno\n",
    "import pandas as pd\n",
    "df = pd.read_csv('dataset.csv') # Load the dataset\n",
    "msno.matrix(df) # Visualize the missing values\n",
    "#This will create a matrix plot that shows the missing values as white lines.\n",
    "\"\"\"You can also use the 'msno.bar' function to visualize the missing values as a bar chart, \n",
    "or the \"msno.heatmap\" function to visualize the missing values as a heatmap.\"\"\"\n",
    "\n",
    "#or\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "mask = df.isnull() # Create a Boolean mask indicating which values are missing\n",
    "plt.figure(figsize=(10,10)) # Use the mask to create a heatmap\n",
    "plt.title(\"Heatmap of Missing Values\")\n",
    "sns.heatmap(mask, cbar=False, annot=True, cmap='PuBu')\n",
    "plt.show()\n",
    "#This will create a heatmap with white squares indicating missing values, and black squares indicating non-missing values.\n",
    "\n",
    "# Remove observations with missing values\n",
    "X[~np.isnan(X).any(axis=1)]\n",
    "\n",
    "#Imputing Missing Class Labels Using k-Nearest Neighbors\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "X = # Create feature matrix with categorical feature \n",
    "X_with_nan = # Create feature matrix with missing values in the categorical feature\n",
    "clf = KNeighborsClassifier(3, weights='distance') # Train KNN learner\n",
    "trained_model = clf.fit(X[:,1:], X[:,0])\n",
    "imputed_values = trained_model.predict(X_with_nan[:,1:]) # Predict missing values' class\n",
    "X_with_imputed = np.hstack((imputed_values.reshape(-1,1), X_with_nan[:,1:])) # Join column of predicted class with their other features\n",
    "np.vstack((X_with_imputed, X)) # Join two feature matrices\n",
    "\n",
    "#Deleting Missing Values\n",
    "df = pd.DataFrame(X, columns=['feature_1', 'feature_2']) # Load data as a data frame\n",
    "df.dropna(axis=0, how=\"any\", thresh=2) # Remove observations with missing values (how = \"any\" or \"all\"; thresh = 1,2,3 - if you have atleast 1 or 2 non-na values)\n",
    "\n",
    "#Impute Missing Values With Means\n",
    "from sklearn.preprocessing import Imputer\n",
    "mean_imputer = Imputer(missing_values='NaN', strategy='mean', axis=0) # Create an imputer object that looks for 'Nan' values, then replaces them with the mean value of the feature by columns (axis=0)\n",
    "mean_imputer = mean_imputer.fit(df) # Train the imputor on the df dataset\n",
    "imputed_df = mean_imputer.transform(df.values) # Apply the imputer to the df dataset\n",
    "imputed_df # View the data\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1e5f0df4",
   "metadata": {},
   "source": [
    "##### Datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39d202f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "df_train[\"dob\"] = pd.to_datetime(df_train[\"dob\"], infer_datetime_format=True) # convert to datetime format \n",
    "df_train['time'] = df_train['unix_time'].apply(datetime.utcfromtimestamp) # Apply function utcfromtimestamp and drop column unix_time\n",
    "df_train['hour_of_day'] = df_train[\"time\"].dt.hour # Add column hour of day\n",
    "\n",
    "#convert date of birth to current age (It subtracts the years of birth from the current year to calculate the age of each person represented in the 'dob' column)\n",
    "import datetime as dt\n",
    "df_train['age']= dt.date.today().year-pd.to_datetime(df_train['dob']).dt.year\n",
    "\n",
    "dt.date.today().year #computes the current year while performing the datetime functionality\n",
    "pd.to_datetime #converts to a datetime object\n",
    ".dt.year #extracts the year from each datetime object\n",
    ".dt.month #extracts the month from each datetime object\n",
    ".dt.day #extracts the day from each datetime object\n",
    ".dt.hour #extracts the hour from each datetime object\n",
    "\n",
    "#If it shows that unicode nonesense of 1970, use this\n",
    "# df_no_of_deaths[\"Year\"].astype(\"datetime64[ns]\")\n",
    "df_deaths_cause[\"Year\"] = pd.to_datetime(df_deaths_cause[\"Year\"].astype(int).astype(str) + '-01-01')\n",
    "\n",
    "df_deaths_cause['Year'] = df_deaths_cause[\"Year\"].dt.year\n",
    "\n",
    "#create a datetime time range, and making it a dataframe index\n",
    "time_index = pd.date_range('2016-01-01 05:00', periods=503911,  freq='min')  \n",
    "time_index = pd.DatetimeIndex(time_index)\n",
    "df = df.set_index(time_index)  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b7ff9e30",
   "metadata": {},
   "source": [
    "##### Outlier Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccff713a",
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "# A. Outlier Detection\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "# Create detector\n",
    "outlier_detector = EllipticEnvelope(contamination=.1)\n",
    "# Select only numeric columns\n",
    "numeric_cols = df.select_dtypes(include=[\"float64\", \"int64\"])  #you may or may not include this step. \n",
    "# Fit detector\n",
    "outlier_detector.fit(numeric_cols)\n",
    "# Predict outliers\n",
    "outlier_predictions = outlier_detector.predict(numeric_cols) \n",
    "# Add outlier predictions to original dataframe\n",
    "smart_home[\"outlier\"] = outlier_predictions         #you may or may not add outlier predictions to the original dataframe\n",
    "\n",
    "#OR \n",
    "#Boxplot \n",
    "def visualize_outlier (df: pd.DataFrame):\n",
    "    # Select only numeric columns\n",
    "    numeric_cols = df.select_dtypes(include=[\"float64\", \"int64\"])\n",
    "    # Set figure size and create boxplot\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    numeric_cols.boxplot(ax=ax, rot=90)\n",
    "    # Set x-axis label\n",
    "    ax.set_xlabel(\"Numeric Columns\")\n",
    "    # Adjust subplot spacing to prevent x-axis labels from being cut off\n",
    "    plt.subplots_adjust(bottom=0.4) \n",
    "    # Increase the size of the plot\n",
    "    fig.set_size_inches(10, 6)\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "''''\n",
    "In a box plot, the central rectangle spans the first quartile to the third quartile (the 25th to 75th percentiles),\n",
    "and a line is also drawn along the median (50th percentile). The \"whiskers\" extend from the box to show the range of the data, \n",
    "and any points that lie outside the whiskers are plotted as individual points. This will create a box plot for each numerical \n",
    "column in the DataFrame. Outliers are typically represented as points outside the \"whiskers\" of the box plot.'''\n",
    "\n",
    "#B. Tukey's test for extreme values (you can replace 1.5 with 3)\n",
    "def find_outliers_tukey(x): # Define function using 1.5x interquartile range deviations from quartile 1/3 as floor/ceiling\n",
    "    q1 = np.percentile(x, 25)\n",
    "    q3 = np.percentile(x, 75)\n",
    "    iqr = q3-q1 \n",
    "    floor = q1 - 1.5 * iqr\n",
    "    ceiling = q3 + 1.5 * iqr\n",
    "    outlier_indices = list(x.index[(x < floor)|(x > ceiling)])\n",
    "    outlier_values = list(x[outlier_indices])\n",
    "    return outlier_indices, outlier_values\n",
    "\n",
    "for x in range(1, 7): # Modify to select numeric columns # Print outliers for each numeric variable\n",
    "    tukey_indices, tukey_values = find_outliers_tukey(data.ix[:, x])\n",
    "    print(list(data[[x]]), np.sort(tukey_values))\n",
    "    \n",
    "#C. Kernel density estimation\n",
    "from statsmodels.nonparametric.kde import KDEUnivariate\n",
    "def find_outliers_kde(x):  # Define outlier function\n",
    "    x_scaled = scale(list(map(float, x)))\n",
    "    kde = KDEUnivariate(x_scaled)\n",
    "    kde.fit(bw = \"scott\", fft = True)\n",
    "    pred = kde.evaluate(x_scaled)    \n",
    "    n = sum(pred < 0.05)\n",
    "    outlier_ind = np.asarray(pred).argsort()[:n]\n",
    "    outlier_value = np.asarray(x)[outlier_ind]\n",
    "    return outlier_ind, outlier_value\n",
    "\n",
    "for x in range(1, 7): # Modify to select numeric columns   # Print outlier values\n",
    "    kde_indices, kde_values = find_outliers_kde(data.ix[:, x])\n",
    "    print(list(data[[x]]), np.sort(kde_values))\n",
    "\n",
    "-------------------------------------------------------------------------\n",
    "#outlier handling (by removal)\n",
    "\n",
    "# Z-score method:  \n",
    "    This method involves calculating the z-score for each data point and removing those that fall outside \n",
    "a certain threshold. Typically, data points with a z-score of more than 3 or less than -3 are considered outliers.\n",
    "\n",
    "def outlier_z-score(df: pd.DataFrame):\n",
    "    # Load data\n",
    "    df = pd.read_csv('data.csv')\n",
    "\n",
    "    # Calculate z-score for each data point\n",
    "    z_scores = np.abs((df - df.mean()) / df.std())\n",
    "\n",
    "    # Remove data points with z-score greater than 3\n",
    "    df_cleaned = df[(z_scores < 3).all(axis=1)]\n",
    "    return df_cleaned \n",
    "\n",
    "# 2. Mahalanobis distance method: (multivariate outlier detection)\n",
    "\n",
    "def outlier_Mahalanobis_distance (df: pd.DataFrame):\n",
    "    from scipy.spatial.distance import mahalanobis\n",
    "\n",
    "    # Load data\n",
    "    df = pd.read_csv('data.csv')\n",
    "\n",
    "    # Calculate the Mahalanobis distance for each data point\n",
    "    cov = df.cov()\n",
    "    inv_cov = pd.DataFrame(np.linalg.pinv(cov.values), index=cov.index, columns=cov.columns)\n",
    "    mean = df.mean()\n",
    "    dist = []\n",
    "    for i in range(len(df)):\n",
    "        x = df.iloc[i]\n",
    "        dist.append(mahalanobis(x, mean, inv_cov))\n",
    "\n",
    "    # Set threshold for Mahalanobis distance\n",
    "    threshold = 3\n",
    "\n",
    "    # Remove data points with Mahalanobis distance greater than threshold\n",
    "    df_cleaned = df[dist < threshold]\n",
    "    return df_cleaned\n",
    "\n",
    "# 3. Isolation Forest model for outlier detection and removal\n",
    "# The `contamination` parameter is again set to 0.01, indicating that we expect 1% of the data to be outliers.\n",
    "def outlier_isolation_forest (df: pd.DataFrame): \n",
    "    from sklearn.ensemble import IsolationForest\n",
    "    import pandas as pd\n",
    "\n",
    "    # Load data\n",
    "    df = pd.read_csv('data.csv')\n",
    "\n",
    "    # Fit IsolationForest model to data\n",
    "    model = IsolationForest(contamination=0.01)\n",
    "    model.fit(df)\n",
    "\n",
    "    # Predict outliers\n",
    "    outliers = model.predict(df) == -1\n",
    "\n",
    "    # Remove outliers from data\n",
    "    df_cleaned = df[~outliers]\n",
    "    return df_cleaned\n",
    "\n",
    "#4 EllipticEnvelope\n",
    "\n",
    "def outlier_EllipticEnvelope (df: pd.DataFrame): \n",
    "    from sklearn.covariance import EllipticEnvelope\n",
    "\n",
    "    # Load data\n",
    "    df = pd.read_csv('data.csv')\n",
    "\n",
    "    # Fit EllipticEnvelope model to data\n",
    "    model = EllipticEnvelope(contamination=0.01)\n",
    "    model.fit(df)\n",
    "\n",
    "    # Predict outliers\n",
    "    outliers = model.predict(df) == -1\n",
    "\n",
    "    # Remove outliers from data\n",
    "    df_cleaned = df[~outliers]\n",
    "    return df_cleaned \n",
    "\n",
    "\n",
    "#oulier handling (with removal)\n",
    "\n",
    "#IQR Method\n",
    "import numpy as np\n",
    "\n",
    "def handle_outliers_iqr(data):\n",
    "    \"\"\"\n",
    "    This function uses the interquartile range (IQR) method to handle outliers in the data. \n",
    "    Any data points that fall below Q1 - 1.5*IQR or above Q3 + 1.5*IQR are replaced with the nearest bound.\n",
    "\n",
    "    Parameters:\n",
    "    data (numpy.ndarray): A 1-dimensional numpy array containing the data.\n",
    "\n",
    "    Returns:\n",
    "    numpy.ndarray: A 1-dimensional numpy array with the outliers replaced by the nearest bound.\n",
    "    \"\"\"\n",
    "    Q1 = np.percentile(data, 25, interpolation='midpoint')\n",
    "    Q3 = np.percentile(data, 75, interpolation='midpoint')\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    data = np.where(data < lower_bound, lower_bound, data)\n",
    "    data = np.where(data > upper_bound, upper_bound, data)\n",
    "    return data\n",
    "\n",
    "#Trimming Method\n",
    "\n",
    "def handle_outliers_trimming(data, percentage):\n",
    "    \"\"\"\n",
    "    This function uses the trimming method to handle outliers in the data. \n",
    "    The percentage of data points to be trimmed from the lower and upper ends is specified.\n",
    "\n",
    "    Parameters:\n",
    "    data (numpy.ndarray): A 1-dimensional numpy array containing the data.\n",
    "    percentage (float): A value between 0 and 100 specifying the percentage of data points to be trimmed from the lower and upper ends.\n",
    "\n",
    "    Returns:\n",
    "    numpy.ndarray: A 1-dimensional numpy array with the trimmed outliers.\n",
    "    \"\"\"\n",
    "    lower_percentage = percentage / 2\n",
    "    upper_percentage = 100 - lower_percentage\n",
    "    lower_bound = np.percentile(data, lower_percentage, interpolation='midpoint')\n",
    "    upper_bound = np.percentile(data, upper_percentage, interpolation='midpoint')\n",
    "    data = np.where(data < lower_bound, lower_bound, data)\n",
    "    data = np.where(data > upper_bound, upper_bound, data)\n",
    "    return data\n",
    "\n",
    "#Arbitrary Capping\n",
    "def handle_outliers_arbitrary(data, lower_cap, upper_cap):\n",
    "    \"\"\"\n",
    "    This function uses the arbitrary capping method to handle outliers in the data. \n",
    "    Any data points that fall below the lower_cap or above the upper_cap are replaced with the nearest bound.\n",
    "\n",
    "    Parameters:\n",
    "    data (numpy.ndarray): A 1-dimensional numpy array containing the data.\n",
    "    lower_cap (float): The lower bound for capping outliers.\n",
    "    upper_cap (float): The upper bound for capping outliers.\n",
    "\n",
    "    Returns:\n",
    "    numpy.ndarray: A 1-dimensional numpy array with the capped outliers.\n",
    "    \"\"\"\n",
    "    data = np.where(data < lower_cap, lower_cap, data)\n",
    "    data = np.where(data > upper_cap, upper_cap, data)\n",
    "    return data\n",
    "\n",
    "#Outlier Capping with Quantiles\n",
    "\n",
    "def handle_outliers_quantile(data, lower_quantile, upper_quantile):\n",
    "    \"\"\"\n",
    "    This function uses the outlier capping method with quantiles to handle outliers in the data. \n",
    "    Any data points that fall below the lower_quantile or above the upper_quantile are replaced with the nearest bound.\n",
    "\n",
    "    Parameters:\n",
    "    data (numpy.ndarray): A 1-dimensional numpy array containing the data.\n",
    "    lower_quantile (float): The lower quantile value for capping outliers.\n",
    "    upper_quantile (float): The upper quantile value for capping outliers.\n",
    "\n",
    "    Returns:\n",
    "    numpy.ndarray: A 1-dimensional numpy array with the capped outliers\n",
    "    \"\"\"\n",
    "    lower_bound = np.quantile(data, lower_quantile, interpolation='midpoint')\n",
    "    upper_bound = np.quantile(data, upper_quantile, interpolation='midpoint')\n",
    "    data = np.where(data < lower_bound, lower_bound, data)\n",
    "    data = np.where(data > upper_bound, upper_bound, data)\n",
    "    return data\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d3ba6f41",
   "metadata": {},
   "source": [
    "##### Dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf76da22",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#A. For a non-binary categorical variable:\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m dummy \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mget_dummies(dta1[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcountry\u001b[39m\u001b[38;5;124m'\u001b[39m], prefix\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mct\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mint\u001b[39m)\n\u001b[0;32m      3\u001b[0m dummy\u001b[38;5;241m.\u001b[39mhead()\n\u001b[0;32m      4\u001b[0m df1\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstring\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "#A. For a non-binary categorical variable:\n",
    "dummy = pd.get_dummies(dta1['country'], prefix='ct').astype(int)\n",
    "dummy.head()\n",
    "df1.astype(\"string\")\n",
    "\n",
    "#B. For all categorical variables of a dataframe:\n",
    "# Create a list of features to dummy\n",
    "dummy_vars = ['COL1', 'COL2', 'COL3'] \n",
    "\n",
    "# Create dummies for all categorical variables\n",
    "def dummy_data(df, dummy_vars): \n",
    "    for x in dummy_vars:\n",
    "        dummies = pd.get_dummies(df[x], prefix=x, dummy_na=False)\n",
    "        df = df.drop(x, 1)\n",
    "        df = pd.concat([df, dummies], axis=1)\n",
    "    return df\n",
    "\n",
    "df = dummy_df(df, dummy_data)\n",
    "print(df.head())\n",
    "\n",
    "# Dummies \n",
    "dummy_ct = pd.get_dummies(df1['country'], prefix='ct').astype(int)\n",
    "dummy_pf = pd.get_dummies(df1['platform'], prefix='pf').astype(int)\n",
    "merged = pd.concat([df1, dummy_ct], axis = \"columns\") #after creating dummies, you merge the dummy with the original dataframe \n",
    "            # and drop df1['country'] and one dummy variable\n",
    "\n",
    "# Define columns to keep\n",
    "colstokeep = ['ABC', 'DEF']\n",
    "\n",
    "# Join dummies to columns to be kept from original dataframe using an identifier that is not in the list of columns to keep\n",
    "df1 = df1[colstokeep].join(dummy_ct.ix[:, 'ct_BR':]).join(dummy_pf.ix[:, 'pf_amazon':])\n",
    "df1.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "02c23e2d",
   "metadata": {},
   "source": [
    "##### Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26720070",
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "#Encoding Ordinal Categorical Features\n",
    "df = pd.DataFrame({'Score': ['Low', 'Low', 'Medium', 'Medium', 'High']}) # Create features\n",
    "scale_mapper = {'Low':1, 'Medium':2, 'High':3} # Create mapper (Scale Map)\n",
    "df['Scale'] = df['Score'].replace(scale_mapper) # Map feature values to scale\n",
    "df # View data frame\n",
    "\n",
    "#Reshaping and catgorising data\n",
    "df[\"Gender\"] = df[\"Gender\"].map({\"M\":0, \"F\": 1}).astype(float)\n",
    "\n",
    "#One-Hot Encode Features With Multiple Labels\n",
    "from sklearn.preprocessing import MultiLabelBinarizer # Load libraries\n",
    "y = [('Texas', 'Florida')]  # Create NumPy array\n",
    "one_hot = MultiLabelBinarizer() # Create MultiLabelBinarizer object\n",
    "one_hot.fit_transform(y) # One-hot encode data\n",
    "one_hot.classes_ # View classes\n",
    "\n",
    "#One-Hot Encode Nominal Categorical Features\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "x = np.array([['Texas'], ['California'], ['Texas'], ['Delaware'], ['Texas']]) # Create NumPy array\n",
    "one_hot = OneHotEncoder() # Create LabelBinzarizer object (Method 1)\n",
    "one_hot.fit_transform(x) # One-hot encode data\n",
    "one_hot.categories_ # View classes\n",
    "pd.get_dummies(x[:,0]) # Dummy feature (Method 2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "13e982c7",
   "metadata": {},
   "source": [
    "##### Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20176d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#A. Handling Imbalanced Classes With Downsampling\n",
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris() # Load iris data\n",
    "X = iris.data # Create feature matrix\n",
    "y = iris.target # Create target vector\n",
    "X = X[40:,:] # Remove first 40 observations\n",
    "y = y[40:] \n",
    "y = np.where((y == 0), 0, 1) # Create binary target vector indicating if class 0\n",
    "y # Look at the imbalanced target vector\n",
    "i_class0 = np.where(y == 0)[0] # Indicies of each class' observations\n",
    "i_class1 = np.where(y == 1)[0]\n",
    "n_class0 = len(i_class0) # Number of observations in each class\n",
    "n_class1 = len(i_class1)\n",
    "i_class1_downsampled = np.random.choice(i_class1, size=n_class0, replace=False) # For every observation of class 0, randomly sample from class 1 without replacement\n",
    "np.hstack((y[i_class0], y[i_class1_downsampled])) # Join together class 0's target vector with the downsampled class 1's target vector\n",
    "\n",
    "\n",
    "#B. Handling Imbalanced Classes With Upsampling\n",
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris() # Load iris data\n",
    "X = iris.data # Create feature matrix\n",
    "y = iris.target # Create target vector\n",
    "X = X[40:,:] # Remove first 40 observations\n",
    "y = y[40:] \n",
    "y = np.where((y == 0), 0, 1) # Create binary target vector indicating if class 0\n",
    "y # Look at the imbalanced target vector\n",
    "i_class0 = np.where(y == 0)[0] # Indicies of each class' observations\n",
    "i_class1 = np.where(y == 1)[0]\n",
    "n_class0 = len(i_class0) # Number of observations in each class\n",
    "n_class1 = len(i_class1)\n",
    "i_class0_upsampled = np.random.choice(i_class0, size=n_class1, replace=True) # For every observation in class 1, randomly sample from class 0 with replacement\n",
    "np.concatenate((y[i_class0_upsampled], y[i_class1])) # Join together class 0's upsampled target vector with class 1's target vector\n",
    "\n",
    "\n",
    "\n",
    "def check_imbalance(dataset):\n",
    "    \"\"\"\n",
    "    This function takes a dataset as input and returns True if the dataset is imbalanced, False otherwise.\n",
    "    \"\"\"\n",
    "    # Get the counts of each class in the dataset\n",
    "    class_counts = dataset['class'].value_counts()\n",
    "    \n",
    "    # Calculate the percentage of each class in the dataset\n",
    "    class_percentages = class_counts / len(dataset) * 100\n",
    "    \n",
    "    # Plot the class percentages\n",
    "    plt.bar(class_counts.index, class_percentages)\n",
    "    plt.xlabel('Class')\n",
    "    plt.ylabel('Percentage')\n",
    "    plt.title('Class Distribution')\n",
    "    plt.show()\n",
    "    \n",
    "    # Check if the dataset is imbalanced\n",
    "    if len(class_counts) == 2:\n",
    "        # Binary classification\n",
    "        minority_class = class_counts.index[1]\n",
    "        minority_class_percentage = class_percentages[1]\n",
    "        if minority_class_percentage < 10 or minority_class_percentage > 90:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    else:\n",
    "        # Multi-class classification\n",
    "        class_imbalance = False\n",
    "        for percentage in class_percentages:\n",
    "            if percentage < 10 or percentage > 90:\n",
    "                class_imbalance = True\n",
    "                break\n",
    "        return class_imbalance\n",
    "\n",
    "def check_imbalance(dataset, columns=None, threshold=10):\n",
    "    \"\"\"\n",
    "    This function takes a dataset and one or more columns as input and returns True if any of the specified columns\n",
    "    are imbalanced, False otherwise. A column is considered imbalanced if the percentage of the minority class is less\n",
    "    than the specified threshold.\n",
    "    \"\"\"\n",
    "    # If no columns are specified, use all columns except for the last one as the features\n",
    "    if columns is None:\n",
    "        features = dataset.iloc[:, :-1]\n",
    "        columns = features.columns\n",
    "    \n",
    "    # Check the imbalance of each specified column\n",
    "    for col in columns:\n",
    "        # Get the counts of each class in the column\n",
    "        class_counts = dataset[col].value_counts()\n",
    "\n",
    "        # Calculate the percentage of each class in the column\n",
    "        class_percentages = class_counts / len(dataset) * 100\n",
    "\n",
    "        # Plot the class percentages\n",
    "        plt.bar(class_counts.index, class_percentages)\n",
    "        plt.xlabel(col)\n",
    "        plt.ylabel('Percentage')\n",
    "        plt.title(f'{col} Distribution')\n",
    "        plt.show()\n",
    "\n",
    "        # Check if the column is imbalanced\n",
    "        minority_class = class_counts.index[-1]\n",
    "        minority_class_percentage = class_percentages.iloc[-1]\n",
    "        if minority_class_percentage < threshold:\n",
    "            print(f'{col} is imbalanced. Minority class: {minority_class}, Percentage: {minority_class_percentage:.2f}%')\n",
    "            return True\n",
    "\n",
    "    # If none of the specified columns are imbalanced, return False\n",
    "    print('No imbalance found.')\n",
    "    return False\n",
    "\n",
    "\n",
    "# Oversampling involves increasing the number of instances in the minority class by generating new samples.\n",
    "# This can be done by randomly duplicating existing instances, or by generating synthetic instances using techniques \n",
    "# such as SMOTE (Synthetic Minority Over-sampling Technique). \n",
    "# Undersampling, on the other hand, involves reducing the number of instances in the majority class. This can be done by \n",
    "# randomly removing instances from the majority class, or by selecting a subset of instances based on some criteria, \n",
    "# such as their distance to the minority class.  \n",
    "\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "def handle_imbalanced_data(X, y, strategy='over-sampling'):\n",
    "    \"\"\"\n",
    "    Handle imbalanced data using imblearn library.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    X: array-like of shape (n_samples, n_features)\n",
    "        The input data.\n",
    "    y: array-like of shape (n_samples,)\n",
    "        The target values.\n",
    "    strategy: str, default='over-sampling'\n",
    "        The strategy to use for handling imbalanced data. Possible values are\n",
    "        'over-sampling' and 'under-sampling'.\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    X_resampled: array-like of shape (n_samples_new, n_features)\n",
    "        The resampled input data.\n",
    "    y_resampled: array-like of shape (n_samples_new,)\n",
    "        The resampled target values.\n",
    "    \"\"\"\n",
    "    if strategy == 'over-sampling':\n",
    "        # Initialize the RandomOverSampler object\n",
    "        ros = RandomOverSampler(sampling_strategy='minority', random_state=0)\n",
    "        # Resample the data\n",
    "        X_resampled, y_resampled = ros.fit_resample(X, y)\n",
    "    elif strategy == 'under-sampling':\n",
    "        # Initialize the RandomUnderSampler object\n",
    "        rus = RandomUnderSampler(sampling_strategy='majority', random_state=0)\n",
    "        # Resample the data\n",
    "        X_resampled, y_resampled = rus.fit_resample(X, y)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid strategy. Possible values are 'over-sampling' and 'under-sampling'.\")\n",
    "    \n",
    "    return X_resampled, y_resampled\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "def apply_smote(X, y, sampling_strategy='auto', random_state=None):\n",
    "    \"\"\"\n",
    "    Applies Synthetic Minority Over-sampling Technique (SMOTE) to address data imbalance in a binary classification problem.\n",
    "    \n",
    "    SMOTE is a technique for oversampling the minority class in a dataset by generating synthetic examples from the\n",
    "    minority class to balance the class distribution. This function takes the input features (X) and corresponding\n",
    "    labels (y), and applies SMOTE to oversample the minority class.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    X : array-like, shape (n_samples, n_features)\n",
    "        The input features.\n",
    "    y : array-like, shape (n_samples,)\n",
    "        The corresponding labels.\n",
    "    sampling_strategy : str or float or dict or callable, optional (default='auto')\n",
    "        The sampling strategy to be applied by SMOTE. This parameter is passed to the `sampling_strategy` argument of\n",
    "        the SMOTE class from the imbalanced-learn library. Possible values:\n",
    "            - 'auto': Resamples the minority class to have the same number of samples as the majority class.\n",
    "            - 'minority': Resamples the minority class to have the same number of samples as the majority class.\n",
    "            - 'not minority': Resamples all classes except the minority class to have the same number of samples as the\n",
    "              majority class.\n",
    "            - 'all': Resamples all classes to have the same number of samples as the majority class.\n",
    "            - float: Resamples the minority class to have the specified ratio of samples compared to the majority class.\n",
    "            - dict: Resamples each class to have the specified number of samples.\n",
    "            - callable: A custom function that defines the sampling strategy.\n",
    "    random_state : int or RandomState or None, optional (default=None)\n",
    "        Seed or random number generator for reproducibility of results.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    X_resampled : array-like, shape (n_samples_new, n_features)\n",
    "        The oversampled feature matrix.\n",
    "    y_resampled : array-like, shape (n_samples_new,)\n",
    "        The corresponding oversampled labels.\n",
    "    \"\"\"\n",
    "    # Create an instance of SMOTE\n",
    "    smote = SMOTE(sampling_strategy=sampling_strategy, random_state=random_state) #sampling_strategy={1:48050}\n",
    "    \n",
    "    # Apply SMOTE to oversample the minority class\n",
    "    X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "    \n",
    "    return X_resampled, y_resampled\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fee641d0",
   "metadata": {},
   "source": [
    "##### Tips for Plotting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006632cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Matplotlib Plots\n",
    "\n",
    "#First Chart (single or multiple charts)\n",
    "fig = plt.figure(figsize=(3,2), dpi=100) #figsize(width,height) in inches; dpi\n",
    "\n",
    "axes_1 = fig.add_axes([0.1,0.1,0.9, 0.8]) #left, bottom, width, and height. If you want more than one chart, keep adding new axis\n",
    "axes_1.plot(x, y**2, label = \"First Chart\", color = \"r\", linewidth = 3, linestyle = \":\",\n",
    "            markers = \"*\" , markersize = 10, markerfacecolor = \"yellow\", markeredgewidth = 3, \n",
    "            markeredgewidthecolor = \"green\" , alpha = 0.5) #alpha shows the level of transparency of the line\n",
    "            #you can also use the following: lw = linewidth; ls = linestyle\n",
    "            #for color and customization, you can combine it together: \"r--\"            \n",
    "axes_1.plot(x,y**3, label = \"Second Chart\", \"r\")\n",
    "axes_1.set_title(\"This is my title\")\n",
    "axes_1.set_xlabel(\"This is xlabel\")\n",
    "axes_1.set_ylabel(\"This is ylabel\")\n",
    "axes_1.legend(loc= 0) #adding legends #for location: 0 = best; you can also use tupe (left, bottom) to specify exact location. \n",
    "axes.set_xlim([0, 1]) #plot range for x-axis  #[lower bound, upper bound]\n",
    "axes.set_ylim([0, 2]) #plot range for y-axis  #[lower bound, upper bound]\n",
    "axes_1.tight_layout()\n",
    "fig.savefig(\"my_first_chart.png\") #save figure\n",
    "\n",
    "\n",
    "\n",
    "#Second Chart (single or multiple charts)\n",
    "fig,axes = plt.subplots(nrows = 2, ncols = 2, figsize=(3,2), dpi=100) #figsize(width,height) in inches; dpi. #You then specify the number of plots based on the rows and columns\n",
    "\n",
    "plt.tight_layout() #to fix the issue of overlapping\n",
    "axes[o,1].plot(x,y, label = \"First Chart\", \"r\") \n",
    "axes[0,1].set_title(\"This is the title for the first chart\")\n",
    "axes[0,1].set_xlabel(\"This is xlabel\")\n",
    "axes[0,1].set_ylabel(\"This is ylabel\")\n",
    "axes[0,1].legend(loc= 0) #adding legends #for location: 0 = best; you can also use tuple (left, bottom) to specify exact location.\n",
    "axes.set_xlim([0, 1]) #plot range for x-axis  #[lower bound, upper bound]\n",
    "axes.set_ylim([0, 2]) #plot range for y-axis  #[lower bound, upper bound]\n",
    "\n",
    "axes[1].plot(x,y, label = \"Second Chart\")\n",
    "axes[1].set_title(\"xxxxxxx\")\n",
    "axes[1].set_xlabel(\"This the label for the x-axis\")\n",
    "axes[1].set_ylabel(\"This is ylabel\")\n",
    "axes[1].legend(loc= 0) #adding legends #for location: 0 = best; you can also use tuple (left, bottom) to specify exact location.\n",
    "axes.set_xlim([0, 1]) #plot range for x-axis  #[lower bound, upper bound]\n",
    "axes.set_ylim([0, 2]) #plot range for y-axis  #[lower bound, upper bound]\n",
    "fig.savefig(\"my_first_chart.png\") #save figure\n",
    "\n",
    "#NB: other important things you can use in your plots\n",
    "sns.boxplot(x=\"Year\", y=\"Deaths 70+ years\", hue='Entity', data=focus_countries, palette='mako')\n",
    "plt.title('Deaths caused by Cardiovascular deaths for 70+ Years')\n",
    "ax = plt.gca() # Get the Axes object\n",
    "ax.set_xlim(0, 50) # Set the x-axis range\n",
    "ax.xaxis.set_ticks(range(0, 55, 5)) # Set the number of x-axis values to display or ax.xaxis.set_ticks([1990, 1995, 2000, 2005, 2010])\n",
    "ax.set_xticks([1990, 1995, 2000, 2005, 2010, 2015, 2020])\n",
    "ax.set_xticklabels([\"1990\", \"1995\", \"2000\", \"2005\", \"2010\", \"2015\", \"2020\"])\n",
    "plt.savefig(\"C:\\\\myDrive\\xx_image.png\")\n",
    "\n",
    "#OR\n",
    "fig,ax = plt.subplots(nrows = 2, ncols = 2, figsize=(3,2), dpi=100)\n",
    "pivot.plot(kind='line', ax = ax)\n",
    "plt.xlabel(\"Year\") # Add labels and title to the plot\n",
    "plt.ylabel(\"Deaths\")\n",
    "plt.title(\"Deaths by Cardiovascular diseases\")\n",
    "plt.show() # Show the plot\n",
    "fig.savefig(\"C:\\\\myDrive\\xx_image.png\")\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "#seaborn inbuilt dataset\n",
    "tips = sns.load_dataset('tips')\n",
    "\n",
    "#Dist plot\n",
    "Dist plot allows us to show the distribution of a univariate set of observations \n",
    "KDE (kernel density estimates) A kernel density estimate (KDE) is a non-parametric method for estimating the \n",
    "    probability density function (PDF) of a random variable. It is the curve on the histogram. \n",
    "#bins are each rectangles in the histogram. \n",
    "\n",
    "sns.distplot(tips[\"total_bill\"]) #or\n",
    "sns.histplot(tips[\"total_bill\"], kde=True, stat=\"density\", linewidth=0, bins = 30)\n",
    "\n",
    "#joint plots\n",
    "allows you to basically match up two distplots for bivariate data\n",
    "#kind allows you to affect what is going on inside of the joint plot. default is scattered. \n",
    "    #hex allows you to make a hexagon distribution representation\n",
    "    #reg - regression \n",
    "    #kde - kernel density estimates\n",
    "sns.jointplot(x= \"total_bill\",y= \"tip\",data = tips, kind= \"hex\")\n",
    "\n",
    "#pairplot (very useful)\n",
    "this plots pairwise relationships across the entire dataframe (at least for the numerical columns). Very important\n",
    "    This is like a jointplot but for the entire dataframe\n",
    "#hue - use hue to access and explore the categorical columns. Simply input the categorical column name\n",
    "sns.pairplot(tips, hue=\"sex\", palette=\"coolwarm\")\n",
    "\n",
    "#rugplot\n",
    "sns.rugplot(tips)\n",
    "\n",
    "#kde plots\n",
    "sns.kde(tips[\"total_bill\"])\n",
    "\n",
    "#Line Plots\n",
    "import plotly.express as px\n",
    "fig = px.line(data_frame=energy_per_day.filter(items=['Dishwasher [kW]', 'Kitchen 14 [kW]', 'Kitchen 38 [kW]',\n",
    "                                                       'Microwave [kW]', 'Living room [kW]', 'Solar [kW]']),\n",
    "              line_dash_sequence=['solid']*16, width=900, height=600)\n",
    "fig.show()\n",
    "\n",
    "\n",
    "#CATEGORICAL PLOTS\n",
    "\n",
    "#bar plots\n",
    "allows you to aggregate the categorical data based off of a function (by default it is the mean)\n",
    "    to change the aggregate, use the estimator and specify the new aggregate. \n",
    "sns.barplot(x= \"sex\", y = \"total_bill\", data = tips, estimator=np.std)\n",
    "\n",
    "#countplot\n",
    "essentially the same as a bar plot, except the estimator is explicitly counting the number of ocurences. \n",
    "    Hence we only set the x value\n",
    "sns.countplot(x = \"sex\", data = tips)\n",
    "\n",
    "#box plots and violin plots\n",
    "useed to show the distribution of categorical data. \n",
    "    A box plot is aka box and wisker plot. it shows the dist of quantitative data in a way that \n",
    "        facilitates comparison btw variableables\n",
    "    x = categorical data; y = numerical data \n",
    "    you can also use \"hue\" for both plots \n",
    "sns.boxplot(x = \"day\", y = \"total_bill\", data=tips) \n",
    "sns.violinplot(x = \"day\", y = \"total_bill\", data=tips) \n",
    "sns.boxplot(x = \"day\", y = \"total_bill\", data=tips, hue=\"sex\", split = True) #if you decide to use \"hue\" \n",
    "\n",
    "#strip plots\n",
    "it will draw a scatter plot where one variable is categorical. \n",
    "sns.stripplot(x = \"day\", y = \"total_bill\", data=tips, jitter=True )\n",
    "sns.stripplot(x = \"day\", y = \"total_bill\", data=tips, jitter=True, hue=\"sex\", split = True) #if you decide to use \"hue\"\n",
    "\n",
    "#swarm plots (you really don't need this type of plot)\n",
    "often used as a combinantion of strip plots and violin plots\n",
    "the points of a swam plot are adjusted so that it doesn not overlap\n",
    "the drawback of swarm plots are that they do not scale well to very large numbers. \n",
    "sns.swarmplot(x = \"day\", y = \"total_bill\", data=tips)\n",
    "\n",
    "#factor plot (or catplot)\n",
    "this is the most general form of all the above plots\n",
    "you can change the kind to \"bar\", 'strip','swarm','box','violin', \"hex\", \"reg\" etc. for additional plots. \n",
    "sns.catplot(x = \"day\", y = \"total_bill\", data=tips, kind = \"bar\")\n",
    "\n",
    "\n",
    "\n",
    "#MATRIX PLOTS\n",
    "you must first convert a datset into a matrix form. To do that use a pivot table, or try to get correlation data\n",
    "    corelation data method: tips_corr = tips.corr()\n",
    "    pivot table method: flights.pivot_table(index = \"month\", columns = \"year\", values= \"passengers\")\n",
    "cmap: color map. a lot of options from \"coolwarm\", \"magma\" etc. \n",
    "sns.heatmap(tips_corr, annot=True, cmap=\"coolwarm\", linecolor=\"white\",linewidths=0.5)\n",
    "sns.clustermap(tips_corr, standard_scale=1) #you can also add clustermap to the heatmap\n",
    "#NB: A heat map will display things in the order you put them in, \n",
    "    #a cluster map will cluster things in an order so that imilar groups are close to each other\n",
    "\n",
    "\n",
    "\n",
    "#GRIDS ()\n",
    "1. grid_m = sns.PairGrid(tips) #similar to pair plots for plotting multiple plots\n",
    "grid_m.map(plt.scatter)\n",
    "\n",
    "#for additional functionalities\n",
    "grid_m.map_diag(sns.distplot) #map a distribution plot on the diagonal grids \n",
    "grid_m.map_upper(plt.scatter) #map a scatter plot on the upper part of the pair grids created\n",
    "grid_m.map_lower(sns.kdeplot) #map a kde plot on the lower part of the pair grids created\n",
    "\n",
    "2. grid_p = sns.FacetGrid(data=tips, col=\"time\", row=\"smoker\")\n",
    "grid_p.map(sns.distplot, \"total_bill\")\n",
    "#or use the other additional functionalities above. \n",
    "\n",
    "\n",
    "\n",
    "#CHLOROPLETH MAPS\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "\n",
    "# Data\n",
    "data = {'Country': ['Algeria', 'Egypt', 'South Africa', 'Kenya', 'Morocco', 'Tunisia'],\n",
    "        'Year': [2020, 2020, 2020, 2020, 2020, 2020],\n",
    "        'Deaths': [1000, 800, 1500, 700, 500, 600]}\n",
    "\n",
    "# Create a DataFrame from the data\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Plot a choropleth map of Africa showing the number of deaths by country and year\n",
    "fig = px.choropleth(df, locations=\"Country\", locationmode='country names', color=\"Deaths\",\n",
    "                    title='Deaths in Africa by Country and Year', color_continuous_scale=\"Viridis\",\n",
    "                    animation_frame=\"Year\", animation_group=\"Country\", hover_name=\"Country\",\n",
    "                    height=500, width=1000)\n",
    "\n",
    "fig.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "250.188px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "144.844px",
    "left": "996px",
    "right": "20px",
    "top": "118px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "c1065e887cc437d9280cab66f73a21fdac543e65443791bfb846601e6c934655"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
