{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EeKPIH5771r0"
      },
      "source": [
        "# Tensorflow Demo\n",
        "\n",
        "This section goes over how to build, train, and tune a model using the \"tensorflow\" library."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "asE7pkSJ8clG"
      },
      "source": [
        "## Creating a basic sequential neural network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0PRtCcUG7zly"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load and preprocess the MNIST dataset\n",
        "(x_train_full, y_train_full), (x_test, y_test) = mnist.load_data()\n",
        "x_train_full, x_test = x_train_full / 255.0, x_test / 255.0  # Normalize the pixel values\n",
        "y_train_full, y_test = to_categorical(y_train_full), to_categorical(y_test)  # One-hot encode the labels\n",
        "\n",
        "# Split off a validation set from the training set\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train_full, y_train_full, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Vd2vOHPNI0y",
        "outputId": "abc27430-9951-4e38-ee3a-1ffcdf6fcfa8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(60000, 10)"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train_full.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "id": "I7QM3PKQMe00",
        "outputId": "8439e66a-2c2e-4bd6-80fe-4ba06902899f"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Plot the first image in the training set\n",
        "plt.imshow(x_train[0], cmap=plt.cm.binary)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-o0V2reCe_t"
      },
      "source": [
        "## Building the architecture\n",
        "\n",
        "In the basic list version, you list out your input layer, your hidden layers, and your output layer. In this example, we only have one hidden layer, and the output is using a \"softmax\" activation function since this is a multiclass problem."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gBlsWLi3CdOU",
        "outputId": "e16d6e5c-bf3c-478d-c6ff-5ca988890b99"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/reshaping/flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        }
      ],
      "source": [
        "# Build a simple neural network model\n",
        "model = Sequential([\n",
        "    Flatten(input_shape=(28, 28)),  # Flatten 28x28 images to a 784-element vector\n",
        "    Dense(128, activation='relu'),  # Hidden layer with 128 neurons and ReLU activation\n",
        "    Dense(10, activation='softmax')  # Output layer with 10 neurons (one for each class) and softmax activation\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-KFxjUrC7Ro"
      },
      "source": [
        "## Compiling and training the model\n",
        "\n",
        "Once you've selected your architecture, you can select your [optimizer](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers), [loss function](https://www.tensorflow.org/api_docs/python/tf/keras/losses), and what [metrics](https://www.tensorflow.org/api_docs/python/tf/keras/metrics) you want to keep track of while training. You can also create custom metrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rIs9j_3bC8VW"
      },
      "outputs": [],
      "source": [
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kAjORw0OEqoP"
      },
      "source": [
        "## Training the model and examining the results\n",
        "\n",
        "To train the model itself, you use the \"fit\" function. You can also save the intermediate results of the fit function in a \"history\" object that keeps track of how the model performed over each epoch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bIpJHl_LJst6",
        "outputId": "e8222aba-364b-4d9a-c506-806a490d58b1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(48000, 28, 28)"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qf-1-QZ-J1HD",
        "outputId": "1d9527ae-5a21-4dc8-c4be-971664e83d98"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "187.5"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x_train.shape[0]/256"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "zxSkhus1Nvxj",
        "outputId": "cdef288e-cea4-45a2-f447-a4f31d7f3fe9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "100352"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "id": "8NSy7B5BKkk0",
        "outputId": "a5c6ce08-54e7-4354-9a4e-2e5df4aa6e84"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">100,480</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │         \u001b[38;5;34m100,480\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │           \u001b[38;5;34m1,290\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">305,312</span> (1.16 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m305,312\u001b[0m (1.16 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">101,770</span> (397.54 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m101,770\u001b[0m (397.54 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">203,542</span> (795.09 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m203,542\u001b[0m (795.09 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VjtOhj-DEuSX",
        "outputId": "d4fca2ef-215a-45f6-f92d-a86d8384d05f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step - accuracy: 0.7676 - loss: 0.8607 - val_accuracy: 0.9283 - val_loss: 0.2562\n",
            "Epoch 2/10\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.9333 - loss: 0.2348 - val_accuracy: 0.9464 - val_loss: 0.1925\n",
            "Epoch 3/10\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9516 - loss: 0.1715 - val_accuracy: 0.9542 - val_loss: 0.1643\n",
            "Epoch 4/10\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9598 - loss: 0.1391 - val_accuracy: 0.9619 - val_loss: 0.1396\n",
            "Epoch 5/10\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 8ms/step - accuracy: 0.9658 - loss: 0.1173 - val_accuracy: 0.9638 - val_loss: 0.1271\n",
            "Epoch 6/10\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.9726 - loss: 0.0990 - val_accuracy: 0.9671 - val_loss: 0.1153\n",
            "Epoch 7/10\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.9774 - loss: 0.0838 - val_accuracy: 0.9699 - val_loss: 0.1065\n",
            "Epoch 8/10\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9788 - loss: 0.0744 - val_accuracy: 0.9705 - val_loss: 0.1015\n",
            "Epoch 9/10\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9821 - loss: 0.0638 - val_accuracy: 0.9707 - val_loss: 0.0998\n",
            "Epoch 10/10\n",
            "\u001b[1m188/188\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9839 - loss: 0.0566 - val_accuracy: 0.9716 - val_loss: 0.0930\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9684 - loss: 0.1019\n",
            "Test accuracy: 97.32%\n"
          ]
        }
      ],
      "source": [
        "# Train the model and capture training history\n",
        "history = model.fit(x_train, y_train, epochs=10, batch_size=256, validation_data=(x_val, y_val))\n",
        "\n",
        "# Evaluate the model on test data\n",
        "test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
        "print(f\"Test accuracy: {test_accuracy * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lLdxG9HnExev"
      },
      "source": [
        "## Graphing the output\n",
        "\n",
        "You can examine the output using the history object and graphing the results. This allows you to see if you're overfitting the model or if you have enough capacity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "9FmUHgmTEx2_",
        "outputId": "7bff74c6-15e7-439a-be9e-a553cbc15c93"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# Plot training & validation accuracy values\n",
        "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.title('Model Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hf9510W_8OJs"
      },
      "source": [
        "## Using model.add() to dynamically add layers\n",
        "\n",
        "Occassionally you'll want to add layers dynamically - in that case, it's better not to define a list and instead use tensorflow's \"model.add()\" function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LwRYwQEu70hQ"
      },
      "outputs": [],
      "source": [
        "# Build a neural network model layer-by-layer\n",
        "model = Sequential()\n",
        "model.add(Flatten(input_shape=(28, 28)))  # Flatten 28x28 images to a 784-element vector\n",
        "model.add(Dense(128, activation='relu'))  # Hidden layer with 128 neurons and ReLU activation\n",
        "model.add(Dense(10, activation='softmax'))  # Output layer with 10 neurons and softmax activation\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(x_train, y_train, epochs=5, batch_size=256, validation_data=(x_val, y_val))\n",
        "\n",
        "# Evaluate the model on test data\n",
        "test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
        "print(f\"Test accuracy: {test_accuracy * 100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x0MgwUX-8mlh"
      },
      "source": [
        "## Using Keras Tuner to tune the architecture\n",
        "\n",
        "The built in method for hyperparameter tuning is \"Keras Tuner\": https://keras.io/api/keras_tuner/hyperparameters/\n",
        "\n",
        "This method lets you choose a few different ways to tune your objects:\n",
        "\n",
        "\n",
        "\n",
        "*   HyperParameters.Boolean(name, default=False, parent_name=None, parent_values=None)\n",
        "      * Lets you use \"true or false\" as the search space\n",
        "*   HyperParameters.Choice(name, values, ordered=None, default=None,parent_name=None, parent_values=None)\n",
        "      * Select from a list of options\n",
        "*   HyperParameters.Float(name,min_value,max_value,step=None,sampling=\"linear\",default=None,parent_name=None,parent_values=None)\n",
        "      * Search for a floating point (value with a decimal point) number, given a specific sampling strategy\n",
        "*   HyperParameters.Int(name,min_value,max_value,step=None,sampling=\"linear\",default=None,parent_name=None, parent_values=None)\n",
        "      * Search for an integer number given a specific sampling strategy\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZCT4u41F8xSs",
        "outputId": "16e576e3-410d-40e3-a96f-7c847d504e88"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting keras-tuner\n",
            "  Downloading keras_tuner-1.4.7-py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (3.4.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (24.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (2.32.3)\n",
            "Collecting kt-legacy (from keras-tuner)\n",
            "  Downloading kt_legacy-1.0.5-py3-none-any.whl.metadata (221 bytes)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (1.26.4)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (3.12.1)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (0.13.0)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras->keras-tuner) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2024.8.30)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from optree->keras->keras-tuner) (4.12.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras->keras-tuner) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras->keras-tuner) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras->keras-tuner) (0.1.2)\n",
            "Downloading keras_tuner-1.4.7-py3-none-any.whl (129 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.1/129.1 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
            "Installing collected packages: kt-legacy, keras-tuner\n",
            "Successfully installed keras-tuner-1.4.7 kt-legacy-1.0.5\n"
          ]
        }
      ],
      "source": [
        "!pip install keras-tuner"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1F55KUWU-LAg"
      },
      "source": [
        "### Building the hyperparameter search space\n",
        "\n",
        "To define the search space, you need to create this \"build_model\" function. This is where you define the model, tell it what you want to tune, and add define how you want to search for those models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lqgnlxoR8oZc"
      },
      "outputs": [],
      "source": [
        "# Define the hypermodel\n",
        "def build_model(hp):\n",
        "    model = Sequential()\n",
        "    model.add(Flatten(input_shape=(28, 28)))\n",
        "\n",
        "    # Tune the number of layers\n",
        "    for i in range(hp.Int('num_layers', min_value=1, max_value=3)):  # Tuning 1-3 layers\n",
        "        # Tune the number of neurons in each layer\n",
        "        model.add(Dense(units=hp.Int(f'units_{i}', min_value=32, max_value=256, step=32),\n",
        "                        activation=hp.Choice(f'activation_{i}', ['relu', 'tanh', 'sigmoid'])))\n",
        "\n",
        "    # Output layer\n",
        "    model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(\n",
        "        optimizer='adam',\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "if-451RE_Jgm"
      },
      "source": [
        "## Selecting your tuning algorithm\n",
        "\n",
        "Keras tuner has multiple available tuners:\n",
        "\n",
        "\n",
        "\n",
        "1.   [**Random Search**](https://keras.io/api/keras_tuner/tuners/random/): Selects parameters at random.\n",
        "2.   [**Grid Search**](https://keras.io/api/keras_tuner/tuners/grid/): Searches all available parameters in the search space. Guaranteed to get the best answer, but could take way too long if you're searching a lot of parameters and a very large space\n",
        "3.   [**Bayesian Optimization**](https://keras.io/api/keras_tuner/tuners/bayesian/): Selects parameters by taking into account previous iterations of the algorithm and searching only in areas it knows it's been successful before. Faster than grid search, but can get stuck in local minima.\n",
        "4.   [**Hyperband Optimization**](https://keras.io/api/keras_tuner/tuners/hyperband/): Runs multiple sets of parameters at the same time, but continues training on only the most successful ones. Faster than bayesian and tends to be fairly good\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7_xw0Q6Q-Af3"
      },
      "outputs": [],
      "source": [
        "from keras_tuner import Hyperband\n",
        "\n",
        "# Initialize the Keras Tuner with Hyperband search\n",
        "tuner = Hyperband(\n",
        "    build_model,\n",
        "    objective='val_accuracy',\n",
        "    max_epochs=10,\n",
        "    factor=3,\n",
        "    directory='my_dir',\n",
        "    project_name='mnist_tuning'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i28jFfgeAvrD"
      },
      "source": [
        "## Search and selecting the best model\n",
        "\n",
        "You can then choose to search for the best hyperparamters. This can take a very long time, especially depending on which optimization algorithm you chose, how you set it up, and how large your search space is."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "BTjb_Dc88vgn",
        "outputId": "f7a2e655-99e8-4392-9708-233756671f30"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial 26 Complete [00h 00m 55s]\n",
            "val_accuracy: 0.9779166579246521\n",
            "\n",
            "Best val_accuracy So Far: 0.9824166893959045\n",
            "Total elapsed time: 00h 32m 21s\n",
            "\n",
            "Search: Running Trial #27\n",
            "\n",
            "Value             |Best Value So Far |Hyperparameter\n",
            "2                 |1                 |num_layers\n",
            "224               |224               |units_0\n",
            "relu              |relu              |activation_0\n",
            "224               |96                |units_1\n",
            "sigmoid           |sigmoid           |activation_1\n",
            "10                |4                 |tuner/epochs\n",
            "0                 |2                 |tuner/initial_epoch\n",
            "0                 |2                 |tuner/bracket\n",
            "0                 |1                 |tuner/round\n",
            "\n",
            "Epoch 1/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 6ms/step - accuracy: 0.8530 - loss: 0.5172 - val_accuracy: 0.9567 - val_loss: 0.1451\n",
            "Epoch 2/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 5ms/step - accuracy: 0.9673 - loss: 0.1111 - val_accuracy: 0.9703 - val_loss: 0.0986\n",
            "Epoch 3/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 7ms/step - accuracy: 0.9800 - loss: 0.0659 - val_accuracy: 0.9753 - val_loss: 0.0765\n",
            "Epoch 4/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.9863 - loss: 0.0434 - val_accuracy: 0.9743 - val_loss: 0.0852\n",
            "Epoch 5/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.9900 - loss: 0.0314 - val_accuracy: 0.9772 - val_loss: 0.0801\n",
            "Epoch 6/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.9921 - loss: 0.0257 - val_accuracy: 0.9747 - val_loss: 0.0881\n",
            "Epoch 7/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 7ms/step - accuracy: 0.9936 - loss: 0.0192 - val_accuracy: 0.9785 - val_loss: 0.0807\n",
            "Epoch 8/10\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 6ms/step - accuracy: 0.9961 - loss: 0.0130 - val_accuracy: 0.9749 - val_loss: 0.1029\n",
            "Epoch 9/10\n",
            "\u001b[1m 857/1500\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9969 - loss: 0.0110"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-66ece19e61be>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Perform the search\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtuner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Retrieve the best model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mbest_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_best_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_models\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/base_tuner.py\u001b[0m in \u001b[0;36msearch\u001b[0;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_trial_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_run_and_update_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_trial_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_search_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/base_tuner.py\u001b[0m in \u001b[0;36m_try_run_and_update_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    272\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_run_and_update_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_and_update_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m             \u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrial_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOMPLETED\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/base_tuner.py\u001b[0m in \u001b[0;36m_run_and_update_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_and_update_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m         if self.oracle.get_trial(trial.trial_id).metrics.exists(\n\u001b[1;32m    241\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moracle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras_tuner/src/tuners/hyperband.py\u001b[0m in \u001b[0;36mrun_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    425\u001b[0m             \u001b[0mfit_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"epochs\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tuner/epochs\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m             \u001b[0mfit_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"initial_epoch\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tuner/initial_epoch\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_build_hypermodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/tuner.py\u001b[0m in \u001b[0;36mrun_trial\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    312\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_checkpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m             \u001b[0mcopied_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"callbacks\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m             \u001b[0mobj_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_and_fit_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcopied_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m             \u001b[0mhistories\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/tuner.py\u001b[0m in \u001b[0;36m_build_and_fit_model\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[0mhp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhyperparameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhypermodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[0;31m# Save the build config for model loading later.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras_tuner/src/engine/hypermodel.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, hp, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m    147\u001b[0m             \u001b[0mIf\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0ma\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mit\u001b[0m \u001b[0mshould\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mthe\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \"\"\"\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    316\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menumerate_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pythonify_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    876\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m       results = tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    879\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1321\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1550\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1552\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1553\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1554\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Perform the search\n",
        "tuner.search(x_train, y_train, epochs=10, validation_data=(x_val, y_val))\n",
        "\n",
        "# Retrieve the best model\n",
        "best_model = tuner.get_best_models(num_models=1)[0]\n",
        "\n",
        "# Evaluate the best model\n",
        "test_loss, test_accuracy = best_model.evaluate(x_test, y_test)\n",
        "print(f\"Best model test accuracy: {test_accuracy * 100:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YvV1sdf_GTrN"
      },
      "source": [
        "# Pytorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JrKXefZ4x0zk"
      },
      "source": [
        "Pytorch loads its data a little differently - instead of directly inputting the data, we can use a \"DataLoader\" that will automatically batch, sample, and shuffle our data. In the below example, we've set the batch size to 64 and chosen to shuffle the training data, but not the test data since no training is being done and the order of the samples won't affect the results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SXovRSqeGUc9"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Define transformations for the MNIST dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))  # Normalize the images\n",
        "])\n",
        "\n",
        "# Load the MNIST dataset\n",
        "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XVzEL9k0MvnY"
      },
      "source": [
        "## Building the Architecture\n",
        "\n",
        "In pytorch, you create the architecture by extending from a basic nn.Module class. You can then define the initial architecture in the \"initialization\" section, then define the activations in the \"forward\" function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-GDd4MQ3MxKg"
      },
      "outputs": [],
      "source": [
        "# Define the neural network model\n",
        "class SimpleNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleNN, self).__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.fc1 = nn.Linear(28 * 28, 128)  # First hidden layer\n",
        "        self.fc2 = nn.Linear(128, 64)       # Second hidden layer\n",
        "        self.fc3 = nn.Linear(64, 10)        # Output layer\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = self.fc3(x)  # No activation here because CrossEntropyLoss expects raw logits\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJvOf86XM0AA"
      },
      "source": [
        "## Creating the model and defining the loss and optimization\n",
        "\n",
        "Just like before, once the architecture is set we can select the [loss function](https://pytorch.org/docs/stable/nn.html#loss-functions) and [optimizer](https://pytorch.org/docs/stable/optim.html) we want to use, as well as set the learning rate for that optimizer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U_EoDs5BMACM"
      },
      "outputs": [],
      "source": [
        "# Instantiate the model, define the loss function and the optimizer\n",
        "model = SimpleNN()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5uISd9e6NPtM"
      },
      "source": [
        "## Training the model - method 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3hGJ3nu3NQcK",
        "outputId": "fbb7e260-c69e-440d-8df8-b8370dcccf19"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5, Loss: 0.4039\n",
            "Epoch 2/5, Loss: 0.1980\n",
            "Epoch 3/5, Loss: 0.1468\n",
            "Epoch 4/5, Loss: 0.1175\n",
            "Epoch 5/5, Loss: 0.1005\n"
          ]
        }
      ],
      "source": [
        "# Training loop\n",
        "epochs = 5\n",
        "for epoch in range(epochs):\n",
        "    model.train()  # Set the model to training mode\n",
        "    running_loss = 0.0\n",
        "    for images, labels in train_loader:\n",
        "        optimizer.zero_grad()         # Zero the gradients\n",
        "        outputs = model(images)       # Forward pass\n",
        "        loss = criterion(outputs, labels)  # Calculate the loss\n",
        "        loss.backward()               # Backpropagation\n",
        "        optimizer.step()              # Update the weights\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(train_loader):.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QUu8p0mINc-L",
        "outputId": "59bb1363-68a9-44a5-e511-3eebdb10327a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy: 96.20%\n"
          ]
        }
      ],
      "source": [
        "# Evaluation loop\n",
        "model.eval()  # Set the model to evaluation mode\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():  # No need to track gradients during evaluation\n",
        "    for images, labels in test_loader:\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs, 1) # Creates predictions by selecting the output with the maximum softmax value\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "accuracy = 100 * correct / total\n",
        "print(f\"Test Accuracy: {accuracy:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWJrLlyF1bk6"
      },
      "source": [
        "### Training the model method 2 - creating test and training functions\n",
        "\n",
        "You can make the code a bit more modular by creating functions for the train and evaluation functions. This also makes the code a little easier to read."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T3a-y_Z71faL"
      },
      "outputs": [],
      "source": [
        "# Define training function\n",
        "def train(model, loader, criterion, optimizer):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for X_batch, y_batch in loader:\n",
        "        optimizer.zero_grad()               # Zero the gradients\n",
        "        outputs = model(X_batch)            # Forward pass\n",
        "        loss = criterion(outputs, y_batch)  # Calculate the loss\n",
        "        loss.backward()                     # Backpropagation\n",
        "        optimizer.step()                    # Update the weights\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predictions = torch.max(outputs, 1)            # Predict output\n",
        "        correct += (predictions == y_batch).sum().item()  # Calculate the number of correct outputs\n",
        "        total += y_batch.size(0)                          # Calculats the number of samples processed across all batches\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    avg_loss = running_loss / len(loader)\n",
        "    return avg_loss, accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zAyvuSqS2dEq"
      },
      "source": [
        "This might also make it a bit easier to add in other performance metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ehG4C-BS2jnj"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Define evaluation function\n",
        "def evaluate(model, loader):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "    with torch.no_grad(): # No need to track gradients during evaluation\n",
        "        for X_batch, y_batch in loader: # For each x and y in the loader\n",
        "            outputs = model(X_batch)    # forward pass to create outputs\n",
        "            _, predictions = torch.max(outputs, 1) # Make a prediction\n",
        "            y_true.extend(y_batch.tolist())  # Add the batch's true values to the y_true list\n",
        "            y_pred.extend(predictions.tolist()) # Add the predictions to the predictin list\n",
        "            correct += (predictions == y_batch).sum().item()  # Calculate the number of true values\n",
        "            total += y_batch.size(0)  # Sum up the total number of points in the batch\n",
        "\n",
        "    # You can then get the current epoch's training metrics using all of the true and predicted values\n",
        "    accuracy = 100 * correct / total\n",
        "    precision = precision_score(y_true, y_pred, average='weighted')\n",
        "    recall = recall_score(y_true, y_pred, average='weighted')\n",
        "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
        "    return accuracy, precision, recall, f1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7lvwV87s2mvc"
      },
      "source": [
        "Once you have your metrics, you can then perform the training and evaluation per epoch much easier."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vHWZoiKm2njy",
        "outputId": "ffd85bfe-cc8c-4af3-c9b7-43403f956bfa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5, Train Loss: 0.4062, Train Accuracy: 88.00%, Val Accuracy: 92.38%, Precision: 0.93, Recall: 0.92, F1: 0.92\n",
            "Epoch 2/5, Train Loss: 0.1968, Train Accuracy: 94.14%, Val Accuracy: 95.20%, Precision: 0.95, Recall: 0.95, F1: 0.95\n",
            "Epoch 3/5, Train Loss: 0.1435, Train Accuracy: 95.69%, Val Accuracy: 95.93%, Precision: 0.96, Recall: 0.96, F1: 0.96\n",
            "Epoch 4/5, Train Loss: 0.1175, Train Accuracy: 96.34%, Val Accuracy: 96.27%, Precision: 0.96, Recall: 0.96, F1: 0.96\n",
            "Epoch 5/5, Train Loss: 0.1000, Train Accuracy: 96.85%, Val Accuracy: 96.37%, Precision: 0.96, Recall: 0.96, F1: 0.96\n"
          ]
        }
      ],
      "source": [
        "# Track metrics\n",
        "train_losses = []\n",
        "train_accuracies = []\n",
        "val_accuracies = []\n",
        "\n",
        "# Training and evaluation loop\n",
        "epochs = 5\n",
        "for epoch in range(epochs):\n",
        "    train_loss, train_accuracy = train(model, train_loader, criterion, optimizer)\n",
        "    val_accuracy, val_precision, val_recall, val_f1 = evaluate(model, test_loader)\n",
        "\n",
        "    # Append this epoch's losses and accuracies to the list\n",
        "    train_losses.append(train_loss)\n",
        "    train_accuracies.append(train_accuracy)\n",
        "    val_accuracies.append(val_accuracy)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{epochs}, \"\n",
        "          f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%, \"\n",
        "          f\"Val Accuracy: {val_accuracy:.2f}%, \"\n",
        "          f\"Precision: {val_precision:.2f}, Recall: {val_recall:.2f}, F1: {val_f1:.2f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_MHurol272E"
      },
      "source": [
        "## Plotting the training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "9URVd7Us3Ebk",
        "outputId": "a69f7b5a-a8d4-4140-d703-86f4a737a73a"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Plot training and validation accuracy over epochs\n",
        "plt.plot(train_accuracies, label='Train Accuracy')\n",
        "plt.plot(val_accuracies, label='Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Accuracy over Epochs')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-2sF2gCNyfJc"
      },
      "source": [
        "## Using tabular data\n",
        "\n",
        "Just as an extra - for tabular data, the process is largely the same, you just have to ensure that you're converting your data into tensors prior to creating the data loaders. Also the output here is a sigmoid activation for binary classification, not softmax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uh137tmQNooT"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Generate a synthetic dataset\n",
        "X, y = make_classification(n_samples=1000, n_features=20, n_classes=2, random_state=42)\n",
        "\n",
        "# Split into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Convert to PyTorch tensors\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
        "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
        "\n",
        "# Create DataLoader for training and testing\n",
        "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# Define a simple feedforward neural network for tabular data\n",
        "class TabularNN(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(TabularNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, 64)\n",
        "        self.fc2 = nn.Linear(64, 32)\n",
        "        self.fc3 = nn.Linear(32, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = torch.sigmoid(self.fc3(x))\n",
        "        return x\n",
        "\n",
        "# Instantiate the model, define loss function and optimizer\n",
        "model = TabularNN(input_dim=X_train.shape[1])\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Define training function\n",
        "def train(model, loader, criterion, optimizer):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for X_batch, y_batch in loader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(X_batch).squeeze()          # Forward pass\n",
        "        loss = criterion(outputs, y_batch.float())  # Calculate the loss\n",
        "        loss.backward()                             # Backprop\n",
        "        optimizer.step()                            # Update the gradients\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        predictions = (outputs > 0.5).long()\n",
        "        correct += (predictions == y_batch).sum().item()\n",
        "        total += y_batch.size(0)\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    avg_loss = running_loss / len(loader)\n",
        "    return avg_loss, accuracy\n",
        "\n",
        "# Define evaluation function\n",
        "def evaluate(model, loader):\n",
        "    model.eval()                                    # Set to evaluation mode\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "    with torch.no_grad():                           # Do not update gradients\n",
        "        for X_batch, y_batch in loader:\n",
        "            outputs = model(X_batch).squeeze()      # Calculate outputs\n",
        "            predictions = (outputs > 0.5).long()    # Convert to predictions\n",
        "            y_true.extend(y_batch.tolist())\n",
        "            y_pred.extend(predictions.tolist())\n",
        "            correct += (predictions == y_batch).sum().item()\n",
        "            total += y_batch.size(0)\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    precision = precision_score(y_true, y_pred)\n",
        "    recall = recall_score(y_true, y_pred)\n",
        "    f1 = f1_score(y_true, y_pred)\n",
        "    return accuracy, precision, recall, f1\n",
        "\n",
        "# Track training and validation metrics\n",
        "train_losses = []\n",
        "train_accuracies = []\n",
        "val_accuracies = []\n",
        "\n",
        "# Training and evaluation loop\n",
        "epochs = 20\n",
        "for epoch in range(epochs):\n",
        "    train_loss, train_accuracy = train(model, train_loader, criterion, optimizer)\n",
        "    val_accuracy, val_precision, val_recall, val_f1 = evaluate(model, test_loader)\n",
        "\n",
        "    train_losses.append(train_loss)\n",
        "    train_accuracies.append(train_accuracy)\n",
        "    val_accuracies.append(val_accuracy)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{epochs}, \"\n",
        "          f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%, \"\n",
        "          f\"Val Accuracy: {val_accuracy:.2f}%, \"\n",
        "          f\"Precision: {val_precision:.2f}, Recall: {val_recall:.2f}, F1: {val_f1:.2f}\")\n",
        "\n",
        "# Plot training and validation accuracy over epochs\n",
        "plt.plot(train_accuracies, label='Train Accuracy')\n",
        "plt.plot(val_accuracies, label='Validation Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Accuracy over Epochs')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Plot training loss over epochs\n",
        "plt.plot(train_losses, label='Train Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Training Loss over Epochs')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l4-FQ-tofsGU"
      },
      "source": [
        "## Hyperparameter Tuning with Ray Tune\n",
        "\n",
        "There's a few different methods for performing hyperparameter tuning on pytorch models. [Ray Tune](https://pytorch.org/tutorials/beginner/hyperparameter_tuning_tutorial.html) seems to be one the developers recommend"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_qIzwEYgikJ",
        "outputId": "4e261adf-4b8c-4bad-d1eb-55a196b54f3f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting ray\n",
            "  Downloading ray-2.39.0-cp310-cp310-manylinux2014_x86_64.whl.metadata (17 kB)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from ray) (8.1.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from ray) (3.16.1)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.10/dist-packages (from ray) (4.23.0)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ray) (1.1.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from ray) (24.2)\n",
            "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /usr/local/lib/python3.10/dist-packages (from ray) (4.25.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from ray) (6.0.2)\n",
            "Requirement already satisfied: aiosignal in /usr/local/lib/python3.10/dist-packages (from ray) (1.3.1)\n",
            "Requirement already satisfied: frozenlist in /usr/local/lib/python3.10/dist-packages (from ray) (1.5.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from ray) (2.32.3)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray) (24.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray) (0.21.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->ray) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->ray) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->ray) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->ray) (2024.8.30)\n",
            "Downloading ray-2.39.0-cp310-cp310-manylinux2014_x86_64.whl (66.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.3/66.3 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ray\n",
            "Successfully installed ray-2.39.0\n"
          ]
        }
      ],
      "source": [
        "!pip install ray"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "WT_K2xYofthe",
        "outputId": "deb42ca6-ad65-4475-bb77-b9411805a037"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 17.9MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 574kB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 4.27MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 2.22MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-11-13 17:12:20,684\tINFO worker.py:1819 -- Started a local Ray instance.\n",
            "2024-11-13 17:12:22,432\tINFO tune.py:253 -- Initializing Ray automatically. For cluster usage or custom Ray initialization, call `ray.init(...)` before `tune.run(...)`.\n",
            "2024-11-13 17:12:23,425\tINFO tensorboardx.py:193 -- pip install \"ray[tune]\" to see TensorBoard files.\n",
            "2024-11-13 17:12:23,427\tWARNING callback.py:136 -- The TensorboardX logger cannot be instantiated because either TensorboardX or one of it's dependencies is not installed. Please make sure you have the latest version of TensorboardX installed: `pip install -U tensorboardx`\n",
            "2024-11-13 17:12:23,434\tWARNING tune.py:902 -- AIR_VERBOSITY is set, ignoring passed-in ProgressReporter for now.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------------------------------------------------------+\n",
            "| Configuration for experiment     train_mnist_2024-11-13_17-12-23   |\n",
            "+--------------------------------------------------------------------+\n",
            "| Search algorithm                 BasicVariantGenerator             |\n",
            "| Scheduler                        AsyncHyperBandScheduler           |\n",
            "| Number of trials                 20                                |\n",
            "+--------------------------------------------------------------------+\n",
            "\n",
            "View detailed results here: /root/ray_results/train_mnist_2024-11-13_17-12-23\n",
            "\u001b[33m(raylet)\u001b[0m Warning: The actor ImplicitFunc is very large (91 MiB). Check that its definition is not implicitly capturing a large array or other object in scope. Tip: use ray.put() to put large objects in the Ray object store.\n",
            "\n",
            "Trial status: 20 PENDING\n",
            "Current time: 2024-11-13 17:12:47. Total running time: 23s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/0 GPUs\n",
            "+------------------------------------------------------------------------------------------+\n",
            "| Trial name                status              lr     batch_size     n_layers     n_units |\n",
            "+------------------------------------------------------------------------------------------+\n",
            "| train_mnist_72e7b_00000   PENDING    0.000105659             64            2         128 |\n",
            "| train_mnist_72e7b_00001   PENDING    0.00118331              64            3         128 |\n",
            "| train_mnist_72e7b_00002   PENDING    5.91159e-05            128            2          32 |\n",
            "| train_mnist_72e7b_00003   PENDING    0.00611151              32            2         128 |\n",
            "| train_mnist_72e7b_00004   PENDING    0.00223458             128            2          32 |\n",
            "| train_mnist_72e7b_00005   PENDING    0.00289927             128            3          32 |\n",
            "| train_mnist_72e7b_00006   PENDING    0.0008884               32            1          64 |\n",
            "| train_mnist_72e7b_00007   PENDING    0.000242121            128            1          32 |\n",
            "| train_mnist_72e7b_00008   PENDING    0.00366188              64            3          32 |\n",
            "| train_mnist_72e7b_00009   PENDING    8.52954e-05             32            3          32 |\n",
            "| train_mnist_72e7b_00010   PENDING    0.00280513              32            2         128 |\n",
            "| train_mnist_72e7b_00011   PENDING    1.78921e-05             64            3         128 |\n",
            "| train_mnist_72e7b_00012   PENDING    2.09159e-05             32            1          64 |\n",
            "| train_mnist_72e7b_00013   PENDING    3.86109e-05             32            3         128 |\n",
            "| train_mnist_72e7b_00014   PENDING    0.000190781             64            2          64 |\n",
            "| train_mnist_72e7b_00015   PENDING    0.000135533            128            3         128 |\n",
            "| train_mnist_72e7b_00016   PENDING    0.000180571             32            3         128 |\n",
            "| train_mnist_72e7b_00017   PENDING    0.0004525               64            3         128 |\n",
            "| train_mnist_72e7b_00018   PENDING    5.73823e-05             32            3          32 |\n",
            "| train_mnist_72e7b_00019   PENDING    0.000175165            128            1          64 |\n",
            "+------------------------------------------------------------------------------------------+\n",
            "\n",
            "Trial train_mnist_72e7b_00000 started with configuration:\n",
            "+--------------------------------------------------+\n",
            "| Trial train_mnist_72e7b_00000 config             |\n",
            "+--------------------------------------------------+\n",
            "| batch_size                                    64 |\n",
            "| lr                                       0.00011 |\n",
            "| n_layers                                       2 |\n",
            "| n_units                                      128 |\n",
            "+--------------------------------------------------+\n",
            "\n",
            "Trial train_mnist_72e7b_00001 started with configuration:\n",
            "+--------------------------------------------------+\n",
            "| Trial train_mnist_72e7b_00001 config             |\n",
            "+--------------------------------------------------+\n",
            "| batch_size                                    64 |\n",
            "| lr                                       0.00118 |\n",
            "| n_layers                                       3 |\n",
            "| n_units                                      128 |\n",
            "+--------------------------------------------------+\n",
            "\n",
            "Trial status: 2 RUNNING | 18 PENDING\n",
            "Current time: 2024-11-13 17:13:17. Total running time: 53s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/0 GPUs\n",
            "+------------------------------------------------------------------------------------------+\n",
            "| Trial name                status              lr     batch_size     n_layers     n_units |\n",
            "+------------------------------------------------------------------------------------------+\n",
            "| train_mnist_72e7b_00000   RUNNING    0.000105659             64            2         128 |\n",
            "| train_mnist_72e7b_00001   RUNNING    0.00118331              64            3         128 |\n",
            "| train_mnist_72e7b_00002   PENDING    5.91159e-05            128            2          32 |\n",
            "| train_mnist_72e7b_00003   PENDING    0.00611151              32            2         128 |\n",
            "| train_mnist_72e7b_00004   PENDING    0.00223458             128            2          32 |\n",
            "| train_mnist_72e7b_00005   PENDING    0.00289927             128            3          32 |\n",
            "| train_mnist_72e7b_00006   PENDING    0.0008884               32            1          64 |\n",
            "| train_mnist_72e7b_00007   PENDING    0.000242121            128            1          32 |\n",
            "| train_mnist_72e7b_00008   PENDING    0.00366188              64            3          32 |\n",
            "| train_mnist_72e7b_00009   PENDING    8.52954e-05             32            3          32 |\n",
            "| train_mnist_72e7b_00010   PENDING    0.00280513              32            2         128 |\n",
            "| train_mnist_72e7b_00011   PENDING    1.78921e-05             64            3         128 |\n",
            "| train_mnist_72e7b_00012   PENDING    2.09159e-05             32            1          64 |\n",
            "| train_mnist_72e7b_00013   PENDING    3.86109e-05             32            3         128 |\n",
            "| train_mnist_72e7b_00014   PENDING    0.000190781             64            2          64 |\n",
            "| train_mnist_72e7b_00015   PENDING    0.000135533            128            3         128 |\n",
            "| train_mnist_72e7b_00016   PENDING    0.000180571             32            3         128 |\n",
            "| train_mnist_72e7b_00017   PENDING    0.0004525               64            3         128 |\n",
            "| train_mnist_72e7b_00018   PENDING    5.73823e-05             32            3          32 |\n",
            "| train_mnist_72e7b_00019   PENDING    0.000175165            128            1          64 |\n",
            "+------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-11-13 17:13:39,497\tERROR tune_controller.py:1331 -- Trial task failed for trial train_mnist_72e7b_00000\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
            "    result = ray.get(future)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2753, in get\n",
            "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 904, in get_objects\n",
            "    raise value.as_instanceof_cause()\n",
            "ray.exceptions.RayTaskError(AttributeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=1520, ip=172.28.0.12, actor_id=def06d423d3cc469849b045a01000000, repr=train_mnist)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/trainable.py\", line 331, in train\n",
            "    raise skipped from exception_cause(skipped)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/air/_internal/util.py\", line 104, in run\n",
            "    self._ret = self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/function_trainable.py\", line 45, in <lambda>\n",
            "    training_func=lambda: self._trainable_func(self.config),\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/function_trainable.py\", line 250, in _trainable_func\n",
            "    output = fn()\n",
            "  File \"<ipython-input-3-8222499238c3>\", line 78, in train_mnist\n",
            "AttributeError: module 'ray.tune' has no attribute 'report'\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Trial train_mnist_72e7b_00000 errored after 0 iterations at 2024-11-13 17:13:39. Total running time: 1min 16s\n",
            "Error file: /tmp/ray/session_2024-11-13_17-12-15_277287_683/artifacts/2024-11-13_17-12-23/train_mnist_2024-11-13_17-12-23/driver_artifacts/train_mnist_72e7b_00000_0_batch_size=64,lr=0.0001,n_layers=2,n_units=128_2024-11-13_17-12-35/error.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-11-13 17:13:40,740\tERROR tune_controller.py:1331 -- Trial task failed for trial train_mnist_72e7b_00001\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
            "    result = ray.get(future)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2753, in get\n",
            "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 904, in get_objects\n",
            "    raise value.as_instanceof_cause()\n",
            "ray.exceptions.RayTaskError(AttributeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=1519, ip=172.28.0.12, actor_id=50bcd4b8854d80ea5dec5f5401000000, repr=train_mnist)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/trainable.py\", line 331, in train\n",
            "    raise skipped from exception_cause(skipped)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/air/_internal/util.py\", line 104, in run\n",
            "    self._ret = self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/function_trainable.py\", line 45, in <lambda>\n",
            "    training_func=lambda: self._trainable_func(self.config),\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/function_trainable.py\", line 250, in _trainable_func\n",
            "    output = fn()\n",
            "  File \"<ipython-input-3-8222499238c3>\", line 78, in train_mnist\n",
            "AttributeError: module 'ray.tune' has no attribute 'report'\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Trial train_mnist_72e7b_00001 errored after 0 iterations at 2024-11-13 17:13:40. Total running time: 1min 17s\n",
            "Error file: /tmp/ray/session_2024-11-13_17-12-15_277287_683/artifacts/2024-11-13_17-12-23/train_mnist_2024-11-13_17-12-23/driver_artifacts/train_mnist_72e7b_00001_1_batch_size=64,lr=0.0012,n_layers=3,n_units=128_2024-11-13_17-12-36/error.txt\n",
            "\n",
            "Trial status: 2 ERROR | 18 PENDING\n",
            "Current time: 2024-11-13 17:13:47. Total running time: 1min 23s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/0 GPUs\n",
            "+------------------------------------------------------------------------------------------+\n",
            "| Trial name                status              lr     batch_size     n_layers     n_units |\n",
            "+------------------------------------------------------------------------------------------+\n",
            "| train_mnist_72e7b_00002   PENDING    5.91159e-05            128            2          32 |\n",
            "| train_mnist_72e7b_00003   PENDING    0.00611151              32            2         128 |\n",
            "| train_mnist_72e7b_00004   PENDING    0.00223458             128            2          32 |\n",
            "| train_mnist_72e7b_00005   PENDING    0.00289927             128            3          32 |\n",
            "| train_mnist_72e7b_00006   PENDING    0.0008884               32            1          64 |\n",
            "| train_mnist_72e7b_00007   PENDING    0.000242121            128            1          32 |\n",
            "| train_mnist_72e7b_00008   PENDING    0.00366188              64            3          32 |\n",
            "| train_mnist_72e7b_00009   PENDING    8.52954e-05             32            3          32 |\n",
            "| train_mnist_72e7b_00010   PENDING    0.00280513              32            2         128 |\n",
            "| train_mnist_72e7b_00011   PENDING    1.78921e-05             64            3         128 |\n",
            "| train_mnist_72e7b_00012   PENDING    2.09159e-05             32            1          64 |\n",
            "| train_mnist_72e7b_00013   PENDING    3.86109e-05             32            3         128 |\n",
            "| train_mnist_72e7b_00014   PENDING    0.000190781             64            2          64 |\n",
            "| train_mnist_72e7b_00015   PENDING    0.000135533            128            3         128 |\n",
            "| train_mnist_72e7b_00016   PENDING    0.000180571             32            3         128 |\n",
            "| train_mnist_72e7b_00017   PENDING    0.0004525               64            3         128 |\n",
            "| train_mnist_72e7b_00018   PENDING    5.73823e-05             32            3          32 |\n",
            "| train_mnist_72e7b_00019   PENDING    0.000175165            128            1          64 |\n",
            "| train_mnist_72e7b_00000   ERROR      0.000105659             64            2         128 |\n",
            "| train_mnist_72e7b_00001   ERROR      0.00118331              64            3         128 |\n",
            "+------------------------------------------------------------------------------------------+\n",
            "\n",
            "Trial train_mnist_72e7b_00002 started with configuration:\n",
            "+------------------------------------------------+\n",
            "| Trial train_mnist_72e7b_00002 config           |\n",
            "+------------------------------------------------+\n",
            "| batch_size                                 128 |\n",
            "| lr                                       6e-05 |\n",
            "| n_layers                                     2 |\n",
            "| n_units                                     32 |\n",
            "+------------------------------------------------+\n",
            "\n",
            "Trial train_mnist_72e7b_00003 started with configuration:\n",
            "+--------------------------------------------------+\n",
            "| Trial train_mnist_72e7b_00003 config             |\n",
            "+--------------------------------------------------+\n",
            "| batch_size                                    32 |\n",
            "| lr                                       0.00611 |\n",
            "| n_layers                                       2 |\n",
            "| n_units                                      128 |\n",
            "+--------------------------------------------------+\n",
            "\n",
            "Trial status: 2 ERROR | 2 RUNNING | 16 PENDING\n",
            "Current time: 2024-11-13 17:14:17. Total running time: 1min 53s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/0 GPUs\n",
            "+------------------------------------------------------------------------------------------+\n",
            "| Trial name                status              lr     batch_size     n_layers     n_units |\n",
            "+------------------------------------------------------------------------------------------+\n",
            "| train_mnist_72e7b_00002   RUNNING    5.91159e-05            128            2          32 |\n",
            "| train_mnist_72e7b_00003   RUNNING    0.00611151              32            2         128 |\n",
            "| train_mnist_72e7b_00004   PENDING    0.00223458             128            2          32 |\n",
            "| train_mnist_72e7b_00005   PENDING    0.00289927             128            3          32 |\n",
            "| train_mnist_72e7b_00006   PENDING    0.0008884               32            1          64 |\n",
            "| train_mnist_72e7b_00007   PENDING    0.000242121            128            1          32 |\n",
            "| train_mnist_72e7b_00008   PENDING    0.00366188              64            3          32 |\n",
            "| train_mnist_72e7b_00009   PENDING    8.52954e-05             32            3          32 |\n",
            "| train_mnist_72e7b_00010   PENDING    0.00280513              32            2         128 |\n",
            "| train_mnist_72e7b_00011   PENDING    1.78921e-05             64            3         128 |\n",
            "| train_mnist_72e7b_00012   PENDING    2.09159e-05             32            1          64 |\n",
            "| train_mnist_72e7b_00013   PENDING    3.86109e-05             32            3         128 |\n",
            "| train_mnist_72e7b_00014   PENDING    0.000190781             64            2          64 |\n",
            "| train_mnist_72e7b_00015   PENDING    0.000135533            128            3         128 |\n",
            "| train_mnist_72e7b_00016   PENDING    0.000180571             32            3         128 |\n",
            "| train_mnist_72e7b_00017   PENDING    0.0004525               64            3         128 |\n",
            "| train_mnist_72e7b_00018   PENDING    5.73823e-05             32            3          32 |\n",
            "| train_mnist_72e7b_00019   PENDING    0.000175165            128            1          64 |\n",
            "| train_mnist_72e7b_00000   ERROR      0.000105659             64            2         128 |\n",
            "| train_mnist_72e7b_00001   ERROR      0.00118331              64            3         128 |\n",
            "+------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-11-13 17:14:24,271\tERROR tune_controller.py:1331 -- Trial task failed for trial train_mnist_72e7b_00002\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
            "    result = ray.get(future)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2753, in get\n",
            "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 904, in get_objects\n",
            "    raise value.as_instanceof_cause()\n",
            "ray.exceptions.RayTaskError(AttributeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=1854, ip=172.28.0.12, actor_id=aad8d3776aaa1515e09b304c01000000, repr=train_mnist)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/trainable.py\", line 331, in train\n",
            "    raise skipped from exception_cause(skipped)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/air/_internal/util.py\", line 104, in run\n",
            "    self._ret = self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/function_trainable.py\", line 45, in <lambda>\n",
            "    training_func=lambda: self._trainable_func(self.config),\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/function_trainable.py\", line 250, in _trainable_func\n",
            "    output = fn()\n",
            "  File \"<ipython-input-3-8222499238c3>\", line 78, in train_mnist\n",
            "AttributeError: module 'ray.tune' has no attribute 'report'\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Trial train_mnist_72e7b_00002 errored after 0 iterations at 2024-11-13 17:14:24. Total running time: 2min 0s\n",
            "Error file: /tmp/ray/session_2024-11-13_17-12-15_277287_683/artifacts/2024-11-13_17-12-23/train_mnist_2024-11-13_17-12-23/driver_artifacts/train_mnist_72e7b_00002_2_batch_size=128,lr=0.0001,n_layers=2,n_units=32_2024-11-13_17-12-36/error.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-11-13 17:14:36,665\tERROR tune_controller.py:1331 -- Trial task failed for trial train_mnist_72e7b_00003\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
            "    result = ray.get(future)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2753, in get\n",
            "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 904, in get_objects\n",
            "    raise value.as_instanceof_cause()\n",
            "ray.exceptions.RayTaskError(AttributeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=1859, ip=172.28.0.12, actor_id=ffc8017d883618a2aa9eb1fe01000000, repr=train_mnist)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/trainable.py\", line 331, in train\n",
            "    raise skipped from exception_cause(skipped)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/air/_internal/util.py\", line 104, in run\n",
            "    self._ret = self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/function_trainable.py\", line 45, in <lambda>\n",
            "    training_func=lambda: self._trainable_func(self.config),\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/function_trainable.py\", line 250, in _trainable_func\n",
            "    output = fn()\n",
            "  File \"<ipython-input-3-8222499238c3>\", line 78, in train_mnist\n",
            "AttributeError: module 'ray.tune' has no attribute 'report'\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Trial train_mnist_72e7b_00003 errored after 0 iterations at 2024-11-13 17:14:36. Total running time: 2min 13s\n",
            "Error file: /tmp/ray/session_2024-11-13_17-12-15_277287_683/artifacts/2024-11-13_17-12-23/train_mnist_2024-11-13_17-12-23/driver_artifacts/train_mnist_72e7b_00003_3_batch_size=32,lr=0.0061,n_layers=2,n_units=128_2024-11-13_17-12-37/error.txt\n",
            "\n",
            "Trial train_mnist_72e7b_00004 started with configuration:\n",
            "+--------------------------------------------------+\n",
            "| Trial train_mnist_72e7b_00004 config             |\n",
            "+--------------------------------------------------+\n",
            "| batch_size                                   128 |\n",
            "| lr                                       0.00223 |\n",
            "| n_layers                                       2 |\n",
            "| n_units                                       32 |\n",
            "+--------------------------------------------------+\n",
            "\n",
            "Trial status: 4 ERROR | 1 RUNNING | 15 PENDING\n",
            "Current time: 2024-11-13 17:14:47. Total running time: 2min 23s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/0 GPUs\n",
            "+------------------------------------------------------------------------------------------+\n",
            "| Trial name                status              lr     batch_size     n_layers     n_units |\n",
            "+------------------------------------------------------------------------------------------+\n",
            "| train_mnist_72e7b_00004   RUNNING    0.00223458             128            2          32 |\n",
            "| train_mnist_72e7b_00005   PENDING    0.00289927             128            3          32 |\n",
            "| train_mnist_72e7b_00006   PENDING    0.0008884               32            1          64 |\n",
            "| train_mnist_72e7b_00007   PENDING    0.000242121            128            1          32 |\n",
            "| train_mnist_72e7b_00008   PENDING    0.00366188              64            3          32 |\n",
            "| train_mnist_72e7b_00009   PENDING    8.52954e-05             32            3          32 |\n",
            "| train_mnist_72e7b_00010   PENDING    0.00280513              32            2         128 |\n",
            "| train_mnist_72e7b_00011   PENDING    1.78921e-05             64            3         128 |\n",
            "| train_mnist_72e7b_00012   PENDING    2.09159e-05             32            1          64 |\n",
            "| train_mnist_72e7b_00013   PENDING    3.86109e-05             32            3         128 |\n",
            "| train_mnist_72e7b_00014   PENDING    0.000190781             64            2          64 |\n",
            "| train_mnist_72e7b_00015   PENDING    0.000135533            128            3         128 |\n",
            "| train_mnist_72e7b_00016   PENDING    0.000180571             32            3         128 |\n",
            "| train_mnist_72e7b_00017   PENDING    0.0004525               64            3         128 |\n",
            "| train_mnist_72e7b_00018   PENDING    5.73823e-05             32            3          32 |\n",
            "| train_mnist_72e7b_00019   PENDING    0.000175165            128            1          64 |\n",
            "| train_mnist_72e7b_00000   ERROR      0.000105659             64            2         128 |\n",
            "| train_mnist_72e7b_00001   ERROR      0.00118331              64            3         128 |\n",
            "| train_mnist_72e7b_00002   ERROR      5.91159e-05            128            2          32 |\n",
            "| train_mnist_72e7b_00003   ERROR      0.00611151              32            2         128 |\n",
            "+------------------------------------------------------------------------------------------+\n",
            "\n",
            "Trial train_mnist_72e7b_00005 started with configuration:\n",
            "+-------------------------------------------------+\n",
            "| Trial train_mnist_72e7b_00005 config            |\n",
            "+-------------------------------------------------+\n",
            "| batch_size                                  128 |\n",
            "| lr                                       0.0029 |\n",
            "| n_layers                                      3 |\n",
            "| n_units                                      32 |\n",
            "+-------------------------------------------------+\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-11-13 17:15:11,154\tERROR tune_controller.py:1331 -- Trial task failed for trial train_mnist_72e7b_00004\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
            "    result = ray.get(future)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2753, in get\n",
            "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 904, in get_objects\n",
            "    raise value.as_instanceof_cause()\n",
            "ray.exceptions.RayTaskError(AttributeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=2134, ip=172.28.0.12, actor_id=85974033bea0ba58f4a756b001000000, repr=train_mnist)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/trainable.py\", line 331, in train\n",
            "    raise skipped from exception_cause(skipped)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/air/_internal/util.py\", line 104, in run\n",
            "    self._ret = self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/function_trainable.py\", line 45, in <lambda>\n",
            "    training_func=lambda: self._trainable_func(self.config),\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/function_trainable.py\", line 250, in _trainable_func\n",
            "    output = fn()\n",
            "  File \"<ipython-input-3-8222499238c3>\", line 78, in train_mnist\n",
            "AttributeError: module 'ray.tune' has no attribute 'report'\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Trial train_mnist_72e7b_00004 errored after 0 iterations at 2024-11-13 17:15:11. Total running time: 2min 47s\n",
            "Error file: /tmp/ray/session_2024-11-13_17-12-15_277287_683/artifacts/2024-11-13_17-12-23/train_mnist_2024-11-13_17-12-23/driver_artifacts/train_mnist_72e7b_00004_4_batch_size=128,lr=0.0022,n_layers=2,n_units=32_2024-11-13_17-12-37/error.txt\n",
            "\n",
            "Trial status: 5 ERROR | 1 RUNNING | 14 PENDING\n",
            "Current time: 2024-11-13 17:15:17. Total running time: 2min 53s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/0 GPUs\n",
            "+------------------------------------------------------------------------------------------+\n",
            "| Trial name                status              lr     batch_size     n_layers     n_units |\n",
            "+------------------------------------------------------------------------------------------+\n",
            "| train_mnist_72e7b_00005   RUNNING    0.00289927             128            3          32 |\n",
            "| train_mnist_72e7b_00006   PENDING    0.0008884               32            1          64 |\n",
            "| train_mnist_72e7b_00007   PENDING    0.000242121            128            1          32 |\n",
            "| train_mnist_72e7b_00008   PENDING    0.00366188              64            3          32 |\n",
            "| train_mnist_72e7b_00009   PENDING    8.52954e-05             32            3          32 |\n",
            "| train_mnist_72e7b_00010   PENDING    0.00280513              32            2         128 |\n",
            "| train_mnist_72e7b_00011   PENDING    1.78921e-05             64            3         128 |\n",
            "| train_mnist_72e7b_00012   PENDING    2.09159e-05             32            1          64 |\n",
            "| train_mnist_72e7b_00013   PENDING    3.86109e-05             32            3         128 |\n",
            "| train_mnist_72e7b_00014   PENDING    0.000190781             64            2          64 |\n",
            "| train_mnist_72e7b_00015   PENDING    0.000135533            128            3         128 |\n",
            "| train_mnist_72e7b_00016   PENDING    0.000180571             32            3         128 |\n",
            "| train_mnist_72e7b_00017   PENDING    0.0004525               64            3         128 |\n",
            "| train_mnist_72e7b_00018   PENDING    5.73823e-05             32            3          32 |\n",
            "| train_mnist_72e7b_00019   PENDING    0.000175165            128            1          64 |\n",
            "| train_mnist_72e7b_00000   ERROR      0.000105659             64            2         128 |\n",
            "| train_mnist_72e7b_00001   ERROR      0.00118331              64            3         128 |\n",
            "| train_mnist_72e7b_00002   ERROR      5.91159e-05            128            2          32 |\n",
            "| train_mnist_72e7b_00003   ERROR      0.00611151              32            2         128 |\n",
            "| train_mnist_72e7b_00004   ERROR      0.00223458             128            2          32 |\n",
            "+------------------------------------------------------------------------------------------+\n",
            "\n",
            "Trial train_mnist_72e7b_00006 started with configuration:\n",
            "+--------------------------------------------------+\n",
            "| Trial train_mnist_72e7b_00006 config             |\n",
            "+--------------------------------------------------+\n",
            "| batch_size                                    32 |\n",
            "| lr                                       0.00089 |\n",
            "| n_layers                                       1 |\n",
            "| n_units                                       64 |\n",
            "+--------------------------------------------------+\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-11-13 17:15:24,793\tERROR tune_controller.py:1331 -- Trial task failed for trial train_mnist_72e7b_00005\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
            "    result = ray.get(future)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2753, in get\n",
            "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 904, in get_objects\n",
            "    raise value.as_instanceof_cause()\n",
            "ray.exceptions.RayTaskError(AttributeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=2253, ip=172.28.0.12, actor_id=6452d141a8a4f52f3230c9df01000000, repr=train_mnist)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/trainable.py\", line 331, in train\n",
            "    raise skipped from exception_cause(skipped)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/air/_internal/util.py\", line 104, in run\n",
            "    self._ret = self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/function_trainable.py\", line 45, in <lambda>\n",
            "    training_func=lambda: self._trainable_func(self.config),\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/function_trainable.py\", line 250, in _trainable_func\n",
            "    output = fn()\n",
            "  File \"<ipython-input-3-8222499238c3>\", line 78, in train_mnist\n",
            "AttributeError: module 'ray.tune' has no attribute 'report'\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Trial train_mnist_72e7b_00005 errored after 0 iterations at 2024-11-13 17:15:24. Total running time: 3min 1s\n",
            "Error file: /tmp/ray/session_2024-11-13_17-12-15_277287_683/artifacts/2024-11-13_17-12-23/train_mnist_2024-11-13_17-12-23/driver_artifacts/train_mnist_72e7b_00005_5_batch_size=128,lr=0.0029,n_layers=3,n_units=32_2024-11-13_17-12-38/error.txt\n",
            "\n",
            "Trial train_mnist_72e7b_00007 started with configuration:\n",
            "+--------------------------------------------------+\n",
            "| Trial train_mnist_72e7b_00007 config             |\n",
            "+--------------------------------------------------+\n",
            "| batch_size                                   128 |\n",
            "| lr                                       0.00024 |\n",
            "| n_layers                                       1 |\n",
            "| n_units                                       32 |\n",
            "+--------------------------------------------------+\n",
            "\n",
            "Trial status: 6 ERROR | 2 RUNNING | 12 PENDING\n",
            "Current time: 2024-11-13 17:15:47. Total running time: 3min 23s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/0 GPUs\n",
            "+------------------------------------------------------------------------------------------+\n",
            "| Trial name                status              lr     batch_size     n_layers     n_units |\n",
            "+------------------------------------------------------------------------------------------+\n",
            "| train_mnist_72e7b_00006   RUNNING    0.0008884               32            1          64 |\n",
            "| train_mnist_72e7b_00007   RUNNING    0.000242121            128            1          32 |\n",
            "| train_mnist_72e7b_00008   PENDING    0.00366188              64            3          32 |\n",
            "| train_mnist_72e7b_00009   PENDING    8.52954e-05             32            3          32 |\n",
            "| train_mnist_72e7b_00010   PENDING    0.00280513              32            2         128 |\n",
            "| train_mnist_72e7b_00011   PENDING    1.78921e-05             64            3         128 |\n",
            "| train_mnist_72e7b_00012   PENDING    2.09159e-05             32            1          64 |\n",
            "| train_mnist_72e7b_00013   PENDING    3.86109e-05             32            3         128 |\n",
            "| train_mnist_72e7b_00014   PENDING    0.000190781             64            2          64 |\n",
            "| train_mnist_72e7b_00015   PENDING    0.000135533            128            3         128 |\n",
            "| train_mnist_72e7b_00016   PENDING    0.000180571             32            3         128 |\n",
            "| train_mnist_72e7b_00017   PENDING    0.0004525               64            3         128 |\n",
            "| train_mnist_72e7b_00018   PENDING    5.73823e-05             32            3          32 |\n",
            "| train_mnist_72e7b_00019   PENDING    0.000175165            128            1          64 |\n",
            "| train_mnist_72e7b_00000   ERROR      0.000105659             64            2         128 |\n",
            "| train_mnist_72e7b_00001   ERROR      0.00118331              64            3         128 |\n",
            "| train_mnist_72e7b_00002   ERROR      5.91159e-05            128            2          32 |\n",
            "| train_mnist_72e7b_00003   ERROR      0.00611151              32            2         128 |\n",
            "| train_mnist_72e7b_00004   ERROR      0.00223458             128            2          32 |\n",
            "| train_mnist_72e7b_00005   ERROR      0.00289927             128            3          32 |\n",
            "+------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-11-13 17:16:02,377\tERROR tune_controller.py:1331 -- Trial task failed for trial train_mnist_72e7b_00006\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
            "    result = ray.get(future)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2753, in get\n",
            "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 904, in get_objects\n",
            "    raise value.as_instanceof_cause()\n",
            "ray.exceptions.RayTaskError(AttributeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=2453, ip=172.28.0.12, actor_id=279ee46b5e5c20ac736aa57b01000000, repr=train_mnist)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/trainable.py\", line 331, in train\n",
            "    raise skipped from exception_cause(skipped)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/air/_internal/util.py\", line 104, in run\n",
            "    self._ret = self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/function_trainable.py\", line 45, in <lambda>\n",
            "    training_func=lambda: self._trainable_func(self.config),\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/function_trainable.py\", line 250, in _trainable_func\n",
            "    output = fn()\n",
            "  File \"<ipython-input-3-8222499238c3>\", line 78, in train_mnist\n",
            "AttributeError: module 'ray.tune' has no attribute 'report'\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Trial train_mnist_72e7b_00006 errored after 0 iterations at 2024-11-13 17:16:02. Total running time: 3min 38s\n",
            "Error file: /tmp/ray/session_2024-11-13_17-12-15_277287_683/artifacts/2024-11-13_17-12-23/train_mnist_2024-11-13_17-12-23/driver_artifacts/train_mnist_72e7b_00006_6_batch_size=32,lr=0.0009,n_layers=1,n_units=64_2024-11-13_17-12-38/error.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-11-13 17:16:10,906\tERROR tune_controller.py:1331 -- Trial task failed for trial train_mnist_72e7b_00007\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
            "    result = ray.get(future)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2753, in get\n",
            "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 904, in get_objects\n",
            "    raise value.as_instanceof_cause()\n",
            "ray.exceptions.RayTaskError(AttributeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=2576, ip=172.28.0.12, actor_id=47fe556c5f299ab27d00c83f01000000, repr=train_mnist)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/trainable.py\", line 331, in train\n",
            "    raise skipped from exception_cause(skipped)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/air/_internal/util.py\", line 104, in run\n",
            "    self._ret = self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/function_trainable.py\", line 45, in <lambda>\n",
            "    training_func=lambda: self._trainable_func(self.config),\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/function_trainable.py\", line 250, in _trainable_func\n",
            "    output = fn()\n",
            "  File \"<ipython-input-3-8222499238c3>\", line 78, in train_mnist\n",
            "AttributeError: module 'ray.tune' has no attribute 'report'\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Trial train_mnist_72e7b_00007 errored after 0 iterations at 2024-11-13 17:16:10. Total running time: 3min 47s\n",
            "Error file: /tmp/ray/session_2024-11-13_17-12-15_277287_683/artifacts/2024-11-13_17-12-23/train_mnist_2024-11-13_17-12-23/driver_artifacts/train_mnist_72e7b_00007_7_batch_size=128,lr=0.0002,n_layers=1,n_units=32_2024-11-13_17-12-39/error.txt\n",
            "\n",
            "Trial train_mnist_72e7b_00008 started with configuration:\n",
            "+--------------------------------------------------+\n",
            "| Trial train_mnist_72e7b_00008 config             |\n",
            "+--------------------------------------------------+\n",
            "| batch_size                                    64 |\n",
            "| lr                                       0.00366 |\n",
            "| n_layers                                       3 |\n",
            "| n_units                                       32 |\n",
            "+--------------------------------------------------+\n",
            "\n",
            "Trial status: 8 ERROR | 1 RUNNING | 11 PENDING\n",
            "Current time: 2024-11-13 17:16:17. Total running time: 3min 54s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/0 GPUs\n",
            "+------------------------------------------------------------------------------------------+\n",
            "| Trial name                status              lr     batch_size     n_layers     n_units |\n",
            "+------------------------------------------------------------------------------------------+\n",
            "| train_mnist_72e7b_00008   RUNNING    0.00366188              64            3          32 |\n",
            "| train_mnist_72e7b_00009   PENDING    8.52954e-05             32            3          32 |\n",
            "| train_mnist_72e7b_00010   PENDING    0.00280513              32            2         128 |\n",
            "| train_mnist_72e7b_00011   PENDING    1.78921e-05             64            3         128 |\n",
            "| train_mnist_72e7b_00012   PENDING    2.09159e-05             32            1          64 |\n",
            "| train_mnist_72e7b_00013   PENDING    3.86109e-05             32            3         128 |\n",
            "| train_mnist_72e7b_00014   PENDING    0.000190781             64            2          64 |\n",
            "| train_mnist_72e7b_00015   PENDING    0.000135533            128            3         128 |\n",
            "| train_mnist_72e7b_00016   PENDING    0.000180571             32            3         128 |\n",
            "| train_mnist_72e7b_00017   PENDING    0.0004525               64            3         128 |\n",
            "| train_mnist_72e7b_00018   PENDING    5.73823e-05             32            3          32 |\n",
            "| train_mnist_72e7b_00019   PENDING    0.000175165            128            1          64 |\n",
            "| train_mnist_72e7b_00000   ERROR      0.000105659             64            2         128 |\n",
            "| train_mnist_72e7b_00001   ERROR      0.00118331              64            3         128 |\n",
            "| train_mnist_72e7b_00002   ERROR      5.91159e-05            128            2          32 |\n",
            "| train_mnist_72e7b_00003   ERROR      0.00611151              32            2         128 |\n",
            "| train_mnist_72e7b_00004   ERROR      0.00223458             128            2          32 |\n",
            "| train_mnist_72e7b_00005   ERROR      0.00289927             128            3          32 |\n",
            "| train_mnist_72e7b_00006   ERROR      0.0008884               32            1          64 |\n",
            "| train_mnist_72e7b_00007   ERROR      0.000242121            128            1          32 |\n",
            "+------------------------------------------------------------------------------------------+\n",
            "\n",
            "Trial train_mnist_72e7b_00009 started with configuration:\n",
            "+------------------------------------------------+\n",
            "| Trial train_mnist_72e7b_00009 config           |\n",
            "+------------------------------------------------+\n",
            "| batch_size                                  32 |\n",
            "| lr                                       9e-05 |\n",
            "| n_layers                                     3 |\n",
            "| n_units                                     32 |\n",
            "+------------------------------------------------+\n",
            "\n",
            "Trial status: 8 ERROR | 2 RUNNING | 10 PENDING\n",
            "Current time: 2024-11-13 17:16:47. Total running time: 4min 24s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/0 GPUs\n",
            "+------------------------------------------------------------------------------------------+\n",
            "| Trial name                status              lr     batch_size     n_layers     n_units |\n",
            "+------------------------------------------------------------------------------------------+\n",
            "| train_mnist_72e7b_00008   RUNNING    0.00366188              64            3          32 |\n",
            "| train_mnist_72e7b_00009   RUNNING    8.52954e-05             32            3          32 |\n",
            "| train_mnist_72e7b_00010   PENDING    0.00280513              32            2         128 |\n",
            "| train_mnist_72e7b_00011   PENDING    1.78921e-05             64            3         128 |\n",
            "| train_mnist_72e7b_00012   PENDING    2.09159e-05             32            1          64 |\n",
            "| train_mnist_72e7b_00013   PENDING    3.86109e-05             32            3         128 |\n",
            "| train_mnist_72e7b_00014   PENDING    0.000190781             64            2          64 |\n",
            "| train_mnist_72e7b_00015   PENDING    0.000135533            128            3         128 |\n",
            "| train_mnist_72e7b_00016   PENDING    0.000180571             32            3         128 |\n",
            "| train_mnist_72e7b_00017   PENDING    0.0004525               64            3         128 |\n",
            "| train_mnist_72e7b_00018   PENDING    5.73823e-05             32            3          32 |\n",
            "| train_mnist_72e7b_00019   PENDING    0.000175165            128            1          64 |\n",
            "| train_mnist_72e7b_00000   ERROR      0.000105659             64            2         128 |\n",
            "| train_mnist_72e7b_00001   ERROR      0.00118331              64            3         128 |\n",
            "| train_mnist_72e7b_00002   ERROR      5.91159e-05            128            2          32 |\n",
            "| train_mnist_72e7b_00003   ERROR      0.00611151              32            2         128 |\n",
            "| train_mnist_72e7b_00004   ERROR      0.00223458             128            2          32 |\n",
            "| train_mnist_72e7b_00005   ERROR      0.00289927             128            3          32 |\n",
            "| train_mnist_72e7b_00006   ERROR      0.0008884               32            1          64 |\n",
            "| train_mnist_72e7b_00007   ERROR      0.000242121            128            1          32 |\n",
            "+------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-11-13 17:16:50,413\tERROR tune_controller.py:1331 -- Trial task failed for trial train_mnist_72e7b_00008\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
            "    result = ray.get(future)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2753, in get\n",
            "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 904, in get_objects\n",
            "    raise value.as_instanceof_cause()\n",
            "ray.exceptions.RayTaskError(AttributeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=2793, ip=172.28.0.12, actor_id=80e93d6fe882a95697d0a15d01000000, repr=train_mnist)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/trainable.py\", line 331, in train\n",
            "    raise skipped from exception_cause(skipped)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/air/_internal/util.py\", line 104, in run\n",
            "    self._ret = self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/function_trainable.py\", line 45, in <lambda>\n",
            "    training_func=lambda: self._trainable_func(self.config),\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/function_trainable.py\", line 250, in _trainable_func\n",
            "    output = fn()\n",
            "  File \"<ipython-input-3-8222499238c3>\", line 78, in train_mnist\n",
            "AttributeError: module 'ray.tune' has no attribute 'report'\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Trial train_mnist_72e7b_00008 errored after 0 iterations at 2024-11-13 17:16:50. Total running time: 4min 26s\n",
            "Error file: /tmp/ray/session_2024-11-13_17-12-15_277287_683/artifacts/2024-11-13_17-12-23/train_mnist_2024-11-13_17-12-23/driver_artifacts/train_mnist_72e7b_00008_8_batch_size=64,lr=0.0037,n_layers=3,n_units=32_2024-11-13_17-12-39/error.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-11-13 17:17:03,233\tERROR tune_controller.py:1331 -- Trial task failed for trial train_mnist_72e7b_00009\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
            "    result = ray.get(future)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2753, in get\n",
            "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 904, in get_objects\n",
            "    raise value.as_instanceof_cause()\n",
            "ray.exceptions.RayTaskError(AttributeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=2893, ip=172.28.0.12, actor_id=b3c56975b47d889be80734a201000000, repr=train_mnist)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/trainable.py\", line 331, in train\n",
            "    raise skipped from exception_cause(skipped)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/air/_internal/util.py\", line 104, in run\n",
            "    self._ret = self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/function_trainable.py\", line 45, in <lambda>\n",
            "    training_func=lambda: self._trainable_func(self.config),\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/function_trainable.py\", line 250, in _trainable_func\n",
            "    output = fn()\n",
            "  File \"<ipython-input-3-8222499238c3>\", line 78, in train_mnist\n",
            "AttributeError: module 'ray.tune' has no attribute 'report'\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Trial train_mnist_72e7b_00009 errored after 0 iterations at 2024-11-13 17:17:03. Total running time: 4min 39s\n",
            "Error file: /tmp/ray/session_2024-11-13_17-12-15_277287_683/artifacts/2024-11-13_17-12-23/train_mnist_2024-11-13_17-12-23/driver_artifacts/train_mnist_72e7b_00009_9_batch_size=32,lr=0.0001,n_layers=3,n_units=32_2024-11-13_17-12-40/error.txt\n",
            "\n",
            "Trial train_mnist_72e7b_00010 started with configuration:\n",
            "+--------------------------------------------------+\n",
            "| Trial train_mnist_72e7b_00010 config             |\n",
            "+--------------------------------------------------+\n",
            "| batch_size                                    32 |\n",
            "| lr                                       0.00281 |\n",
            "| n_layers                                       2 |\n",
            "| n_units                                      128 |\n",
            "+--------------------------------------------------+\n",
            "\n",
            "Trial train_mnist_72e7b_00011 started with configuration:\n",
            "+------------------------------------------------+\n",
            "| Trial train_mnist_72e7b_00011 config           |\n",
            "+------------------------------------------------+\n",
            "| batch_size                                  64 |\n",
            "| lr                                       2e-05 |\n",
            "| n_layers                                     3 |\n",
            "| n_units                                    128 |\n",
            "+------------------------------------------------+\n",
            "\n",
            "Trial status: 10 ERROR | 2 RUNNING | 8 PENDING\n",
            "Current time: 2024-11-13 17:17:17. Total running time: 4min 54s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/0 GPUs\n",
            "+------------------------------------------------------------------------------------------+\n",
            "| Trial name                status              lr     batch_size     n_layers     n_units |\n",
            "+------------------------------------------------------------------------------------------+\n",
            "| train_mnist_72e7b_00010   RUNNING    0.00280513              32            2         128 |\n",
            "| train_mnist_72e7b_00011   RUNNING    1.78921e-05             64            3         128 |\n",
            "| train_mnist_72e7b_00012   PENDING    2.09159e-05             32            1          64 |\n",
            "| train_mnist_72e7b_00013   PENDING    3.86109e-05             32            3         128 |\n",
            "| train_mnist_72e7b_00014   PENDING    0.000190781             64            2          64 |\n",
            "| train_mnist_72e7b_00015   PENDING    0.000135533            128            3         128 |\n",
            "| train_mnist_72e7b_00016   PENDING    0.000180571             32            3         128 |\n",
            "| train_mnist_72e7b_00017   PENDING    0.0004525               64            3         128 |\n",
            "| train_mnist_72e7b_00018   PENDING    5.73823e-05             32            3          32 |\n",
            "| train_mnist_72e7b_00019   PENDING    0.000175165            128            1          64 |\n",
            "| train_mnist_72e7b_00000   ERROR      0.000105659             64            2         128 |\n",
            "| train_mnist_72e7b_00001   ERROR      0.00118331              64            3         128 |\n",
            "| train_mnist_72e7b_00002   ERROR      5.91159e-05            128            2          32 |\n",
            "| train_mnist_72e7b_00003   ERROR      0.00611151              32            2         128 |\n",
            "| train_mnist_72e7b_00004   ERROR      0.00223458             128            2          32 |\n",
            "| train_mnist_72e7b_00005   ERROR      0.00289927             128            3          32 |\n",
            "| train_mnist_72e7b_00006   ERROR      0.0008884               32            1          64 |\n",
            "| train_mnist_72e7b_00007   ERROR      0.000242121            128            1          32 |\n",
            "| train_mnist_72e7b_00008   ERROR      0.00366188              64            3          32 |\n",
            "| train_mnist_72e7b_00009   ERROR      8.52954e-05             32            3          32 |\n",
            "+------------------------------------------------------------------------------------------+\n",
            "Trial status: 10 ERROR | 2 RUNNING | 8 PENDING\n",
            "Current time: 2024-11-13 17:17:47. Total running time: 5min 24s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/0 GPUs\n",
            "+------------------------------------------------------------------------------------------+\n",
            "| Trial name                status              lr     batch_size     n_layers     n_units |\n",
            "+------------------------------------------------------------------------------------------+\n",
            "| train_mnist_72e7b_00010   RUNNING    0.00280513              32            2         128 |\n",
            "| train_mnist_72e7b_00011   RUNNING    1.78921e-05             64            3         128 |\n",
            "| train_mnist_72e7b_00012   PENDING    2.09159e-05             32            1          64 |\n",
            "| train_mnist_72e7b_00013   PENDING    3.86109e-05             32            3         128 |\n",
            "| train_mnist_72e7b_00014   PENDING    0.000190781             64            2          64 |\n",
            "| train_mnist_72e7b_00015   PENDING    0.000135533            128            3         128 |\n",
            "| train_mnist_72e7b_00016   PENDING    0.000180571             32            3         128 |\n",
            "| train_mnist_72e7b_00017   PENDING    0.0004525               64            3         128 |\n",
            "| train_mnist_72e7b_00018   PENDING    5.73823e-05             32            3          32 |\n",
            "| train_mnist_72e7b_00019   PENDING    0.000175165            128            1          64 |\n",
            "| train_mnist_72e7b_00000   ERROR      0.000105659             64            2         128 |\n",
            "| train_mnist_72e7b_00001   ERROR      0.00118331              64            3         128 |\n",
            "| train_mnist_72e7b_00002   ERROR      5.91159e-05            128            2          32 |\n",
            "| train_mnist_72e7b_00003   ERROR      0.00611151              32            2         128 |\n",
            "| train_mnist_72e7b_00004   ERROR      0.00223458             128            2          32 |\n",
            "| train_mnist_72e7b_00005   ERROR      0.00289927             128            3          32 |\n",
            "| train_mnist_72e7b_00006   ERROR      0.0008884               32            1          64 |\n",
            "| train_mnist_72e7b_00007   ERROR      0.000242121            128            1          32 |\n",
            "| train_mnist_72e7b_00008   ERROR      0.00366188              64            3          32 |\n",
            "| train_mnist_72e7b_00009   ERROR      8.52954e-05             32            3          32 |\n",
            "+------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-11-13 17:17:48,335\tERROR tune_controller.py:1331 -- Trial task failed for trial train_mnist_72e7b_00010\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
            "    result = ray.get(future)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2753, in get\n",
            "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 904, in get_objects\n",
            "    raise value.as_instanceof_cause()\n",
            "ray.exceptions.RayTaskError(AttributeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=3120, ip=172.28.0.12, actor_id=26af1e1baee249d6dd7b47f001000000, repr=train_mnist)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/trainable.py\", line 331, in train\n",
            "    raise skipped from exception_cause(skipped)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/air/_internal/util.py\", line 104, in run\n",
            "    self._ret = self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/function_trainable.py\", line 45, in <lambda>\n",
            "    training_func=lambda: self._trainable_func(self.config),\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/function_trainable.py\", line 250, in _trainable_func\n",
            "    output = fn()\n",
            "  File \"<ipython-input-3-8222499238c3>\", line 78, in train_mnist\n",
            "AttributeError: module 'ray.tune' has no attribute 'report'\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Trial train_mnist_72e7b_00010 errored after 0 iterations at 2024-11-13 17:17:48. Total running time: 5min 24s\n",
            "Error file: /tmp/ray/session_2024-11-13_17-12-15_277287_683/artifacts/2024-11-13_17-12-23/train_mnist_2024-11-13_17-12-23/driver_artifacts/train_mnist_72e7b_00010_10_batch_size=32,lr=0.0028,n_layers=2,n_units=128_2024-11-13_17-12-40/error.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-11-13 17:17:54,278\tERROR tune_controller.py:1331 -- Trial task failed for trial train_mnist_72e7b_00011\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
            "    result = ray.get(future)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2753, in get\n",
            "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 904, in get_objects\n",
            "    raise value.as_instanceof_cause()\n",
            "ray.exceptions.RayTaskError(AttributeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=3238, ip=172.28.0.12, actor_id=2921a76e6137f35290497cc801000000, repr=train_mnist)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/trainable.py\", line 331, in train\n",
            "    raise skipped from exception_cause(skipped)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/air/_internal/util.py\", line 104, in run\n",
            "    self._ret = self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/function_trainable.py\", line 45, in <lambda>\n",
            "    training_func=lambda: self._trainable_func(self.config),\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/function_trainable.py\", line 250, in _trainable_func\n",
            "    output = fn()\n",
            "  File \"<ipython-input-3-8222499238c3>\", line 78, in train_mnist\n",
            "AttributeError: module 'ray.tune' has no attribute 'report'\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Trial train_mnist_72e7b_00011 errored after 0 iterations at 2024-11-13 17:17:54. Total running time: 5min 30s\n",
            "Error file: /tmp/ray/session_2024-11-13_17-12-15_277287_683/artifacts/2024-11-13_17-12-23/train_mnist_2024-11-13_17-12-23/driver_artifacts/train_mnist_72e7b_00011_11_batch_size=64,lr=0.0000,n_layers=3,n_units=128_2024-11-13_17-12-41/error.txt\n",
            "\n",
            "Trial train_mnist_72e7b_00012 started with configuration:\n",
            "+------------------------------------------------+\n",
            "| Trial train_mnist_72e7b_00012 config           |\n",
            "+------------------------------------------------+\n",
            "| batch_size                                  32 |\n",
            "| lr                                       2e-05 |\n",
            "| n_layers                                     1 |\n",
            "| n_units                                     64 |\n",
            "+------------------------------------------------+\n",
            "\n",
            "Trial train_mnist_72e7b_00013 started with configuration:\n",
            "+------------------------------------------------+\n",
            "| Trial train_mnist_72e7b_00013 config           |\n",
            "+------------------------------------------------+\n",
            "| batch_size                                  32 |\n",
            "| lr                                       4e-05 |\n",
            "| n_layers                                     3 |\n",
            "| n_units                                    128 |\n",
            "+------------------------------------------------+\n",
            "\n",
            "Trial status: 12 ERROR | 2 RUNNING | 6 PENDING\n",
            "Current time: 2024-11-13 17:18:17. Total running time: 5min 54s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/0 GPUs\n",
            "+------------------------------------------------------------------------------------------+\n",
            "| Trial name                status              lr     batch_size     n_layers     n_units |\n",
            "+------------------------------------------------------------------------------------------+\n",
            "| train_mnist_72e7b_00012   RUNNING    2.09159e-05             32            1          64 |\n",
            "| train_mnist_72e7b_00013   RUNNING    3.86109e-05             32            3         128 |\n",
            "| train_mnist_72e7b_00014   PENDING    0.000190781             64            2          64 |\n",
            "| train_mnist_72e7b_00015   PENDING    0.000135533            128            3         128 |\n",
            "| train_mnist_72e7b_00016   PENDING    0.000180571             32            3         128 |\n",
            "| train_mnist_72e7b_00017   PENDING    0.0004525               64            3         128 |\n",
            "| train_mnist_72e7b_00018   PENDING    5.73823e-05             32            3          32 |\n",
            "| train_mnist_72e7b_00019   PENDING    0.000175165            128            1          64 |\n",
            "| train_mnist_72e7b_00000   ERROR      0.000105659             64            2         128 |\n",
            "| train_mnist_72e7b_00001   ERROR      0.00118331              64            3         128 |\n",
            "| train_mnist_72e7b_00002   ERROR      5.91159e-05            128            2          32 |\n",
            "| train_mnist_72e7b_00003   ERROR      0.00611151              32            2         128 |\n",
            "| train_mnist_72e7b_00004   ERROR      0.00223458             128            2          32 |\n",
            "| train_mnist_72e7b_00005   ERROR      0.00289927             128            3          32 |\n",
            "| train_mnist_72e7b_00006   ERROR      0.0008884               32            1          64 |\n",
            "| train_mnist_72e7b_00007   ERROR      0.000242121            128            1          32 |\n",
            "| train_mnist_72e7b_00008   ERROR      0.00366188              64            3          32 |\n",
            "| train_mnist_72e7b_00009   ERROR      8.52954e-05             32            3          32 |\n",
            "| train_mnist_72e7b_00010   ERROR      0.00280513              32            2         128 |\n",
            "| train_mnist_72e7b_00011   ERROR      1.78921e-05             64            3         128 |\n",
            "+------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-11-13 17:18:38,025\tERROR tune_controller.py:1331 -- Trial task failed for trial train_mnist_72e7b_00012\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
            "    result = ray.get(future)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2753, in get\n",
            "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 904, in get_objects\n",
            "    raise value.as_instanceof_cause()\n",
            "ray.exceptions.RayTaskError(AttributeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=3483, ip=172.28.0.12, actor_id=cf345de542c0cf3070e5c57c01000000, repr=train_mnist)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/trainable.py\", line 331, in train\n",
            "    raise skipped from exception_cause(skipped)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/air/_internal/util.py\", line 104, in run\n",
            "    self._ret = self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/function_trainable.py\", line 45, in <lambda>\n",
            "    training_func=lambda: self._trainable_func(self.config),\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/function_trainable.py\", line 250, in _trainable_func\n",
            "    output = fn()\n",
            "  File \"<ipython-input-3-8222499238c3>\", line 78, in train_mnist\n",
            "AttributeError: module 'ray.tune' has no attribute 'report'\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Trial train_mnist_72e7b_00012 errored after 0 iterations at 2024-11-13 17:18:38. Total running time: 6min 14s\n",
            "Error file: /tmp/ray/session_2024-11-13_17-12-15_277287_683/artifacts/2024-11-13_17-12-23/train_mnist_2024-11-13_17-12-23/driver_artifacts/train_mnist_72e7b_00012_12_batch_size=32,lr=0.0000,n_layers=1,n_units=64_2024-11-13_17-12-41/error.txt\n",
            "\n",
            "Trial status: 13 ERROR | 1 RUNNING | 6 PENDING\n",
            "Current time: 2024-11-13 17:18:47. Total running time: 6min 24s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/0 GPUs\n",
            "+------------------------------------------------------------------------------------------+\n",
            "| Trial name                status              lr     batch_size     n_layers     n_units |\n",
            "+------------------------------------------------------------------------------------------+\n",
            "| train_mnist_72e7b_00013   RUNNING    3.86109e-05             32            3         128 |\n",
            "| train_mnist_72e7b_00014   PENDING    0.000190781             64            2          64 |\n",
            "| train_mnist_72e7b_00015   PENDING    0.000135533            128            3         128 |\n",
            "| train_mnist_72e7b_00016   PENDING    0.000180571             32            3         128 |\n",
            "| train_mnist_72e7b_00017   PENDING    0.0004525               64            3         128 |\n",
            "| train_mnist_72e7b_00018   PENDING    5.73823e-05             32            3          32 |\n",
            "| train_mnist_72e7b_00019   PENDING    0.000175165            128            1          64 |\n",
            "| train_mnist_72e7b_00000   ERROR      0.000105659             64            2         128 |\n",
            "| train_mnist_72e7b_00001   ERROR      0.00118331              64            3         128 |\n",
            "| train_mnist_72e7b_00002   ERROR      5.91159e-05            128            2          32 |\n",
            "| train_mnist_72e7b_00003   ERROR      0.00611151              32            2         128 |\n",
            "| train_mnist_72e7b_00004   ERROR      0.00223458             128            2          32 |\n",
            "| train_mnist_72e7b_00005   ERROR      0.00289927             128            3          32 |\n",
            "| train_mnist_72e7b_00006   ERROR      0.0008884               32            1          64 |\n",
            "| train_mnist_72e7b_00007   ERROR      0.000242121            128            1          32 |\n",
            "| train_mnist_72e7b_00008   ERROR      0.00366188              64            3          32 |\n",
            "| train_mnist_72e7b_00009   ERROR      8.52954e-05             32            3          32 |\n",
            "| train_mnist_72e7b_00010   ERROR      0.00280513              32            2         128 |\n",
            "| train_mnist_72e7b_00011   ERROR      1.78921e-05             64            3         128 |\n",
            "| train_mnist_72e7b_00012   ERROR      2.09159e-05             32            1          64 |\n",
            "+------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-11-13 17:18:51,300\tERROR tune_controller.py:1331 -- Trial task failed for trial train_mnist_72e7b_00013\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
            "    result = ray.get(future)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2753, in get\n",
            "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 904, in get_objects\n",
            "    raise value.as_instanceof_cause()\n",
            "ray.exceptions.RayTaskError(AttributeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=3569, ip=172.28.0.12, actor_id=108831311f43e5e3e74cb61301000000, repr=train_mnist)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/trainable.py\", line 331, in train\n",
            "    raise skipped from exception_cause(skipped)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/air/_internal/util.py\", line 104, in run\n",
            "    self._ret = self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/function_trainable.py\", line 45, in <lambda>\n",
            "    training_func=lambda: self._trainable_func(self.config),\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/function_trainable.py\", line 250, in _trainable_func\n",
            "    output = fn()\n",
            "  File \"<ipython-input-3-8222499238c3>\", line 78, in train_mnist\n",
            "AttributeError: module 'ray.tune' has no attribute 'report'\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Trial train_mnist_72e7b_00013 errored after 0 iterations at 2024-11-13 17:18:51. Total running time: 6min 27s\n",
            "Error file: /tmp/ray/session_2024-11-13_17-12-15_277287_683/artifacts/2024-11-13_17-12-23/train_mnist_2024-11-13_17-12-23/driver_artifacts/train_mnist_72e7b_00013_13_batch_size=32,lr=0.0000,n_layers=3,n_units=128_2024-11-13_17-12-42/error.txt\n",
            "\n",
            "Trial train_mnist_72e7b_00014 started with configuration:\n",
            "+--------------------------------------------------+\n",
            "| Trial train_mnist_72e7b_00014 config             |\n",
            "+--------------------------------------------------+\n",
            "| batch_size                                    64 |\n",
            "| lr                                       0.00019 |\n",
            "| n_layers                                       2 |\n",
            "| n_units                                       64 |\n",
            "+--------------------------------------------------+\n",
            "\n",
            "Trial train_mnist_72e7b_00015 started with configuration:\n",
            "+--------------------------------------------------+\n",
            "| Trial train_mnist_72e7b_00015 config             |\n",
            "+--------------------------------------------------+\n",
            "| batch_size                                   128 |\n",
            "| lr                                       0.00014 |\n",
            "| n_layers                                       3 |\n",
            "| n_units                                      128 |\n",
            "+--------------------------------------------------+\n",
            "\n",
            "Trial status: 14 ERROR | 2 RUNNING | 4 PENDING\n",
            "Current time: 2024-11-13 17:19:17. Total running time: 6min 54s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/0 GPUs\n",
            "+------------------------------------------------------------------------------------------+\n",
            "| Trial name                status              lr     batch_size     n_layers     n_units |\n",
            "+------------------------------------------------------------------------------------------+\n",
            "| train_mnist_72e7b_00014   RUNNING    0.000190781             64            2          64 |\n",
            "| train_mnist_72e7b_00015   RUNNING    0.000135533            128            3         128 |\n",
            "| train_mnist_72e7b_00016   PENDING    0.000180571             32            3         128 |\n",
            "| train_mnist_72e7b_00017   PENDING    0.0004525               64            3         128 |\n",
            "| train_mnist_72e7b_00018   PENDING    5.73823e-05             32            3          32 |\n",
            "| train_mnist_72e7b_00019   PENDING    0.000175165            128            1          64 |\n",
            "| train_mnist_72e7b_00000   ERROR      0.000105659             64            2         128 |\n",
            "| train_mnist_72e7b_00001   ERROR      0.00118331              64            3         128 |\n",
            "| train_mnist_72e7b_00002   ERROR      5.91159e-05            128            2          32 |\n",
            "| train_mnist_72e7b_00003   ERROR      0.00611151              32            2         128 |\n",
            "| train_mnist_72e7b_00004   ERROR      0.00223458             128            2          32 |\n",
            "| train_mnist_72e7b_00005   ERROR      0.00289927             128            3          32 |\n",
            "| train_mnist_72e7b_00006   ERROR      0.0008884               32            1          64 |\n",
            "| train_mnist_72e7b_00007   ERROR      0.000242121            128            1          32 |\n",
            "| train_mnist_72e7b_00008   ERROR      0.00366188              64            3          32 |\n",
            "| train_mnist_72e7b_00009   ERROR      8.52954e-05             32            3          32 |\n",
            "| train_mnist_72e7b_00010   ERROR      0.00280513              32            2         128 |\n",
            "| train_mnist_72e7b_00011   ERROR      1.78921e-05             64            3         128 |\n",
            "| train_mnist_72e7b_00012   ERROR      2.09159e-05             32            1          64 |\n",
            "| train_mnist_72e7b_00013   ERROR      3.86109e-05             32            3         128 |\n",
            "+------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-11-13 17:19:27,909\tERROR tune_controller.py:1331 -- Trial task failed for trial train_mnist_72e7b_00014\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
            "    result = ray.get(future)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2753, in get\n",
            "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 904, in get_objects\n",
            "    raise value.as_instanceof_cause()\n",
            "ray.exceptions.RayTaskError(AttributeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=3818, ip=172.28.0.12, actor_id=2b06190ecc38075a7f3b5c9301000000, repr=train_mnist)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/trainable.py\", line 331, in train\n",
            "    raise skipped from exception_cause(skipped)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/air/_internal/util.py\", line 104, in run\n",
            "    self._ret = self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/function_trainable.py\", line 45, in <lambda>\n",
            "    training_func=lambda: self._trainable_func(self.config),\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/function_trainable.py\", line 250, in _trainable_func\n",
            "    output = fn()\n",
            "  File \"<ipython-input-3-8222499238c3>\", line 78, in train_mnist\n",
            "AttributeError: module 'ray.tune' has no attribute 'report'\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Trial train_mnist_72e7b_00014 errored after 0 iterations at 2024-11-13 17:19:27. Total running time: 7min 4s\n",
            "Error file: /tmp/ray/session_2024-11-13_17-12-15_277287_683/artifacts/2024-11-13_17-12-23/train_mnist_2024-11-13_17-12-23/driver_artifacts/train_mnist_72e7b_00014_14_batch_size=64,lr=0.0002,n_layers=2,n_units=64_2024-11-13_17-12-42/error.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-11-13 17:19:40,672\tERROR tune_controller.py:1331 -- Trial task failed for trial train_mnist_72e7b_00015\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
            "    result = ray.get(future)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2753, in get\n",
            "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 904, in get_objects\n",
            "    raise value.as_instanceof_cause()\n",
            "ray.exceptions.RayTaskError(AttributeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=3936, ip=172.28.0.12, actor_id=41e6b3082bdc2b5ef72d80bf01000000, repr=train_mnist)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/trainable.py\", line 331, in train\n",
            "    raise skipped from exception_cause(skipped)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/air/_internal/util.py\", line 104, in run\n",
            "    self._ret = self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/function_trainable.py\", line 45, in <lambda>\n",
            "    training_func=lambda: self._trainable_func(self.config),\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/function_trainable.py\", line 250, in _trainable_func\n",
            "    output = fn()\n",
            "  File \"<ipython-input-3-8222499238c3>\", line 78, in train_mnist\n",
            "AttributeError: module 'ray.tune' has no attribute 'report'\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Trial train_mnist_72e7b_00015 errored after 0 iterations at 2024-11-13 17:19:40. Total running time: 7min 17s\n",
            "Error file: /tmp/ray/session_2024-11-13_17-12-15_277287_683/artifacts/2024-11-13_17-12-23/train_mnist_2024-11-13_17-12-23/driver_artifacts/train_mnist_72e7b_00015_15_batch_size=128,lr=0.0001,n_layers=3,n_units=128_2024-11-13_17-12-43/error.txt\n",
            "\n",
            "Trial train_mnist_72e7b_00016 started with configuration:\n",
            "+--------------------------------------------------+\n",
            "| Trial train_mnist_72e7b_00016 config             |\n",
            "+--------------------------------------------------+\n",
            "| batch_size                                    32 |\n",
            "| lr                                       0.00018 |\n",
            "| n_layers                                       3 |\n",
            "| n_units                                      128 |\n",
            "+--------------------------------------------------+\n",
            "\n",
            "Trial status: 16 ERROR | 1 RUNNING | 3 PENDING\n",
            "Current time: 2024-11-13 17:19:47. Total running time: 7min 24s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/0 GPUs\n",
            "+------------------------------------------------------------------------------------------+\n",
            "| Trial name                status              lr     batch_size     n_layers     n_units |\n",
            "+------------------------------------------------------------------------------------------+\n",
            "| train_mnist_72e7b_00016   RUNNING    0.000180571             32            3         128 |\n",
            "| train_mnist_72e7b_00017   PENDING    0.0004525               64            3         128 |\n",
            "| train_mnist_72e7b_00018   PENDING    5.73823e-05             32            3          32 |\n",
            "| train_mnist_72e7b_00019   PENDING    0.000175165            128            1          64 |\n",
            "| train_mnist_72e7b_00000   ERROR      0.000105659             64            2         128 |\n",
            "| train_mnist_72e7b_00001   ERROR      0.00118331              64            3         128 |\n",
            "| train_mnist_72e7b_00002   ERROR      5.91159e-05            128            2          32 |\n",
            "| train_mnist_72e7b_00003   ERROR      0.00611151              32            2         128 |\n",
            "| train_mnist_72e7b_00004   ERROR      0.00223458             128            2          32 |\n",
            "| train_mnist_72e7b_00005   ERROR      0.00289927             128            3          32 |\n",
            "| train_mnist_72e7b_00006   ERROR      0.0008884               32            1          64 |\n",
            "| train_mnist_72e7b_00007   ERROR      0.000242121            128            1          32 |\n",
            "| train_mnist_72e7b_00008   ERROR      0.00366188              64            3          32 |\n",
            "| train_mnist_72e7b_00009   ERROR      8.52954e-05             32            3          32 |\n",
            "| train_mnist_72e7b_00010   ERROR      0.00280513              32            2         128 |\n",
            "| train_mnist_72e7b_00011   ERROR      1.78921e-05             64            3         128 |\n",
            "| train_mnist_72e7b_00012   ERROR      2.09159e-05             32            1          64 |\n",
            "| train_mnist_72e7b_00013   ERROR      3.86109e-05             32            3         128 |\n",
            "| train_mnist_72e7b_00014   ERROR      0.000190781             64            2          64 |\n",
            "| train_mnist_72e7b_00015   ERROR      0.000135533            128            3         128 |\n",
            "+------------------------------------------------------------------------------------------+\n",
            "\n",
            "Trial train_mnist_72e7b_00017 started with configuration:\n",
            "+--------------------------------------------------+\n",
            "| Trial train_mnist_72e7b_00017 config             |\n",
            "+--------------------------------------------------+\n",
            "| batch_size                                    64 |\n",
            "| lr                                       0.00045 |\n",
            "| n_layers                                       3 |\n",
            "| n_units                                      128 |\n",
            "+--------------------------------------------------+\n",
            "\n",
            "Trial status: 16 ERROR | 2 RUNNING | 2 PENDING\n",
            "Current time: 2024-11-13 17:20:17. Total running time: 7min 54s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/0 GPUs\n",
            "+------------------------------------------------------------------------------------------+\n",
            "| Trial name                status              lr     batch_size     n_layers     n_units |\n",
            "+------------------------------------------------------------------------------------------+\n",
            "| train_mnist_72e7b_00016   RUNNING    0.000180571             32            3         128 |\n",
            "| train_mnist_72e7b_00017   RUNNING    0.0004525               64            3         128 |\n",
            "| train_mnist_72e7b_00018   PENDING    5.73823e-05             32            3          32 |\n",
            "| train_mnist_72e7b_00019   PENDING    0.000175165            128            1          64 |\n",
            "| train_mnist_72e7b_00000   ERROR      0.000105659             64            2         128 |\n",
            "| train_mnist_72e7b_00001   ERROR      0.00118331              64            3         128 |\n",
            "| train_mnist_72e7b_00002   ERROR      5.91159e-05            128            2          32 |\n",
            "| train_mnist_72e7b_00003   ERROR      0.00611151              32            2         128 |\n",
            "| train_mnist_72e7b_00004   ERROR      0.00223458             128            2          32 |\n",
            "| train_mnist_72e7b_00005   ERROR      0.00289927             128            3          32 |\n",
            "| train_mnist_72e7b_00006   ERROR      0.0008884               32            1          64 |\n",
            "| train_mnist_72e7b_00007   ERROR      0.000242121            128            1          32 |\n",
            "| train_mnist_72e7b_00008   ERROR      0.00366188              64            3          32 |\n",
            "| train_mnist_72e7b_00009   ERROR      8.52954e-05             32            3          32 |\n",
            "| train_mnist_72e7b_00010   ERROR      0.00280513              32            2         128 |\n",
            "| train_mnist_72e7b_00011   ERROR      1.78921e-05             64            3         128 |\n",
            "| train_mnist_72e7b_00012   ERROR      2.09159e-05             32            1          64 |\n",
            "| train_mnist_72e7b_00013   ERROR      3.86109e-05             32            3         128 |\n",
            "| train_mnist_72e7b_00014   ERROR      0.000190781             64            2          64 |\n",
            "| train_mnist_72e7b_00015   ERROR      0.000135533            128            3         128 |\n",
            "+------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-11-13 17:20:26,477\tERROR tune_controller.py:1331 -- Trial task failed for trial train_mnist_72e7b_00016\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
            "    result = ray.get(future)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2753, in get\n",
            "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 904, in get_objects\n",
            "    raise value.as_instanceof_cause()\n",
            "ray.exceptions.RayTaskError(AttributeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=4153, ip=172.28.0.12, actor_id=710791ed9d74243b9e940cad01000000, repr=train_mnist)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/trainable.py\", line 331, in train\n",
            "    raise skipped from exception_cause(skipped)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/air/_internal/util.py\", line 104, in run\n",
            "    self._ret = self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/function_trainable.py\", line 45, in <lambda>\n",
            "    training_func=lambda: self._trainable_func(self.config),\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/function_trainable.py\", line 250, in _trainable_func\n",
            "    output = fn()\n",
            "  File \"<ipython-input-3-8222499238c3>\", line 78, in train_mnist\n",
            "AttributeError: module 'ray.tune' has no attribute 'report'\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Trial train_mnist_72e7b_00016 errored after 0 iterations at 2024-11-13 17:20:26. Total running time: 8min 3s\n",
            "Error file: /tmp/ray/session_2024-11-13_17-12-15_277287_683/artifacts/2024-11-13_17-12-23/train_mnist_2024-11-13_17-12-23/driver_artifacts/train_mnist_72e7b_00016_16_batch_size=32,lr=0.0002,n_layers=3,n_units=128_2024-11-13_17-12-43/error.txt\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-11-13 17:20:34,351\tERROR tune_controller.py:1331 -- Trial task failed for trial train_mnist_72e7b_00017\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
            "    result = ray.get(future)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2753, in get\n",
            "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 904, in get_objects\n",
            "    raise value.as_instanceof_cause()\n",
            "ray.exceptions.RayTaskError(AttributeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=4266, ip=172.28.0.12, actor_id=2a82b730313a632aa300467001000000, repr=train_mnist)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/trainable.py\", line 331, in train\n",
            "    raise skipped from exception_cause(skipped)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/air/_internal/util.py\", line 104, in run\n",
            "    self._ret = self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/function_trainable.py\", line 45, in <lambda>\n",
            "    training_func=lambda: self._trainable_func(self.config),\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/function_trainable.py\", line 250, in _trainable_func\n",
            "    output = fn()\n",
            "  File \"<ipython-input-3-8222499238c3>\", line 78, in train_mnist\n",
            "AttributeError: module 'ray.tune' has no attribute 'report'\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Trial train_mnist_72e7b_00017 errored after 0 iterations at 2024-11-13 17:20:34. Total running time: 8min 10s\n",
            "Error file: /tmp/ray/session_2024-11-13_17-12-15_277287_683/artifacts/2024-11-13_17-12-23/train_mnist_2024-11-13_17-12-23/driver_artifacts/train_mnist_72e7b_00017_17_batch_size=64,lr=0.0005,n_layers=3,n_units=128_2024-11-13_17-12-44/error.txt\n",
            "\n",
            "Trial train_mnist_72e7b_00018 started with configuration:\n",
            "+------------------------------------------------+\n",
            "| Trial train_mnist_72e7b_00018 config           |\n",
            "+------------------------------------------------+\n",
            "| batch_size                                  32 |\n",
            "| lr                                       6e-05 |\n",
            "| n_layers                                     3 |\n",
            "| n_units                                     32 |\n",
            "+------------------------------------------------+\n",
            "\n",
            "Trial train_mnist_72e7b_00019 started with configuration:\n",
            "+--------------------------------------------------+\n",
            "| Trial train_mnist_72e7b_00019 config             |\n",
            "+--------------------------------------------------+\n",
            "| batch_size                                   128 |\n",
            "| lr                                       0.00018 |\n",
            "| n_layers                                       1 |\n",
            "| n_units                                       64 |\n",
            "+--------------------------------------------------+\n",
            "\n",
            "Trial status: 18 ERROR | 2 RUNNING\n",
            "Current time: 2024-11-13 17:20:48. Total running time: 8min 24s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/0 GPUs\n",
            "+------------------------------------------------------------------------------------------+\n",
            "| Trial name                status              lr     batch_size     n_layers     n_units |\n",
            "+------------------------------------------------------------------------------------------+\n",
            "| train_mnist_72e7b_00018   RUNNING    5.73823e-05             32            3          32 |\n",
            "| train_mnist_72e7b_00019   RUNNING    0.000175165            128            1          64 |\n",
            "| train_mnist_72e7b_00000   ERROR      0.000105659             64            2         128 |\n",
            "| train_mnist_72e7b_00001   ERROR      0.00118331              64            3         128 |\n",
            "| train_mnist_72e7b_00002   ERROR      5.91159e-05            128            2          32 |\n",
            "| train_mnist_72e7b_00003   ERROR      0.00611151              32            2         128 |\n",
            "| train_mnist_72e7b_00004   ERROR      0.00223458             128            2          32 |\n",
            "| train_mnist_72e7b_00005   ERROR      0.00289927             128            3          32 |\n",
            "| train_mnist_72e7b_00006   ERROR      0.0008884               32            1          64 |\n",
            "| train_mnist_72e7b_00007   ERROR      0.000242121            128            1          32 |\n",
            "| train_mnist_72e7b_00008   ERROR      0.00366188              64            3          32 |\n",
            "| train_mnist_72e7b_00009   ERROR      8.52954e-05             32            3          32 |\n",
            "| train_mnist_72e7b_00010   ERROR      0.00280513              32            2         128 |\n",
            "| train_mnist_72e7b_00011   ERROR      1.78921e-05             64            3         128 |\n",
            "| train_mnist_72e7b_00012   ERROR      2.09159e-05             32            1          64 |\n",
            "| train_mnist_72e7b_00013   ERROR      3.86109e-05             32            3         128 |\n",
            "| train_mnist_72e7b_00014   ERROR      0.000190781             64            2          64 |\n",
            "| train_mnist_72e7b_00015   ERROR      0.000135533            128            3         128 |\n",
            "| train_mnist_72e7b_00016   ERROR      0.000180571             32            3         128 |\n",
            "| train_mnist_72e7b_00017   ERROR      0.0004525               64            3         128 |\n",
            "+------------------------------------------------------------------------------------------+\n",
            "Trial status: 18 ERROR | 2 RUNNING\n",
            "Current time: 2024-11-13 17:21:18. Total running time: 8min 54s\n",
            "Logical resource usage: 2.0/2 CPUs, 0/0 GPUs\n",
            "+------------------------------------------------------------------------------------------+\n",
            "| Trial name                status              lr     batch_size     n_layers     n_units |\n",
            "+------------------------------------------------------------------------------------------+\n",
            "| train_mnist_72e7b_00018   RUNNING    5.73823e-05             32            3          32 |\n",
            "| train_mnist_72e7b_00019   RUNNING    0.000175165            128            1          64 |\n",
            "| train_mnist_72e7b_00000   ERROR      0.000105659             64            2         128 |\n",
            "| train_mnist_72e7b_00001   ERROR      0.00118331              64            3         128 |\n",
            "| train_mnist_72e7b_00002   ERROR      5.91159e-05            128            2          32 |\n",
            "| train_mnist_72e7b_00003   ERROR      0.00611151              32            2         128 |\n",
            "| train_mnist_72e7b_00004   ERROR      0.00223458             128            2          32 |\n",
            "| train_mnist_72e7b_00005   ERROR      0.00289927             128            3          32 |\n",
            "| train_mnist_72e7b_00006   ERROR      0.0008884               32            1          64 |\n",
            "| train_mnist_72e7b_00007   ERROR      0.000242121            128            1          32 |\n",
            "| train_mnist_72e7b_00008   ERROR      0.00366188              64            3          32 |\n",
            "| train_mnist_72e7b_00009   ERROR      8.52954e-05             32            3          32 |\n",
            "| train_mnist_72e7b_00010   ERROR      0.00280513              32            2         128 |\n",
            "| train_mnist_72e7b_00011   ERROR      1.78921e-05             64            3         128 |\n",
            "| train_mnist_72e7b_00012   ERROR      2.09159e-05             32            1          64 |\n",
            "| train_mnist_72e7b_00013   ERROR      3.86109e-05             32            3         128 |\n",
            "| train_mnist_72e7b_00014   ERROR      0.000190781             64            2          64 |\n",
            "| train_mnist_72e7b_00015   ERROR      0.000135533            128            3         128 |\n",
            "| train_mnist_72e7b_00016   ERROR      0.000180571             32            3         128 |\n",
            "| train_mnist_72e7b_00017   ERROR      0.0004525               64            3         128 |\n",
            "+------------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-11-13 17:21:20,279\tERROR tune_controller.py:1331 -- Trial task failed for trial train_mnist_72e7b_00018\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
            "    result = ray.get(future)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2753, in get\n",
            "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 904, in get_objects\n",
            "    raise value.as_instanceof_cause()\n",
            "ray.exceptions.RayTaskError(AttributeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=4519, ip=172.28.0.12, actor_id=8998bd67a57acceaeded0ec601000000, repr=train_mnist)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/trainable.py\", line 331, in train\n",
            "    raise skipped from exception_cause(skipped)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/air/_internal/util.py\", line 104, in run\n",
            "    self._ret = self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/function_trainable.py\", line 45, in <lambda>\n",
            "    training_func=lambda: self._trainable_func(self.config),\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/function_trainable.py\", line 250, in _trainable_func\n",
            "    output = fn()\n",
            "  File \"<ipython-input-3-8222499238c3>\", line 78, in train_mnist\n",
            "AttributeError: module 'ray.tune' has no attribute 'report'\n",
            "2024-11-13 17:21:20,377\tERROR tune_controller.py:1331 -- Trial task failed for trial train_mnist_72e7b_00019\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
            "    result = ray.get(future)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
            "    return fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 2753, in get\n",
            "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/_private/worker.py\", line 904, in get_objects\n",
            "    raise value.as_instanceof_cause()\n",
            "ray.exceptions.RayTaskError(AttributeError): \u001b[36mray::ImplicitFunc.train()\u001b[39m (pid=4615, ip=172.28.0.12, actor_id=a79fc895708ba23474ccebbb01000000, repr=train_mnist)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/trainable.py\", line 331, in train\n",
            "    raise skipped from exception_cause(skipped)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/air/_internal/util.py\", line 104, in run\n",
            "    self._ret = self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/function_trainable.py\", line 45, in <lambda>\n",
            "    training_func=lambda: self._trainable_func(self.config),\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ray/tune/trainable/function_trainable.py\", line 250, in _trainable_func\n",
            "    output = fn()\n",
            "  File \"<ipython-input-3-8222499238c3>\", line 78, in train_mnist\n",
            "AttributeError: module 'ray.tune' has no attribute 'report'\n",
            "2024-11-13 17:21:20,429\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/root/ray_results/train_mnist_2024-11-13_17-12-23' in 0.0421s.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Trial train_mnist_72e7b_00018 errored after 0 iterations at 2024-11-13 17:21:20. Total running time: 8min 56s\n",
            "Error file: /tmp/ray/session_2024-11-13_17-12-15_277287_683/artifacts/2024-11-13_17-12-23/train_mnist_2024-11-13_17-12-23/driver_artifacts/train_mnist_72e7b_00018_18_batch_size=32,lr=0.0001,n_layers=3,n_units=32_2024-11-13_17-12-44/error.txt\n",
            "\n",
            "Trial train_mnist_72e7b_00019 errored after 0 iterations at 2024-11-13 17:21:20. Total running time: 8min 56s\n",
            "Error file: /tmp/ray/session_2024-11-13_17-12-15_277287_683/artifacts/2024-11-13_17-12-23/train_mnist_2024-11-13_17-12-23/driver_artifacts/train_mnist_72e7b_00019_19_batch_size=128,lr=0.0002,n_layers=1,n_units=64_2024-11-13_17-12-45/error.txt\n",
            "\n",
            "Trial status: 20 ERROR\n",
            "Current time: 2024-11-13 17:21:20. Total running time: 8min 56s\n",
            "Logical resource usage: 1.0/2 CPUs, 0/0 GPUs\n",
            "+------------------------------------------------------------------------------------------+\n",
            "| Trial name                status              lr     batch_size     n_layers     n_units |\n",
            "+------------------------------------------------------------------------------------------+\n",
            "| train_mnist_72e7b_00000   ERROR      0.000105659             64            2         128 |\n",
            "| train_mnist_72e7b_00001   ERROR      0.00118331              64            3         128 |\n",
            "| train_mnist_72e7b_00002   ERROR      5.91159e-05            128            2          32 |\n",
            "| train_mnist_72e7b_00003   ERROR      0.00611151              32            2         128 |\n",
            "| train_mnist_72e7b_00004   ERROR      0.00223458             128            2          32 |\n",
            "| train_mnist_72e7b_00005   ERROR      0.00289927             128            3          32 |\n",
            "| train_mnist_72e7b_00006   ERROR      0.0008884               32            1          64 |\n",
            "| train_mnist_72e7b_00007   ERROR      0.000242121            128            1          32 |\n",
            "| train_mnist_72e7b_00008   ERROR      0.00366188              64            3          32 |\n",
            "| train_mnist_72e7b_00009   ERROR      8.52954e-05             32            3          32 |\n",
            "| train_mnist_72e7b_00010   ERROR      0.00280513              32            2         128 |\n",
            "| train_mnist_72e7b_00011   ERROR      1.78921e-05             64            3         128 |\n",
            "| train_mnist_72e7b_00012   ERROR      2.09159e-05             32            1          64 |\n",
            "| train_mnist_72e7b_00013   ERROR      3.86109e-05             32            3         128 |\n",
            "| train_mnist_72e7b_00014   ERROR      0.000190781             64            2          64 |\n",
            "| train_mnist_72e7b_00015   ERROR      0.000135533            128            3         128 |\n",
            "| train_mnist_72e7b_00016   ERROR      0.000180571             32            3         128 |\n",
            "| train_mnist_72e7b_00017   ERROR      0.0004525               64            3         128 |\n",
            "| train_mnist_72e7b_00018   ERROR      5.73823e-05             32            3          32 |\n",
            "| train_mnist_72e7b_00019   ERROR      0.000175165            128            1          64 |\n",
            "+------------------------------------------------------------------------------------------+\n",
            "\n",
            "Number of errored trials: 20\n",
            "+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| Trial name                  # failures   error file                                                                                                                                                                                                                              |\n",
            "+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "| train_mnist_72e7b_00000              1   /tmp/ray/session_2024-11-13_17-12-15_277287_683/artifacts/2024-11-13_17-12-23/train_mnist_2024-11-13_17-12-23/driver_artifacts/train_mnist_72e7b_00000_0_batch_size=64,lr=0.0001,n_layers=2,n_units=128_2024-11-13_17-12-35/error.txt   |\n",
            "| train_mnist_72e7b_00001              1   /tmp/ray/session_2024-11-13_17-12-15_277287_683/artifacts/2024-11-13_17-12-23/train_mnist_2024-11-13_17-12-23/driver_artifacts/train_mnist_72e7b_00001_1_batch_size=64,lr=0.0012,n_layers=3,n_units=128_2024-11-13_17-12-36/error.txt   |\n",
            "| train_mnist_72e7b_00002              1   /tmp/ray/session_2024-11-13_17-12-15_277287_683/artifacts/2024-11-13_17-12-23/train_mnist_2024-11-13_17-12-23/driver_artifacts/train_mnist_72e7b_00002_2_batch_size=128,lr=0.0001,n_layers=2,n_units=32_2024-11-13_17-12-36/error.txt   |\n",
            "| train_mnist_72e7b_00003              1   /tmp/ray/session_2024-11-13_17-12-15_277287_683/artifacts/2024-11-13_17-12-23/train_mnist_2024-11-13_17-12-23/driver_artifacts/train_mnist_72e7b_00003_3_batch_size=32,lr=0.0061,n_layers=2,n_units=128_2024-11-13_17-12-37/error.txt   |\n",
            "| train_mnist_72e7b_00004              1   /tmp/ray/session_2024-11-13_17-12-15_277287_683/artifacts/2024-11-13_17-12-23/train_mnist_2024-11-13_17-12-23/driver_artifacts/train_mnist_72e7b_00004_4_batch_size=128,lr=0.0022,n_layers=2,n_units=32_2024-11-13_17-12-37/error.txt   |\n",
            "| train_mnist_72e7b_00005              1   /tmp/ray/session_2024-11-13_17-12-15_277287_683/artifacts/2024-11-13_17-12-23/train_mnist_2024-11-13_17-12-23/driver_artifacts/train_mnist_72e7b_00005_5_batch_size=128,lr=0.0029,n_layers=3,n_units=32_2024-11-13_17-12-38/error.txt   |\n",
            "| train_mnist_72e7b_00006              1   /tmp/ray/session_2024-11-13_17-12-15_277287_683/artifacts/2024-11-13_17-12-23/train_mnist_2024-11-13_17-12-23/driver_artifacts/train_mnist_72e7b_00006_6_batch_size=32,lr=0.0009,n_layers=1,n_units=64_2024-11-13_17-12-38/error.txt    |\n",
            "| train_mnist_72e7b_00007              1   /tmp/ray/session_2024-11-13_17-12-15_277287_683/artifacts/2024-11-13_17-12-23/train_mnist_2024-11-13_17-12-23/driver_artifacts/train_mnist_72e7b_00007_7_batch_size=128,lr=0.0002,n_layers=1,n_units=32_2024-11-13_17-12-39/error.txt   |\n",
            "| train_mnist_72e7b_00008              1   /tmp/ray/session_2024-11-13_17-12-15_277287_683/artifacts/2024-11-13_17-12-23/train_mnist_2024-11-13_17-12-23/driver_artifacts/train_mnist_72e7b_00008_8_batch_size=64,lr=0.0037,n_layers=3,n_units=32_2024-11-13_17-12-39/error.txt    |\n",
            "| train_mnist_72e7b_00009              1   /tmp/ray/session_2024-11-13_17-12-15_277287_683/artifacts/2024-11-13_17-12-23/train_mnist_2024-11-13_17-12-23/driver_artifacts/train_mnist_72e7b_00009_9_batch_size=32,lr=0.0001,n_layers=3,n_units=32_2024-11-13_17-12-40/error.txt    |\n",
            "| train_mnist_72e7b_00010              1   /tmp/ray/session_2024-11-13_17-12-15_277287_683/artifacts/2024-11-13_17-12-23/train_mnist_2024-11-13_17-12-23/driver_artifacts/train_mnist_72e7b_00010_10_batch_size=32,lr=0.0028,n_layers=2,n_units=128_2024-11-13_17-12-40/error.txt  |\n",
            "| train_mnist_72e7b_00011              1   /tmp/ray/session_2024-11-13_17-12-15_277287_683/artifacts/2024-11-13_17-12-23/train_mnist_2024-11-13_17-12-23/driver_artifacts/train_mnist_72e7b_00011_11_batch_size=64,lr=0.0000,n_layers=3,n_units=128_2024-11-13_17-12-41/error.txt  |\n",
            "| train_mnist_72e7b_00012              1   /tmp/ray/session_2024-11-13_17-12-15_277287_683/artifacts/2024-11-13_17-12-23/train_mnist_2024-11-13_17-12-23/driver_artifacts/train_mnist_72e7b_00012_12_batch_size=32,lr=0.0000,n_layers=1,n_units=64_2024-11-13_17-12-41/error.txt   |\n",
            "| train_mnist_72e7b_00013              1   /tmp/ray/session_2024-11-13_17-12-15_277287_683/artifacts/2024-11-13_17-12-23/train_mnist_2024-11-13_17-12-23/driver_artifacts/train_mnist_72e7b_00013_13_batch_size=32,lr=0.0000,n_layers=3,n_units=128_2024-11-13_17-12-42/error.txt  |\n",
            "| train_mnist_72e7b_00014              1   /tmp/ray/session_2024-11-13_17-12-15_277287_683/artifacts/2024-11-13_17-12-23/train_mnist_2024-11-13_17-12-23/driver_artifacts/train_mnist_72e7b_00014_14_batch_size=64,lr=0.0002,n_layers=2,n_units=64_2024-11-13_17-12-42/error.txt   |\n",
            "| train_mnist_72e7b_00015              1   /tmp/ray/session_2024-11-13_17-12-15_277287_683/artifacts/2024-11-13_17-12-23/train_mnist_2024-11-13_17-12-23/driver_artifacts/train_mnist_72e7b_00015_15_batch_size=128,lr=0.0001,n_layers=3,n_units=128_2024-11-13_17-12-43/error.txt |\n",
            "| train_mnist_72e7b_00016              1   /tmp/ray/session_2024-11-13_17-12-15_277287_683/artifacts/2024-11-13_17-12-23/train_mnist_2024-11-13_17-12-23/driver_artifacts/train_mnist_72e7b_00016_16_batch_size=32,lr=0.0002,n_layers=3,n_units=128_2024-11-13_17-12-43/error.txt  |\n",
            "| train_mnist_72e7b_00017              1   /tmp/ray/session_2024-11-13_17-12-15_277287_683/artifacts/2024-11-13_17-12-23/train_mnist_2024-11-13_17-12-23/driver_artifacts/train_mnist_72e7b_00017_17_batch_size=64,lr=0.0005,n_layers=3,n_units=128_2024-11-13_17-12-44/error.txt  |\n",
            "| train_mnist_72e7b_00018              1   /tmp/ray/session_2024-11-13_17-12-15_277287_683/artifacts/2024-11-13_17-12-23/train_mnist_2024-11-13_17-12-23/driver_artifacts/train_mnist_72e7b_00018_18_batch_size=32,lr=0.0001,n_layers=3,n_units=32_2024-11-13_17-12-44/error.txt   |\n",
            "| train_mnist_72e7b_00019              1   /tmp/ray/session_2024-11-13_17-12-15_277287_683/artifacts/2024-11-13_17-12-23/train_mnist_2024-11-13_17-12-23/driver_artifacts/train_mnist_72e7b_00019_19_batch_size=128,lr=0.0002,n_layers=1,n_units=64_2024-11-13_17-12-45/error.txt  |\n",
            "+----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
            "\n"
          ]
        },
        {
          "ename": "TuneError",
          "evalue": "('Trials did not complete', [train_mnist_72e7b_00000, train_mnist_72e7b_00001, train_mnist_72e7b_00002, train_mnist_72e7b_00003, train_mnist_72e7b_00004, train_mnist_72e7b_00005, train_mnist_72e7b_00006, train_mnist_72e7b_00007, train_mnist_72e7b_00008, train_mnist_72e7b_00009, train_mnist_72e7b_00010, train_mnist_72e7b_00011, train_mnist_72e7b_00012, train_mnist_72e7b_00013, train_mnist_72e7b_00014, train_mnist_72e7b_00015, train_mnist_72e7b_00016, train_mnist_72e7b_00017, train_mnist_72e7b_00018, train_mnist_72e7b_00019])",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTuneError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-8222499238c3>\u001b[0m in \u001b[0;36m<cell line: 102>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;31m# Run Ray Tune\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m analysis = tune.run(\n\u001b[0m\u001b[1;32m    103\u001b[0m     \u001b[0mtrain_mnist\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0mresources_per_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"gpu\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ray/tune/tune.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(run_or_experiment, name, metric, mode, stop, time_budget_s, config, resources_per_trial, num_samples, storage_path, storage_filesystem, search_alg, scheduler, checkpoint_config, verbose, progress_reporter, log_to_file, trial_name_creator, trial_dirname_creator, sync_config, export_formats, max_failures, fail_fast, restore, resume, resume_config, reuse_actors, raise_on_failed_trial, callbacks, max_concurrent_trials, keep_checkpoints_num, checkpoint_score_attr, checkpoint_freq, checkpoint_at_end, chdir_to_trial_dir, local_dir, _remote, _remote_string_queue, _entrypoint)\u001b[0m\n\u001b[1;32m   1033\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mincomplete_trials\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mraise_on_failed_trial\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mexperiment_interrupted_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1035\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTuneError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Trials did not complete\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincomplete_trials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1036\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1037\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Trials did not complete: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mincomplete_trials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTuneError\u001b[0m: ('Trials did not complete', [train_mnist_72e7b_00000, train_mnist_72e7b_00001, train_mnist_72e7b_00002, train_mnist_72e7b_00003, train_mnist_72e7b_00004, train_mnist_72e7b_00005, train_mnist_72e7b_00006, train_mnist_72e7b_00007, train_mnist_72e7b_00008, train_mnist_72e7b_00009, train_mnist_72e7b_00010, train_mnist_72e7b_00011, train_mnist_72e7b_00012, train_mnist_72e7b_00013, train_mnist_72e7b_00014, train_mnist_72e7b_00015, train_mnist_72e7b_00016, train_mnist_72e7b_00017, train_mnist_72e7b_00018, train_mnist_72e7b_00019])"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from ray import tune\n",
        "from ray.tune import CLIReporter\n",
        "from ray.tune.schedulers import ASHAScheduler\n",
        "\n",
        "# Define transformations for the MNIST dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))  # Normalize the images\n",
        "])\n",
        "\n",
        "# Load the MNIST training and test datasets\n",
        "train_val_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "# Split train_val_dataset into training and validation sets (e.g., 90% train, 10% validation)\n",
        "train_size = int(0.9 * len(train_val_dataset))\n",
        "val_size = len(train_val_dataset) - train_size\n",
        "train_dataset, val_dataset = random_split(train_val_dataset, [train_size, val_size])\n",
        "\n",
        "# Define the PyTorch model\n",
        "class SimpleNN(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super(SimpleNN, self).__init__()\n",
        "        layers = [nn.Flatten()]\n",
        "        in_features = 28 * 28\n",
        "        for _ in range(config[\"n_layers\"]):\n",
        "            layers.append(nn.Linear(in_features, config[\"n_units\"]))\n",
        "            layers.append(nn.ReLU())\n",
        "            in_features = config[\"n_units\"]\n",
        "        layers.append(nn.Linear(in_features, 10))  # Output layer for 10 classes\n",
        "        self.model = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.model(x)\n",
        "\n",
        "# Training function for Ray Tune\n",
        "def train_mnist(config, checkpoint_dir=None):\n",
        "    model = SimpleNN(config)\n",
        "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "    model.to(device)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=config[\"lr\"])\n",
        "\n",
        "    # Load data\n",
        "    train_loader = DataLoader(train_dataset, batch_size=config[\"batch_size\"], shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=config[\"batch_size\"], shuffle=False)\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(5):  # Training for a few epochs\n",
        "        model.train()\n",
        "        for X_batch, y_batch in train_loader:\n",
        "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(X_batch)\n",
        "            loss = criterion(outputs, y_batch)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        # Validation accuracy\n",
        "        model.eval()\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        with torch.no_grad():\n",
        "            for X_batch, y_batch in val_loader:\n",
        "                X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "                outputs = model(X_batch)\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                correct += (predicted == y_batch).sum().item()\n",
        "                total += y_batch.size(0)\n",
        "\n",
        "        val_accuracy = correct / total\n",
        "        tune.report(mean_accuracy=val_accuracy)\n",
        "\n",
        "# Hyperparameter tuning configuration\n",
        "config = {\n",
        "    \"lr\": tune.loguniform(1e-5, 1e-2),\n",
        "    \"batch_size\": tune.choice([32, 64, 128]),\n",
        "    \"n_layers\": tune.randint(1, 4),\n",
        "    \"n_units\": tune.choice([32, 64, 128])\n",
        "}\n",
        "\n",
        "# Scheduler and Reporter for Ray Tune\n",
        "scheduler = ASHAScheduler(\n",
        "    metric=\"mean_accuracy\",\n",
        "    mode=\"max\",\n",
        "    max_t=5,  # Max epochs\n",
        "    grace_period=1,\n",
        "    reduction_factor=2\n",
        ")\n",
        "\n",
        "reporter = CLIReporter(\n",
        "    metric_columns=[\"mean_accuracy\", \"training_iteration\"]\n",
        ")\n",
        "\n",
        "# Run Ray Tune\n",
        "analysis = tune.run(\n",
        "    train_mnist,\n",
        "    resources_per_trial={\"cpu\": 1, \"gpu\": 1 if torch.cuda.is_available() else 0},\n",
        "    config=config,\n",
        "    num_samples=20,  # Number of hyperparameter configurations to try\n",
        "    scheduler=scheduler,\n",
        "    progress_reporter=reporter\n",
        ")\n",
        "\n",
        "# Best hyperparameters\n",
        "print(\"Best hyperparameters found were: \", analysis.best_config)\n",
        "\n",
        "# Optional: Evaluate the best model on the test set\n",
        "best_config = analysis.best_config\n",
        "\n",
        "# Load the test set with the best batch size\n",
        "test_loader = DataLoader(test_dataset, batch_size=best_config[\"batch_size\"], shuffle=False)\n",
        "\n",
        "# Define the best model and set it up for testing\n",
        "best_model = SimpleNN(best_config).to(device)\n",
        "optimizer = optim.Adam(best_model.parameters(), lr=best_config[\"lr\"])\n",
        "\n",
        "# Train the best model on the entire training dataset\n",
        "def train_final_model(model, train_loader, criterion, optimizer, epochs=5):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        for X_batch, y_batch in train_loader:\n",
        "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(X_batch)\n",
        "            loss = criterion(outputs, y_batch)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=best_config[\"batch_size\"], shuffle=True)\n",
        "train_final_model(best_model, train_loader, criterion, optimizer)\n",
        "\n",
        "# Evaluate on the test set\n",
        "best_model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for X_batch, y_batch in test_loader:\n",
        "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
        "        outputs = best_model(X_batch)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        correct += (predicted == y_batch).sum().item()\n",
        "        total += y_batch.size(0)\n",
        "\n",
        "test_accuracy = correct / total\n",
        "print(f\"Test Accuracy with best hyperparameters: {test_accuracy * 100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dMQuhRBmgW7V"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xdFO1m5fImpp"
      },
      "source": [
        "# Other Resources\n",
        "\n",
        "# 6 - Useful Resources\n",
        "\n",
        "\n",
        "## Textbooks\n",
        "\n",
        "-\tGéron, Aurélien. *Hands-on machine learning with Scikit-Learn, Keras, and TensorFlow*. \" O'Reilly Media, Inc.\", 2022.\n",
        "-\tHastie, Trevor, et al. *The elements of statistical learning: data mining, inference, and prediction*. Vol. 2. New York: springer, 2009.\n",
        "-\tGoodfellow, Ian, Yoshua Bengio, and Aaron Courville. [*Deep learning*](https://www.deeplearningbook.org/). MIT press, 2016.\n",
        "-\tParr, Terence, and Jeremy Howard. [\"*The matrix calculus you need for deep learning.*\"](https://arxiv.org/abs/1802.01528) arXiv preprint arXiv:1802.01528 (2018).\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## Websites\n",
        "-\t[Hand's on machine learning Github Repository](https://github.com/ageron/handson-ml2) - a series of Jupyter notebooks that includes example code for extremely important concepts.\n",
        "-\t[Machine Learning Mastery](https://machinelearningmastery.com/) - A blog that covers almost every possible topic and includes example codes, links to papers, and more. Code mostly written in Python, with some entries in R.\n",
        "-\t[Papers with Code](https://paperswithcode.com/) - a website that contains links to research papers and their code.\n",
        "- [kaggle](https://www.kaggle.com/) - a website for data science competitions, as well as free learning modules in a variety of machine learning topics\n",
        "-\t[AI2ES](https://www.ai2es.org/products/education/) - a research group mostly focused on machine learning in weather, but that has extremely useful resources.\n",
        "\n",
        "## Other\n",
        "- [Anaconda](https://www.anaconda.com/) - a data science application that includes software and a package manager, as well as pre-installed basic packages used for machine learning."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}