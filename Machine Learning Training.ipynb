{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f42406d0",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e164ac22",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'lab_utils_uni'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12232\\3362080910.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msns\u001b[0m        \u001b[1;31m# data visualization library based on matplotlib for creating more attractive visualizations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# plt.style.use('./deeplearning.mplstyle')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mlab_utils_uni\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mplt_house_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplt_contour_wgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplt_divergence\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplt_gradients\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;31m# Machine Learning\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'lab_utils_uni'"
     ]
    }
   ],
   "source": [
    "import pandas as pd          # data analysis library for handling structured data\n",
    "import numpy as np           # mathematical library for working with numerical data\n",
    "import pandas_profiling\n",
    "import time \n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt     # data visualization library for creating graphs and charts\n",
    "%matplotlib inline\n",
    "import seaborn as sns        # data visualization library based on matplotlib for creating more attractive visualizations\n",
    "# plt.style.use('./deeplearning.mplstyle')\n",
    "from lab_utils_uni import plt_house_x, plt_contour_wgrad, plt_divergence, plt_gradients\n",
    "\n",
    "# Machine Learning \n",
    "\n",
    "\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") \n",
    "\n",
    "pd.set_option('display.max_rows', 15)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6746e081",
   "metadata": {},
   "outputs": [],
   "source": [
    "smart_home = pd.read_csv(r\"C:\\Users\\Cornel\\Documents\\5. Projects\\Smart Home\\Smart Home Dataset\\Smart Home Dataset with weather Information\\HomeC.csv\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c276165",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>use [kW]</th>\n",
       "      <th>gen [kW]</th>\n",
       "      <th>House overall [kW]</th>\n",
       "      <th>Dishwasher [kW]</th>\n",
       "      <th>Furnace 1 [kW]</th>\n",
       "      <th>Furnace 2 [kW]</th>\n",
       "      <th>Home office [kW]</th>\n",
       "      <th>Fridge [kW]</th>\n",
       "      <th>Wine cellar [kW]</th>\n",
       "      <th>Garage door [kW]</th>\n",
       "      <th>Kitchen 12 [kW]</th>\n",
       "      <th>Kitchen 14 [kW]</th>\n",
       "      <th>Kitchen 38 [kW]</th>\n",
       "      <th>Barn [kW]</th>\n",
       "      <th>Well [kW]</th>\n",
       "      <th>Microwave [kW]</th>\n",
       "      <th>Living room [kW]</th>\n",
       "      <th>Solar [kW]</th>\n",
       "      <th>temperature</th>\n",
       "      <th>icon</th>\n",
       "      <th>humidity</th>\n",
       "      <th>visibility</th>\n",
       "      <th>summary</th>\n",
       "      <th>apparentTemperature</th>\n",
       "      <th>pressure</th>\n",
       "      <th>windSpeed</th>\n",
       "      <th>cloudCover</th>\n",
       "      <th>windBearing</th>\n",
       "      <th>precipIntensity</th>\n",
       "      <th>dewPoint</th>\n",
       "      <th>precipProbability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1451624400</td>\n",
       "      <td>0.932833</td>\n",
       "      <td>0.003483</td>\n",
       "      <td>0.932833</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.020700</td>\n",
       "      <td>0.061917</td>\n",
       "      <td>0.442633</td>\n",
       "      <td>0.124150</td>\n",
       "      <td>0.006983</td>\n",
       "      <td>0.013083</td>\n",
       "      <td>0.000417</td>\n",
       "      <td>0.000150</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031350</td>\n",
       "      <td>0.001017</td>\n",
       "      <td>0.004067</td>\n",
       "      <td>0.001517</td>\n",
       "      <td>0.003483</td>\n",
       "      <td>36.14</td>\n",
       "      <td>clear-night</td>\n",
       "      <td>0.62</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Clear</td>\n",
       "      <td>29.26</td>\n",
       "      <td>1016.91</td>\n",
       "      <td>9.18</td>\n",
       "      <td>cloudCover</td>\n",
       "      <td>282.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1451624401</td>\n",
       "      <td>0.934333</td>\n",
       "      <td>0.003467</td>\n",
       "      <td>0.934333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020717</td>\n",
       "      <td>0.063817</td>\n",
       "      <td>0.444067</td>\n",
       "      <td>0.124000</td>\n",
       "      <td>0.006983</td>\n",
       "      <td>0.013117</td>\n",
       "      <td>0.000417</td>\n",
       "      <td>0.000150</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031500</td>\n",
       "      <td>0.001017</td>\n",
       "      <td>0.004067</td>\n",
       "      <td>0.001650</td>\n",
       "      <td>0.003467</td>\n",
       "      <td>36.14</td>\n",
       "      <td>clear-night</td>\n",
       "      <td>0.62</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Clear</td>\n",
       "      <td>29.26</td>\n",
       "      <td>1016.91</td>\n",
       "      <td>9.18</td>\n",
       "      <td>cloudCover</td>\n",
       "      <td>282.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1451624402</td>\n",
       "      <td>0.931817</td>\n",
       "      <td>0.003467</td>\n",
       "      <td>0.931817</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.020700</td>\n",
       "      <td>0.062317</td>\n",
       "      <td>0.446067</td>\n",
       "      <td>0.123533</td>\n",
       "      <td>0.006983</td>\n",
       "      <td>0.013083</td>\n",
       "      <td>0.000433</td>\n",
       "      <td>0.000167</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.031517</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.004067</td>\n",
       "      <td>0.001650</td>\n",
       "      <td>0.003467</td>\n",
       "      <td>36.14</td>\n",
       "      <td>clear-night</td>\n",
       "      <td>0.62</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Clear</td>\n",
       "      <td>29.26</td>\n",
       "      <td>1016.91</td>\n",
       "      <td>9.18</td>\n",
       "      <td>cloudCover</td>\n",
       "      <td>282.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1451624403</td>\n",
       "      <td>1.022050</td>\n",
       "      <td>0.003483</td>\n",
       "      <td>1.022050</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.106900</td>\n",
       "      <td>0.068517</td>\n",
       "      <td>0.446583</td>\n",
       "      <td>0.123133</td>\n",
       "      <td>0.006983</td>\n",
       "      <td>0.013000</td>\n",
       "      <td>0.000433</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.031500</td>\n",
       "      <td>0.001017</td>\n",
       "      <td>0.004067</td>\n",
       "      <td>0.001617</td>\n",
       "      <td>0.003483</td>\n",
       "      <td>36.14</td>\n",
       "      <td>clear-night</td>\n",
       "      <td>0.62</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Clear</td>\n",
       "      <td>29.26</td>\n",
       "      <td>1016.91</td>\n",
       "      <td>9.18</td>\n",
       "      <td>cloudCover</td>\n",
       "      <td>282.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         time  use [kW]  gen [kW]  House overall [kW]  Dishwasher [kW]  Furnace 1 [kW]  Furnace 2 [kW]  Home office [kW]  Fridge [kW]  Wine cellar [kW]  Garage door [kW]  Kitchen 12 [kW]  Kitchen 14 [kW]  Kitchen 38 [kW]  Barn [kW]  Well [kW]  Microwave [kW]  Living room [kW]  Solar [kW]  temperature         icon  humidity  visibility summary  apparentTemperature  pressure  windSpeed  cloudCover  windBearing  precipIntensity  dewPoint  precipProbability\n",
       "0  1451624400  0.932833  0.003483            0.932833         0.000033        0.020700        0.061917          0.442633     0.124150          0.006983          0.013083         0.000417         0.000150         0.000000   0.031350   0.001017        0.004067          0.001517    0.003483        36.14  clear-night      0.62        10.0   Clear                29.26   1016.91       9.18  cloudCover        282.0              0.0      24.4                0.0\n",
       "1  1451624401  0.934333  0.003467            0.934333         0.000000        0.020717        0.063817          0.444067     0.124000          0.006983          0.013117         0.000417         0.000150         0.000000   0.031500   0.001017        0.004067          0.001650    0.003467        36.14  clear-night      0.62        10.0   Clear                29.26   1016.91       9.18  cloudCover        282.0              0.0      24.4                0.0\n",
       "2  1451624402  0.931817  0.003467            0.931817         0.000017        0.020700        0.062317          0.446067     0.123533          0.006983          0.013083         0.000433         0.000167         0.000017   0.031517   0.001000        0.004067          0.001650    0.003467        36.14  clear-night      0.62        10.0   Clear                29.26   1016.91       9.18  cloudCover        282.0              0.0      24.4                0.0\n",
       "3  1451624403  1.022050  0.003483            1.022050         0.000017        0.106900        0.068517          0.446583     0.123133          0.006983          0.013000         0.000433         0.000217         0.000000   0.031500   0.001017        0.004067          0.001617    0.003483        36.14  clear-night      0.62        10.0   Clear                29.26   1016.91       9.18  cloudCover        282.0              0.0      24.4                0.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smart_home.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de7d0dbb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def replace_non_numeric(df: pd.DataFrame, columns):\n",
    "    \"\"\"\n",
    "    Replaces non-numeric values in the specified columns of a Pandas dataframe with NaN.\n",
    "\n",
    "    Parameters:\n",
    "        df (pd.DataFrame): The dataframe to process.\n",
    "        columns (list): A list of column names to replace non-numeric values in.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The updated dataframe with non-numeric values replaced by NaN.\n",
    "    \"\"\"\n",
    "    for col in columns:\n",
    "        if df[col].dtype == 'object':\n",
    "            df.dropna(subset = col, inplace= True)\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "        else:\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    return df\n",
    "\n",
    "smart_home = replace_non_numeric(smart_home, columns= ['time', 'use [kW]', 'gen [kW]', 'House overall [kW]', 'Dishwasher [kW]',\n",
    "       'Furnace 1 [kW]', 'Furnace 2 [kW]', 'Home office [kW]', 'Fridge [kW]',\n",
    "       'Wine cellar [kW]', 'Garage door [kW]', 'Kitchen 12 [kW]',\n",
    "       'Kitchen 14 [kW]', 'Kitchen 38 [kW]', 'Barn [kW]', 'Well [kW]',\n",
    "       'Microwave [kW]', 'Living room [kW]', 'Solar [kW]', 'temperature',\n",
    "       'humidity', 'visibility', 'apparentTemperature',\n",
    "       'pressure', 'windSpeed', 'cloudCover', 'windBearing', 'precipIntensity',\n",
    "       'dewPoint', 'precipProbability'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7a180009",
   "metadata": {},
   "source": [
    "### Scikit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a9daba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Built-in datasets. \n",
    "from sklearn.datasets import load_boston #Sklearn built-in dataset (load_boston, load_breast_cancer etc.)\n",
    "X, y = load_boston (return_X_y= True)\n",
    "\n",
    "#Sklearn Models\n",
    "#from sklearn.\"sub-module\" import \"model\"\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "    #steps  \n",
    "    1. create your model object\n",
    "        mod = KNeighborsRegressor() \n",
    "    2. Learn from your Data\n",
    "        mod.fit(X, y)   \n",
    "    3. Predict\n",
    "        pred = mod.predict(X) \n",
    "    \n",
    "    #Or (you may need to perform feature scaaling on your model in order to achieve better results) \n",
    "from sklearn.preprocessing import StandardScaler #this model can perform scaling\n",
    "from sklearn.pipeline import Pipeline #pipeline object - allows you to chain processing steps after each other\n",
    "    4. Pipeline\n",
    "        pipe = Pipeline( [                              #it needs a list of tuples, and its a pair of a name and a step\n",
    "            (\"scale\", StandardScaler()),\n",
    "            (\"model\", KNeighborsRegressor()) \n",
    "            ]) \n",
    "    5. then learn from the Data\n",
    "        pipe.fit(X, y)\n",
    "    6. Predict\n",
    "        pred = pipe.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba2f634",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scikit-Learn Sub-modules\n",
    "\n",
    "# Scikit-Learn library is organized into several sub-modules, each of which contains a set of related functions and classes. \n",
    "# Here are the main sub-modules in scikit-learn:\n",
    "\n",
    "# sklearn.datasets: This sub-module provides a set of standard datasets for machine learning, including iris, \n",
    "#     digits, and breast cancer.\n",
    "\n",
    "# sklearn.model_selection: This sub-module contains functions for model selection, such as splitting data into \n",
    "#     training and test sets, cross-validation, and grid search.\n",
    "\n",
    "# sklearn.preprocessing: This sub-module provides functions for preprocessing data, such as scaling, normalization, \n",
    "#     and encoding categorical variables.\n",
    "\n",
    "# sklearn.feature_extraction: This sub-module contains functions for feature extraction from raw data, \n",
    "#     such as text data, including Bag of Words, CountVectorizer, and TfidfVectorizer.\n",
    "\n",
    "# sklearn.metrics: This sub-module provides functions for evaluating the performance of machine learning models, \n",
    "#     such as accuracy, precision, recall, and F1 score.\n",
    "\n",
    "# sklearn.pipeline: This sub-module provides tools for building machine learning pipelines, \n",
    "#     which allows you to chain together multiple steps, such as feature extraction, preprocessing, and model selection.\n",
    "\n",
    "# sklearn.decomposition: This sub-module provides classes for matrix factorization and decomposition, \n",
    "#     such as Principal Component Analysis (PCA), Non-negative Matrix Factorization (NMF), \n",
    "#     and Latent Dirichlet Allocation (LDA).\n",
    "\n",
    "# sklearn.discriminant_analysis: This sub-module provides classes for linear and quadratic discriminant analysis, \n",
    "#     which are used for supervised classification tasks.\n",
    "\n",
    "# sklearn.covariance: This sub-module provides classes for covariance estimation, such as Empirical Covariance and \n",
    "#     Shrunk Covariance.\n",
    "\n",
    "# sklearn.exceptions: This sub-module contains custom exceptions raised by scikit-learn, such as NotFittedError and \n",
    "#     ConvergenceWarning.\n",
    "\n",
    "\n",
    "#Models: \n",
    "\n",
    "\n",
    "# sklearn.linear_model: This sub-module contains classes for linear models, such as linear regression, \n",
    "#     logistic regression, and ridge regression.\n",
    "\n",
    "# sklearn.tree: This sub-module provides classes for decision trees, such as DecisionTreeClassifier and \n",
    "#     DecisionTreeRegressor.\n",
    "\n",
    "# sklearn.ensemble: This sub-module contains classes for ensemble models, such as random forests, AdaBoost, \n",
    "#     and Gradient Boosting.\n",
    "\n",
    "# sklearn.cluster: This sub-module provides classes for clustering, such as KMeans and Hierarchical Clustering.\n",
    "\n",
    "# sklearn.neural_network: This sub-module contains classes for neural networks, such as Multi-Layer Perceptron (MLP) \n",
    "#     and Convolutional Neural Networks (CNNs).\n",
    "\n",
    "# sklearn.svm: This sub-module contains classes for Support Vector Machines (SVMs), such as SVM classifier and regression.\n",
    "\n",
    "# sklearn.manifold: This sub-module provides classes for manifold learning, such as t-SNE and Isomap.\n",
    "\n",
    "# sklearn.naive_bayes: This sub-module provides classes for Naive Bayes models, such as Gaussian Naive Bayes and \n",
    "#     Multinomial Naive Bayes.\n",
    "\n",
    "# sklearn.neighbors: This sub-module provides classes for k-Nearest Neighbors (k-NN) models, \n",
    "#     such as KNeighborsClassifier and KNeighborsRegressor.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "5aa3dbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "c0fcba43",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "77025d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data.data, columns=data.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "779e2117",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>radius error</th>\n",
       "      <th>texture error</th>\n",
       "      <th>perimeter error</th>\n",
       "      <th>area error</th>\n",
       "      <th>smoothness error</th>\n",
       "      <th>compactness error</th>\n",
       "      <th>concavity error</th>\n",
       "      <th>concave points error</th>\n",
       "      <th>symmetry error</th>\n",
       "      <th>fractal dimension error</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>1.0950</td>\n",
       "      <td>0.9053</td>\n",
       "      <td>8.589</td>\n",
       "      <td>153.40</td>\n",
       "      <td>0.006399</td>\n",
       "      <td>0.04904</td>\n",
       "      <td>0.05373</td>\n",
       "      <td>0.01587</td>\n",
       "      <td>0.03003</td>\n",
       "      <td>0.006193</td>\n",
       "      <td>25.380</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>0.5435</td>\n",
       "      <td>0.7339</td>\n",
       "      <td>3.398</td>\n",
       "      <td>74.08</td>\n",
       "      <td>0.005225</td>\n",
       "      <td>0.01308</td>\n",
       "      <td>0.01860</td>\n",
       "      <td>0.01340</td>\n",
       "      <td>0.01389</td>\n",
       "      <td>0.003532</td>\n",
       "      <td>24.990</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>0.7456</td>\n",
       "      <td>0.7869</td>\n",
       "      <td>4.585</td>\n",
       "      <td>94.03</td>\n",
       "      <td>0.006150</td>\n",
       "      <td>0.04006</td>\n",
       "      <td>0.03832</td>\n",
       "      <td>0.02058</td>\n",
       "      <td>0.02250</td>\n",
       "      <td>0.004571</td>\n",
       "      <td>23.570</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>0.4956</td>\n",
       "      <td>1.1560</td>\n",
       "      <td>3.445</td>\n",
       "      <td>27.23</td>\n",
       "      <td>0.009110</td>\n",
       "      <td>0.07458</td>\n",
       "      <td>0.05661</td>\n",
       "      <td>0.01867</td>\n",
       "      <td>0.05963</td>\n",
       "      <td>0.009208</td>\n",
       "      <td>14.910</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>0.7572</td>\n",
       "      <td>0.7813</td>\n",
       "      <td>5.438</td>\n",
       "      <td>94.44</td>\n",
       "      <td>0.011490</td>\n",
       "      <td>0.02461</td>\n",
       "      <td>0.05688</td>\n",
       "      <td>0.01885</td>\n",
       "      <td>0.01756</td>\n",
       "      <td>0.005115</td>\n",
       "      <td>22.540</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>0.05623</td>\n",
       "      <td>1.1760</td>\n",
       "      <td>1.2560</td>\n",
       "      <td>7.673</td>\n",
       "      <td>158.70</td>\n",
       "      <td>0.010300</td>\n",
       "      <td>0.02891</td>\n",
       "      <td>0.05198</td>\n",
       "      <td>0.02454</td>\n",
       "      <td>0.01114</td>\n",
       "      <td>0.004239</td>\n",
       "      <td>25.450</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>0.05533</td>\n",
       "      <td>0.7655</td>\n",
       "      <td>2.4630</td>\n",
       "      <td>5.203</td>\n",
       "      <td>99.04</td>\n",
       "      <td>0.005769</td>\n",
       "      <td>0.02423</td>\n",
       "      <td>0.03950</td>\n",
       "      <td>0.01678</td>\n",
       "      <td>0.01898</td>\n",
       "      <td>0.002498</td>\n",
       "      <td>23.690</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>0.05648</td>\n",
       "      <td>0.4564</td>\n",
       "      <td>1.0750</td>\n",
       "      <td>3.425</td>\n",
       "      <td>48.55</td>\n",
       "      <td>0.005903</td>\n",
       "      <td>0.03731</td>\n",
       "      <td>0.04730</td>\n",
       "      <td>0.01557</td>\n",
       "      <td>0.01318</td>\n",
       "      <td>0.003892</td>\n",
       "      <td>18.980</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.07016</td>\n",
       "      <td>0.7260</td>\n",
       "      <td>1.5950</td>\n",
       "      <td>5.772</td>\n",
       "      <td>86.22</td>\n",
       "      <td>0.006522</td>\n",
       "      <td>0.06158</td>\n",
       "      <td>0.07117</td>\n",
       "      <td>0.01664</td>\n",
       "      <td>0.02324</td>\n",
       "      <td>0.006185</td>\n",
       "      <td>25.740</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.05884</td>\n",
       "      <td>0.3857</td>\n",
       "      <td>1.4280</td>\n",
       "      <td>2.548</td>\n",
       "      <td>19.15</td>\n",
       "      <td>0.007189</td>\n",
       "      <td>0.00466</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.02676</td>\n",
       "      <td>0.002783</td>\n",
       "      <td>9.456</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  mean compactness  mean concavity  mean concave points  mean symmetry  mean fractal dimension  radius error  texture error  perimeter error  area error  smoothness error  compactness error  concavity error  concave points error  symmetry error  fractal dimension error  worst radius  worst texture  worst perimeter  worst area  worst smoothness  worst compactness  worst concavity  worst concave points  worst symmetry  worst fractal dimension\n",
       "0          17.99         10.38          122.80     1001.0          0.11840           0.27760         0.30010              0.14710         0.2419                 0.07871        1.0950         0.9053            8.589      153.40          0.006399            0.04904          0.05373               0.01587         0.03003                 0.006193        25.380          17.33           184.60      2019.0           0.16220            0.66560           0.7119                0.2654          0.4601                  0.11890\n",
       "1          20.57         17.77          132.90     1326.0          0.08474           0.07864         0.08690              0.07017         0.1812                 0.05667        0.5435         0.7339            3.398       74.08          0.005225            0.01308          0.01860               0.01340         0.01389                 0.003532        24.990          23.41           158.80      1956.0           0.12380            0.18660           0.2416                0.1860          0.2750                  0.08902\n",
       "2          19.69         21.25          130.00     1203.0          0.10960           0.15990         0.19740              0.12790         0.2069                 0.05999        0.7456         0.7869            4.585       94.03          0.006150            0.04006          0.03832               0.02058         0.02250                 0.004571        23.570          25.53           152.50      1709.0           0.14440            0.42450           0.4504                0.2430          0.3613                  0.08758\n",
       "3          11.42         20.38           77.58      386.1          0.14250           0.28390         0.24140              0.10520         0.2597                 0.09744        0.4956         1.1560            3.445       27.23          0.009110            0.07458          0.05661               0.01867         0.05963                 0.009208        14.910          26.50            98.87       567.7           0.20980            0.86630           0.6869                0.2575          0.6638                  0.17300\n",
       "4          20.29         14.34          135.10     1297.0          0.10030           0.13280         0.19800              0.10430         0.1809                 0.05883        0.7572         0.7813            5.438       94.44          0.011490            0.02461          0.05688               0.01885         0.01756                 0.005115        22.540          16.67           152.20      1575.0           0.13740            0.20500           0.4000                0.1625          0.2364                  0.07678\n",
       "..           ...           ...             ...        ...              ...               ...             ...                  ...            ...                     ...           ...            ...              ...         ...               ...                ...              ...                   ...             ...                      ...           ...            ...              ...         ...               ...                ...              ...                   ...             ...                      ...\n",
       "564        21.56         22.39          142.00     1479.0          0.11100           0.11590         0.24390              0.13890         0.1726                 0.05623        1.1760         1.2560            7.673      158.70          0.010300            0.02891          0.05198               0.02454         0.01114                 0.004239        25.450          26.40           166.10      2027.0           0.14100            0.21130           0.4107                0.2216          0.2060                  0.07115\n",
       "565        20.13         28.25          131.20     1261.0          0.09780           0.10340         0.14400              0.09791         0.1752                 0.05533        0.7655         2.4630            5.203       99.04          0.005769            0.02423          0.03950               0.01678         0.01898                 0.002498        23.690          38.25           155.00      1731.0           0.11660            0.19220           0.3215                0.1628          0.2572                  0.06637\n",
       "566        16.60         28.08          108.30      858.1          0.08455           0.10230         0.09251              0.05302         0.1590                 0.05648        0.4564         1.0750            3.425       48.55          0.005903            0.03731          0.04730               0.01557         0.01318                 0.003892        18.980          34.12           126.70      1124.0           0.11390            0.30940           0.3403                0.1418          0.2218                  0.07820\n",
       "567        20.60         29.33          140.10     1265.0          0.11780           0.27700         0.35140              0.15200         0.2397                 0.07016        0.7260         1.5950            5.772       86.22          0.006522            0.06158          0.07117               0.01664         0.02324                 0.006185        25.740          39.42           184.60      1821.0           0.16500            0.86810           0.9387                0.2650          0.4087                  0.12400\n",
       "568         7.76         24.54           47.92      181.0          0.05263           0.04362         0.00000              0.00000         0.1587                 0.05884        0.3857         1.4280            2.548       19.15          0.007189            0.00466          0.00000               0.00000         0.02676                 0.002783         9.456          30.37            59.16       268.6           0.08996            0.06444           0.0000                0.0000          0.2871                  0.07039\n",
       "\n",
       "[569 rows x 30 columns]"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "af831349",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris_data = load_iris()\n",
    "iris_features = iris_data.data \n",
    "iris_target = iris_data.target\n",
    "\n",
    "# Convert the data to a DataFrame\n",
    "df = pd.DataFrame(iris_features, columns=iris_data.feature_names)\n",
    "\n",
    "# Add the target variable to the DataFrame\n",
    "df['target'] = iris_target "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "d8d193cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  target\n",
       "0                  5.1               3.5                1.4               0.2       0\n",
       "1                  4.9               3.0                1.4               0.2       0\n",
       "2                  4.7               3.2                1.3               0.2       0\n",
       "3                  4.6               3.1                1.5               0.2       0\n",
       "4                  5.0               3.6                1.4               0.2       0\n",
       "..                 ...               ...                ...               ...     ...\n",
       "145                6.7               3.0                5.2               2.3       2\n",
       "146                6.3               2.5                5.0               1.9       2\n",
       "147                6.5               3.0                5.2               2.0       2\n",
       "148                6.2               3.4                5.4               2.3       2\n",
       "149                5.9               3.0                5.1               1.8       2\n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "004f5fc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _iris_dataset:\n",
      "\n",
      "Iris plants dataset\n",
      "--------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 150 (50 in each of three classes)\n",
      "    :Number of Attributes: 4 numeric, predictive attributes and the class\n",
      "    :Attribute Information:\n",
      "        - sepal length in cm\n",
      "        - sepal width in cm\n",
      "        - petal length in cm\n",
      "        - petal width in cm\n",
      "        - class:\n",
      "                - Iris-Setosa\n",
      "                - Iris-Versicolour\n",
      "                - Iris-Virginica\n",
      "                \n",
      "    :Summary Statistics:\n",
      "\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "                    Min  Max   Mean    SD   Class Correlation\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "    sepal length:   4.3  7.9   5.84   0.83    0.7826\n",
      "    sepal width:    2.0  4.4   3.05   0.43   -0.4194\n",
      "    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n",
      "    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "    :Class Distribution: 33.3% for each of 3 classes.\n",
      "    :Creator: R.A. Fisher\n",
      "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      "    :Date: July, 1988\n",
      "\n",
      "The famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\n",
      "from Fisher's paper. Note that it's the same as in R, but not as in the UCI\n",
      "Machine Learning Repository, which has two wrong data points.\n",
      "\n",
      "This is perhaps the best known database to be found in the\n",
      "pattern recognition literature.  Fisher's paper is a classic in the field and\n",
      "is referenced frequently to this day.  (See Duda & Hart, for example.)  The\n",
      "data set contains 3 classes of 50 instances each, where each class refers to a\n",
      "type of iris plant.  One class is linearly separable from the other 2; the\n",
      "latter are NOT linearly separable from each other.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\n",
      "     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\n",
      "     Mathematical Statistics\" (John Wiley, NY, 1950).\n",
      "   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\n",
      "     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\n",
      "   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\n",
      "     Structure and Classification Rule for Recognition in Partially Exposed\n",
      "     Environments\".  IEEE Transactions on Pattern Analysis and Machine\n",
      "     Intelligence, Vol. PAMI-2, No. 1, 67-71.\n",
      "   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\n",
      "     on Information Theory, May 1972, 431-433.\n",
      "   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\n",
      "     conceptual clustering system finds 3 classes in the data.\n",
      "   - Many, many more ...\n"
     ]
    }
   ],
   "source": [
    "# iris_data.DESCR\n",
    "print(iris_data.DESCR)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "55f0aee4",
   "metadata": {},
   "source": [
    "### Linear Regression and Multiple Linear Regression"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4b31424b",
   "metadata": {},
   "source": [
    "> Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "25162c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorization is a technique used in machine learning and other computational tasks to speed up computations \n",
    "# by performing them on arrays of data instead of iterating over each individual element. \n",
    "# NumPy is a popular Python library for numerical computations and it provides many functions and methods for vectorization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "cd222b23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22.14\n"
     ]
    }
   ],
   "source": [
    "#to compute the Multiple Linear regression values\n",
    "# f(x) = W.X + b\n",
    "# W = [w1, w2, w3, .... wn]     #a row vector of W (slope)\n",
    "# X = [x1, x2, x3, .... xn]     # a row vector of X (features)\n",
    "W = np.array([1.0, 2.5, -3.3])\n",
    "b = 4\n",
    "X = np.array([10,20,30])\n",
    "\n",
    "#use\n",
    "f = np.dot(W,X) + b     #Vectorization\n",
    "\n",
    "#or a for-loop, which doesn't work as fast\n",
    "f = 0 \n",
    "for j in range(3):\n",
    "    # f[j] = w[j] * x[j] \n",
    "    f = f + W[j] * W[j]\n",
    "f = f + b\n",
    "#NB: Vectorization makes the code shorter, faster and more efficient. \n",
    "print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "cb084eff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-35.0\n",
      "Elapsed time:  0.0010428428649902344 seconds\n"
     ]
    }
   ],
   "source": [
    "#Checking the time it takes to perform Vectorization, and comparing it with for-loop\n",
    "W = np.array([1.0, 2.5, -3.3])\n",
    "b = 4\n",
    "X = np.array([10,20,30])\n",
    "\n",
    "#vectorization\n",
    "start_time = time.time()\n",
    "\n",
    "f = np.dot(W,X) + b     #Vectorization\n",
    "#or a for-loop, which doesn't work as fast\n",
    "print(f) \n",
    "\n",
    "end_time = time.time() \n",
    "\n",
    "elapsed_time = end_time - start_time\n",
    "print(\"Elapsed time: \", elapsed_time, \"seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "2f1fa69d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-35.0\n",
      "Elapsed time:  0.0009684562683105469 seconds\n"
     ]
    }
   ],
   "source": [
    "#using for-loop\n",
    "\n",
    "W = np.array([1.0, 2.5, -3.3])\n",
    "b = 4\n",
    "X = np.array([10,20,30])\n",
    "\n",
    "#for-loop\n",
    "start_time = time.time()\n",
    "\n",
    "f = 0 \n",
    "for j in range(3):\n",
    "    f = f + W[j] * X[j]\n",
    "f = f + b\n",
    "print(f) \n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print(\"Elapsed time: \", elapsed_time, \"seconds\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1dcc1680",
   "metadata": {},
   "source": [
    "> Understanding Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d0544de2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.14331378, 0.50623554, 0.36266187, 0.56075036],\n",
       "        [0.75644037, 0.00317005, 0.28006657, 0.27545594],\n",
       "        [0.35731577, 0.63558213, 0.15984875, 0.92458012]],\n",
       "\n",
       "       [[0.54956668, 0.01727769, 0.36649432, 0.58258039],\n",
       "        [0.45841122, 0.00759815, 0.41263046, 0.88569144],\n",
       "        [0.66353197, 0.13433911, 0.31030726, 0.79395491]]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "arr = np.random.rand(2, 3, 4)\n",
    "\n",
    "row_means = np.mean(arr, axis=0)\n",
    "#it performs the mean on each row (just like axis = 2), unless there are multiple dimensions,\n",
    "#then it adds the value of each [ith] element in each dimension and divides by total no of values in that dimension.\n",
    "\n",
    "row_means = np.mean(arr, axis=1)\n",
    "print(row_means)\n",
    "#it sums the values of each column, and divides it by the number of elements in that column. \n",
    "# If there are multiple dimensions present, it does it for each dimension (1D, 2D, 3D etc.)\n",
    "\n",
    "col_means = np.mean(arr, axis=2)\n",
    "print(col_means)\n",
    "#it sums the values of each row, and divides it by the number of elements in that row. \n",
    "# If there are multiple dimensions present, it does it for each dimension (1D, 2D, 3D etc.)\n",
    "\n",
    "col_means = np.mean(arr, axis=(2,1))\n",
    "#it first performs the mean on axis = 1(columns), and then performs another mean on the previous mean on axis = 2(row)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dac91b5c",
   "metadata": {},
   "source": [
    "#### Linear Model, Cost function, Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e209a75d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt_gradients' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12232\\3405923596.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     45\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdj_dw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdj_db\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m \u001b[0mplt_gradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompute_cost\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompute_gradient\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt_gradients' is not defined"
     ]
    }
   ],
   "source": [
    "# Load our data set\n",
    "x_train = np.array([1.0, 2.0])   #features\n",
    "y_train = np.array([300.0, 500.0])   #target value\n",
    "\n",
    "#Function to calculate the cost\n",
    "def compute_cost(x, y, w, b):\n",
    "   \n",
    "    m = x.shape[0] \n",
    "    cost = 0\n",
    "    \n",
    "    for i in range(m):\n",
    "        f_wb = w * x[i] + b\n",
    "        cost = cost + (f_wb - y[i])**2\n",
    "    total_cost = 1 / (2 * m) * cost\n",
    "\n",
    "    return total_cost\n",
    "\n",
    "\n",
    "def compute_gradient(x, y, w, b): \n",
    "    \"\"\"\n",
    "    Computes the gradient for linear regression \n",
    "    Args:\n",
    "      x (ndarray (m,)): Data, m examples \n",
    "      y (ndarray (m,)): target values\n",
    "      w,b (scalar)    : model parameters  \n",
    "    Returns\n",
    "      dj_dw (scalar): The gradient of the cost w.r.t. the parameters w\n",
    "      dj_db (scalar): The gradient of the cost w.r.t. the parameter b     \n",
    "     \"\"\"\n",
    "    \n",
    "    # Number of training examples\n",
    "    m = x.shape[0]    \n",
    "    dj_dw = 0\n",
    "    dj_db = 0\n",
    "    \n",
    "    for i in range(m):  \n",
    "        f_wb = w * x[i] + b \n",
    "        dj_dw_i = (f_wb - y[i]) * x[i] \n",
    "        dj_db_i = f_wb - y[i] \n",
    "        dj_db += dj_db_i\n",
    "        dj_dw += dj_dw_i \n",
    "    dj_dw = dj_dw / m \n",
    "    dj_db = dj_db / m \n",
    "        \n",
    "    return dj_dw, dj_db\n",
    "\n",
    "plt_gradients(x_train,y_train, compute_cost, compute_gradient)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd99bb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c06f95f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0db13095",
   "metadata": {},
   "source": [
    "### Next thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "26905821",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "import numpy as np\n",
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "5bf41d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_wine()\n",
    "features = load_wine().data\n",
    "target = load_wine().target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1ad2f46c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _wine_dataset:\n",
      "\n",
      "Wine recognition dataset\n",
      "------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 178\n",
      "    :Number of Attributes: 13 numeric, predictive attributes and the class\n",
      "    :Attribute Information:\n",
      " \t\t- Alcohol\n",
      " \t\t- Malic acid\n",
      " \t\t- Ash\n",
      "\t\t- Alcalinity of ash  \n",
      " \t\t- Magnesium\n",
      "\t\t- Total phenols\n",
      " \t\t- Flavanoids\n",
      " \t\t- Nonflavanoid phenols\n",
      " \t\t- Proanthocyanins\n",
      "\t\t- Color intensity\n",
      " \t\t- Hue\n",
      " \t\t- OD280/OD315 of diluted wines\n",
      " \t\t- Proline\n",
      "\n",
      "    - class:\n",
      "            - class_0\n",
      "            - class_1\n",
      "            - class_2\n",
      "\t\t\n",
      "    :Summary Statistics:\n",
      "    \n",
      "    ============================= ==== ===== ======= =====\n",
      "                                   Min   Max   Mean     SD\n",
      "    ============================= ==== ===== ======= =====\n",
      "    Alcohol:                      11.0  14.8    13.0   0.8\n",
      "    Malic Acid:                   0.74  5.80    2.34  1.12\n",
      "    Ash:                          1.36  3.23    2.36  0.27\n",
      "    Alcalinity of Ash:            10.6  30.0    19.5   3.3\n",
      "    Magnesium:                    70.0 162.0    99.7  14.3\n",
      "    Total Phenols:                0.98  3.88    2.29  0.63\n",
      "    Flavanoids:                   0.34  5.08    2.03  1.00\n",
      "    Nonflavanoid Phenols:         0.13  0.66    0.36  0.12\n",
      "    Proanthocyanins:              0.41  3.58    1.59  0.57\n",
      "    Colour Intensity:              1.3  13.0     5.1   2.3\n",
      "    Hue:                          0.48  1.71    0.96  0.23\n",
      "    OD280/OD315 of diluted wines: 1.27  4.00    2.61  0.71\n",
      "    Proline:                       278  1680     746   315\n",
      "    ============================= ==== ===== ======= =====\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "    :Class Distribution: class_0 (59), class_1 (71), class_2 (48)\n",
      "    :Creator: R.A. Fisher\n",
      "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      "    :Date: July, 1988\n",
      "\n",
      "This is a copy of UCI ML Wine recognition datasets.\n",
      "https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\n",
      "\n",
      "The data is the results of a chemical analysis of wines grown in the same\n",
      "region in Italy by three different cultivators. There are thirteen different\n",
      "measurements taken for different constituents found in the three types of\n",
      "wine.\n",
      "\n",
      "Original Owners: \n",
      "\n",
      "Forina, M. et al, PARVUS - \n",
      "An Extendible Package for Data Exploration, Classification and Correlation. \n",
      "Institute of Pharmaceutical and Food Analysis and Technologies,\n",
      "Via Brigata Salerno, 16147 Genoa, Italy.\n",
      "\n",
      "Citation:\n",
      "\n",
      "Lichman, M. (2013). UCI Machine Learning Repository\n",
      "[https://archive.ics.uci.edu/ml]. Irvine, CA: University of California,\n",
      "School of Information and Computer Science. \n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "  (1) S. Aeberhard, D. Coomans and O. de Vel, \n",
      "  Comparison of Classifiers in High Dimensional Settings, \n",
      "  Tech. Rep. no. 92-02, (1992), Dept. of Computer Science and Dept. of  \n",
      "  Mathematics and Statistics, James Cook University of North Queensland. \n",
      "  (Also submitted to Technometrics). \n",
      "\n",
      "  The data was used with many others for comparing various \n",
      "  classifiers. The classes are separable, though only RDA \n",
      "  has achieved 100% correct classification. \n",
      "  (RDA : 100%, QDA 99.4%, LDA 98.9%, 1NN 96.1% (z-transformed data)) \n",
      "  (All results using the leave-one-out technique) \n",
      "\n",
      "  (2) S. Aeberhard, D. Coomans and O. de Vel, \n",
      "  \"THE CLASSIFICATION PERFORMANCE OF RDA\" \n",
      "  Tech. Rep. no. 92-01, (1992), Dept. of Computer Science and Dept. of \n",
      "  Mathematics and Statistics, James Cook University of North Queensland. \n",
      "  (Also submitted to Journal of Chemometrics).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(data.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e336cda1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((178, 13), (178,))"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape, target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9de798c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.feature_names\n",
    "df = pd.DataFrame(features, columns=data.feature_names)\n",
    "df[\"target\"] = target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "5608cd19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alcohol</th>\n",
       "      <th>malic_acid</th>\n",
       "      <th>ash</th>\n",
       "      <th>alcalinity_of_ash</th>\n",
       "      <th>magnesium</th>\n",
       "      <th>total_phenols</th>\n",
       "      <th>flavanoids</th>\n",
       "      <th>nonflavanoid_phenols</th>\n",
       "      <th>proanthocyanins</th>\n",
       "      <th>color_intensity</th>\n",
       "      <th>hue</th>\n",
       "      <th>od280/od315_of_diluted_wines</th>\n",
       "      <th>proline</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113.0</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>13.71</td>\n",
       "      <td>5.65</td>\n",
       "      <td>2.45</td>\n",
       "      <td>20.5</td>\n",
       "      <td>95.0</td>\n",
       "      <td>1.68</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.52</td>\n",
       "      <td>1.06</td>\n",
       "      <td>7.70</td>\n",
       "      <td>0.64</td>\n",
       "      <td>1.74</td>\n",
       "      <td>740.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>13.40</td>\n",
       "      <td>3.91</td>\n",
       "      <td>2.48</td>\n",
       "      <td>23.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.41</td>\n",
       "      <td>7.30</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.56</td>\n",
       "      <td>750.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>13.27</td>\n",
       "      <td>4.28</td>\n",
       "      <td>2.26</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.59</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.35</td>\n",
       "      <td>10.20</td>\n",
       "      <td>0.59</td>\n",
       "      <td>1.56</td>\n",
       "      <td>835.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>13.17</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.37</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>1.65</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1.46</td>\n",
       "      <td>9.30</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.62</td>\n",
       "      <td>840.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>14.13</td>\n",
       "      <td>4.10</td>\n",
       "      <td>2.74</td>\n",
       "      <td>24.5</td>\n",
       "      <td>96.0</td>\n",
       "      <td>2.05</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.35</td>\n",
       "      <td>9.20</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1.60</td>\n",
       "      <td>560.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>178 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  od280/od315_of_diluted_wines  proline  target\n",
       "0      14.23        1.71  2.43               15.6      127.0           2.80        3.06                  0.28             2.29             5.64  1.04                          3.92   1065.0       0\n",
       "1      13.20        1.78  2.14               11.2      100.0           2.65        2.76                  0.26             1.28             4.38  1.05                          3.40   1050.0       0\n",
       "2      13.16        2.36  2.67               18.6      101.0           2.80        3.24                  0.30             2.81             5.68  1.03                          3.17   1185.0       0\n",
       "3      14.37        1.95  2.50               16.8      113.0           3.85        3.49                  0.24             2.18             7.80  0.86                          3.45   1480.0       0\n",
       "4      13.24        2.59  2.87               21.0      118.0           2.80        2.69                  0.39             1.82             4.32  1.04                          2.93    735.0       0\n",
       "..       ...         ...   ...                ...        ...            ...         ...                   ...              ...              ...   ...                           ...      ...     ...\n",
       "173    13.71        5.65  2.45               20.5       95.0           1.68        0.61                  0.52             1.06             7.70  0.64                          1.74    740.0       2\n",
       "174    13.40        3.91  2.48               23.0      102.0           1.80        0.75                  0.43             1.41             7.30  0.70                          1.56    750.0       2\n",
       "175    13.27        4.28  2.26               20.0      120.0           1.59        0.69                  0.43             1.35            10.20  0.59                          1.56    835.0       2\n",
       "176    13.17        2.59  2.37               20.0      120.0           1.65        0.68                  0.53             1.46             9.30  0.60                          1.62    840.0       2\n",
       "177    14.13        4.10  2.74               24.5       96.0           2.05        0.76                  0.56             1.35             9.20  0.61                          1.60    560.0       2\n",
       "\n",
       "[178 rows x 14 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "6eca255e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"target\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e80ed4c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['class_0', 'class_1', 'class_2'], dtype='<U7')"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.target_names"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "c1065e887cc437d9280cab66f73a21fdac543e65443791bfb846601e6c934655"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
